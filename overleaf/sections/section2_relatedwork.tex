The problem of detecting fake news using machine learning techniques is being addressed in many different ways in the literature \autocite{Pathak2020}. The problem of fake news detection can be addressed in three different ways: an approach based on the use of traditional methods, an approach based on the use of deep learning methods, the implementation of extensions with language models. Authors try to find ways to make their models perform as well as possible. The classical approach is based on analysis of text length, word frequency or the use of n-grams \autocite{Shu2017}. In addition, it is proposed to use sentiment analysis to improve the model's performace. It has been detected that the sentiment of a text is correlated with the type of information conveyed (whether it is misinformation or not) \autocite{rubin2016fake}.

However, the classical approach is being supplanted by deep learning. There are papers that show that deep learning performs better at detecting fake news than classical methods. An example is the work of Wang et al. whose model based on convolutional neural networks (CNN) outperforms classical text classification methods \autocite{wang-2017-liar}. Rashkin et al. comes to similar findings by building the LSTM \autocite{rashkin-etal-2017-truth}. In addition, the performance of different approaches on the same dataset was also checked. It was shown that of all the machine learning algorithms, deep learning methods (such as Deep CNN, LSTM or RNN) are the best at detecting fake news. Deep learning shows supremacy over traditional machine learning methods on various datasets \autocite{IEEE2021}. 

On top of that, deep learning models can be yet improved. Research shows that employing language models improves performance of the previous state-of-the-art models \autocite{Conroy2015}. One of the most popular language models is BERT \autocite{Devlin2018}. There are, several variants of this model. The base BERT is a pre-trained model that was created to learn the context of words in unlabeled text. An extension of BERT that achieves even better results is RoBERTa (Robustly optimized BERT approach). However, its use requires more computing power and is more time-consuming \autocite{Liu2019}. Another variant of BERT is DistilBERT, a lighter version of BERT. It requires fewer resources and is faster, but has weaker performance \autocite{Sanh2019}. The above relationship is also true for the prediction of fake news using language models \autocite{Khan2021, Joy2022}.

In this paper, I focus on exploring the base version of BERT. I believe it is a good starting point and a compromise between the great performing RoBERTa and the light and fast DistilBERT. 

Earlier I described the confirmation that language models are useful for text classification. Detection of fake news is a special case of text classification, and the usefulness of language models (specifically, BERT) in this case has also been confirmed in the literature \autocite{Gundapu2021}. The paper \autocite{Carvajal2020} shows an example that BERT performs better in text classification than traditional approaches (Logistic Regression, SVC, Ridge Classifier).
There are numerous papers \autocite{Alonso-Bartolome2021, Wang2021, Singhal2019, Aljawarneh2022, Jwa2019, Yang2019} that confirm BERT can also be used for many various approaches in fake news detection. 

Na podstawie literatury można wysnuć hipotezę jakoby użycie BERTa poprawiało wyniki predykcji niezależnie od modelu jaki został na nim użyty \autocite{Kaliyar2021}. Kaliyar et al. 2021 budują framework, w którym używają oni BERTa do word embedding i na nim aplikują różnye modele machine learningowe (Multinomial Naïve Bayes, Decision Tree, Random Forest, KNN). Obserwują, że użycie BERTa poprawia wyniki predykcji. Można też patrzeć na to z drugiej strony i poprawiać performance Vanilla BERT przy użyciu LSTM (BERT + LSTM) \autocite{Rai2022}. 
Ze względu na łatwość przetrenowywania się sieci neuronowych, na małych zbiorach danych lepiej od deep learningu i modeli językowych radzi sobie Naive Bayes. Wraz ze zwiększaniem zbioru danych lepiej z predykcją fake newsów zaczyna sobie radzić deep learning. Używając modeli językowych należy się spodziewać osiągnięcia lepszych, state-of-the-art wyników \autocite{Khan2021}.

...

None of the sources in the literature review indicated that the use of BERT worsens model performance. Therefore, I form the research hypothesis that:
\vspace{0.2cm}

\noindent\textbf{H1: The use of BERT improves model performance regardless of model type}.
\vspace{0.2cm}

Apart from this, the model most often used \textit{(or perhaps recommended? to be checked)} predicting fake news together is the X model. Based on this, I form another research hypothesis that:
\vspace{0.2cm}

\noindent\textbf{H2: BERT works best with model X}
\vspace{0.2cm}

...


\noindent\rule{3cm}{0.2pt}

\textit{
Blueprint:
\begin{enumerate}
    \item \st{Fake News Detection in general}
    \item \st{Fake News Detection with BERT}
    \item \st{What models were used}
    \item \st{Are there any clues if BERT always 
        improves the performance?}
    \item With what models BERT works best?
\end{enumerate}
}

\noindent\rule{3cm}{0.2pt}