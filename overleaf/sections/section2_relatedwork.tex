The problem of detecting fake news using machine learning techniques is being addressed in many different ways in the literature \autocite{Pathak2020}. The problem of fake news detection can be addressed in three different ways: an approach based on the use of traditional methods, an approach based on the use of deep learning methods, the implementation of extensions with language models. Authors try to find ways to make their models perform as well as possible. The classical approach is based on analysis of text length, word frequency or the use of n-grams \autocite{Shu2017}. In addition, it is proposed to use sentiment analysis to improve the model's performace. It has been detected that the sentiment of a text is correlated with the type of information conveyed (whether it is misinformation or not) \autocite{rubin2016fake}.

However, the classical approach is being supplanted by deep learning. There are papers that show that deep learning performs better at detecting fake news than classical methods. An example is the work of Wang et al. whose model based on convolutional neural networks (CNN) outperforms classical text classification methods \autocite{wang-2017-liar}. Rashkin et al. comes to similar findings by building the LSTM \autocite{rashkin-etal-2017-truth}. In addition, the performance of different approaches on the same dataset was also checked. It was shown that of all the machine learning algorithms, deep learning methods (such as Deep CNN, LSTM or RNN) are the best at detecting fake news. Deep learning shows supremacy over traditional machine learning methods on various datasets \autocite{IEEE2021}. 

\textit{\textbf{WIP}} One approach that shows high efficacy and outperforms other solutions is the use of linguistic models \autocite{Conroy2015}. One model that is often reported in the literature is BERT \autocite{}. The authors in their study showing that using BERT outperforms other models and allows for state-of-the-art results \autocite{} ....

...

None of the sources in the literature review indicated that the use of BERT worsens model performance. Therefore, I form the research hypothesis that:
\vspace{0.2cm}

\noindent\textbf{H1: The use of BERT improves model performance regardless of model type}.
\vspace{0.2cm}

Apart from this, the model most often used \textit{(or perhaps recommended? to be checked)} predicting fake news together is the X model. Based on this, I form another research hypothesis that:
\vspace{0.2cm}

\noindent\textbf{H2: BERT works best with model X}
\vspace{0.2cm}

...


\noindent\rule{3cm}{0.2pt}

\textit{
Blueprint:
\begin{enumerate}
    \item Fake News Detection in general 
    \item Fake News Detection with BERT
    \item What models were used
    \item Are there any clues if BERT always 
        improves the performance?
    \item With what models BERT works best?
\end{enumerate}
}

Basing on the literature review formulate hypothesis. 

\textit{
\\Early hypothesis ideas:
\begin{enumerate}
    \item BERT improves the performance regardless of type of model used
    \item BERT works best with the model X 
        (choose the type of model after the literature review)
\end{enumerate}
}