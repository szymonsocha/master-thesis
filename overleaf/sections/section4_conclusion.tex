The aim of the study was to examine how the application of various tools affects the performance of fake news detection. For this purpose, the LIAR dataset was employed, as it demonstrated greater difficulty for prediction execution compared to other datasets. The fake news detection process consists of two crucial phases. The first one involves obtaining embeddings, while the second phase focuses on applying an appropriate algorithm for classifying fake news. The data, after undergoing prior cleansing and preparation, undergo the embedding generation process. Subsequently, these embeddings serve as inputs to the fake news classification algorithms, distinguishing between fake and genuine information.

In the literature, various approaches to obtaining embeddings and utilizing classification algorithms can be found. However, no comprehensive review has been conducted on how different combinations of embedding methods and classification algorithms impact the model's performance. This study focuses on the most popular and high-performing models. Regarding the embedding methods, GloVe, Word2Vec, BERT, RoBERTa, and GPT-2 were examined. For the classification algorithms, Logistic Regression, KNN, SVM, Random Forest, XGBoost, and Neural Network were selected. The model utilizing GloVe embeddings and a neural network classifier proved to be the best-performing model in terms of F1 Score (F1 Score = 55.7), outperforming the second-best model that employed RoBERTa embeddings and a neural network classifier (F1 Score = 54.8). The best-performing model achieved a lower performance compared to the benchmark model developed by Khan et al. (F1 Score = 60.2).

The research hypothesis stating that language model-based models outperform other embedding methods included in this study was verified. Additionally, it was investigated whether the choice of embedding method and classification algorithm significantly affects the model's performance.


The research hypotheses were verified using Kruskal-Wallis statistical tests, which demonstrated that the selection of an embedding method does not significantly impact the performance of the fake news detection model (p-value = 0.98 > 0.05, thereby failing to reject the null hypothesis that the distributions of the model results do not differ significantly from each other). Conversely, the same test revealed that the selection of a classification method does have a significant impact on the model's performance (p-value = 0.0002 < 0.05). Furthermore, in order to identify which of the examined classification methods exhibit different performance compared to the others, the pairwise Dunn test was employed. It was demonstrated that the average F1 Score results obtained from the Neural Network classification differ significantly from those obtained from KNN (p-value = 0.001) and Random Forest (p-value = 0.002).

In response to the titular question of whether GPT-2 is the best tool for fake news detection, the study did not provide sufficient evidence to indicate the existence of embedding methods demonstrating superior performance over others among those examined.

As a future research direction, to obtain more robust results, a similar study could be conducted on a larger number of datasets simultaneously. This would minimize the risk of results being influenced by the specific characteristics of a given dataset. Furthermore, improvements could be made to the classification methods. In this study, a classical neural network was employed. In addition to deep learning methods, another frequently mentioned classification method yielding highly accurate results is the Naive Bayes method. Given that the hypothesis that classification methods significantly impact model outcomes has been confirmed in this study, examining additional classification algorithms can greatly influence the results of future extensions of this research.