{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpFId1mjCySe"
   },
   "source": [
    "# Word Embeddings + various classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "TCU7NPLUuQrU",
    "ExecuteTime": {
     "end_time": "2023-05-15T23:51:06.108947864Z",
     "start_time": "2023-05-15T23:51:06.092514408Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gensim\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/liar_dataset/train.tsv', sep=\"\\t\", usecols=[1, 2], names = [\"label\", \"text\"])\n",
    "test = pd.read_csv('../../data/liar_dataset/test.tsv', sep=\"\\t\", usecols=[1, 2], names = [\"label\", \"text\"])\n",
    "valid = pd.read_csv('../../data/liar_dataset/valid.tsv', sep=\"\\t\", usecols=[1, 2], names = [\"label\", \"text\"])\n",
    "\n",
    "train = pd.concat([train, valid])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:42.103747834Z",
     "start_time": "2023-05-15T23:34:42.011808243Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "half-true      2362\nfalse          2258\nmostly-true    2213\nbarely-true    1891\ntrue           1845\npants-fire      955\nName: label, dtype: int64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:42.274982270Z",
     "start_time": "2023-05-15T23:34:42.244973909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "convert_text_labels = lambda x: 0 if x in ['true', 'mostly-true'] else 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:42.539052880Z",
     "start_time": "2023-05-15T23:34:42.518871674Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train['label'] = train['label'].apply(convert_text_labels)\n",
    "test['label'] = test['label'].apply(convert_text_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:42.902356033Z",
     "start_time": "2023-05-15T23:34:42.862577417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "1    7466\n0    4058\nName: label, dtype: int64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:43.241803884Z",
     "start_time": "2023-05-15T23:34:43.216864309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(train['label'].value_counts().index, train['label'].value_counts().values)\n",
    "\n",
    "plt.xticks(train['label'].value_counts().index)\n",
    "\n",
    "plt.title('Train')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:43.840692315Z",
     "start_time": "2023-05-15T23:34:43.749701048Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "1    818\n0    449\nName: label, dtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:44.358370793Z",
     "start_time": "2023-05-15T23:34:44.331447611Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtpUlEQVR4nO3dfXRU9Z3H8c+QJ5I0GUiCM8waIGJ8wESlASNplVhCKPIgskdKURcr7qLRaCosmtLWYDVRugSqqbj0oElFGrtnjXV9QIIIFdHdEKUStLYeeQiaGG3jTCJhAuHuHx7u7hBQCAN3+PF+nXPP4f7u9975/v4Y8jm/e2fGZVmWJQAAAEP1c7oBAACAk4mwAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADIKK5XK5j2jZs2HDCr7V3716VlZWF5VoAIke00w0AwNd58803Q/Z/8Ytf6LXXXtP69etDxkeMGHHCr7V3714tWrRIkpSfn3/C1wMQGQg7ACLa5ZdfHrI/aNAg9evXr9c4ABwNt7EAnPa6u7v1wAMP6IILLlBcXJwGDRqkH/3oR/rss89C6tavX6/8/HylpqYqPj5eQ4YM0T/+4z9q79692rlzpwYNGiRJWrRokX177KabbnJgRgDCiZUdAKe1gwcP6pprrtHrr7+uBQsWKC8vT7t27dJ9992n/Px8bdmyRfHx8dq5c6cmTZqkK664Qk888YQGDBigjz/+WGvWrFF3d7cGDx6sNWvW6Pvf/77mzJmjW265RZLsAATg9EXYAXBa+/3vf681a9boP//zPzV9+nR7/JJLLtHo0aNVXV2t2267TY2Njdq3b59++ctf6pJLLrHrZs2aZf87JydHknT22WdzmwwwCLexAJzWXnjhBQ0YMEBTpkzRgQMH7O3SSy+V1+u1P1l16aWXKjY2Vv/yL/+impoaffTRR842DuCUIewAOK19+umn+uKLLxQbG6uYmJiQrbW1VZ9//rkkafjw4Vq3bp3OOuss3X777Ro+fLiGDx+uX/3qVw7PAMDJxm0sAKe1tLQ0paamas2aNUc8npSUZP/7iiuu0BVXXKGenh5t2bJFjz76qEpKSuTxeDRz5sxT1TKAU4ywA+C0NnnyZNXW1qqnp0e5ubnHdE5UVJRyc3N1wQUX6Omnn9bbb7+tmTNnKi4uTpLU1dV1MlsGcIoRdgCc1mbOnKmnn35aV199te666y5ddtlliomJ0Z49e/Taa6/pmmuu0bXXXqvHH39c69ev16RJkzRkyBDt27dPTzzxhCSpoKBA0lerQEOHDtUf/vAHjRs3TikpKUpLS9OwYcMcnCGAE8UzOwBOa1FRUXr++ef1k5/8RM8++6yuvfZaTZs2TQ899JD69++v7OxsSV89oHzgwAHdd999mjhxom688UZ99tlnev7551VYWGhfb+XKlUpISNDUqVM1evRolZWVOTQzAOHisizLcroJAACAk4WVHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAo/GlgpIOHjyoTz75RElJSXK5XE63AwAAjoFlWero6JDP51O/fkdfvyHsSPrkk0+Unp7udBsAAKAPmpubdfbZZx/1OGFH//dDgc3NzUpOTna4GwAAcCwCgYDS09NDfvD3SAg7kn3rKjk5mbADAMBp5pseQeEBZQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRop1uAABMMOzeF51uAYhYOx+a5Ojrs7IDAACMRtgBAABGczTsHDhwQD/96U+VkZGh+Ph4nXPOObr//vt18OBBu8ayLJWVlcnn8yk+Pl75+fnavn17yHWCwaCKi4uVlpamxMRETZ06VXv27DnV0wEAABHI0bDz8MMP6/HHH1dVVZXef/99LV68WL/85S/16KOP2jWLFy9WZWWlqqqq1NDQIK/Xq/Hjx6ujo8OuKSkpUV1dnWpra7Vp0yZ1dnZq8uTJ6unpcWJaAAAggjj6gPKbb76pa665RpMmffXg0rBhw/S73/1OW7ZskfTVqs6yZcu0cOFCTZ8+XZJUU1Mjj8ej1atXa+7cufL7/Vq5cqWeeuopFRQUSJJWrVql9PR0rVu3ThMmTHBmcgAAICI4urLz3e9+V6+++qr+8pe/SJL+9Kc/adOmTbr66qslSTt27FBra6sKCwvtc+Li4jR27Fht3rxZktTY2Kj9+/eH1Ph8PmVlZdk1hwsGgwoEAiEbAAAwk6MrO/fcc4/8fr8uuOACRUVFqaenRw8++KB++MMfSpJaW1slSR6PJ+Q8j8ejXbt22TWxsbEaOHBgr5pD5x+uoqJCixYtCvd0AABABHJ0ZeeZZ57RqlWrtHr1ar399tuqqanRv/3bv6mmpiakzuVyhexbltVr7HBfV1NaWiq/329vzc3NJzYRAAAQsRxd2fnXf/1X3XvvvZo5c6YkKTs7W7t27VJFRYVmz54tr9cr6avVm8GDB9vntbW12as9Xq9X3d3dam9vD1ndaWtrU15e3hFfNy4uTnFxcSdrWgAAIII4urKzd+9e9esX2kJUVJT90fOMjAx5vV7V19fbx7u7u7Vx40Y7yOTk5CgmJiakpqWlRU1NTUcNOwAA4Mzh6MrOlClT9OCDD2rIkCG66KKL9M4776iyslI333yzpK9uX5WUlKi8vFyZmZnKzMxUeXm5EhISNGvWLEmS2+3WnDlzNG/ePKWmpiolJUXz589Xdna2/eksAABw5nI07Dz66KP62c9+pqKiIrW1tcnn82nu3Ln6+c9/btcsWLBAXV1dKioqUnt7u3Jzc7V27VolJSXZNUuXLlV0dLRmzJihrq4ujRs3TtXV1YqKinJiWgAAIIK4LMuynG7CaYFAQG63W36/X8nJyU63A+A0xA+BAkd3sn4I9Fj/fvPbWAAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0RwNO8OGDZPL5eq13X777ZIky7JUVlYmn8+n+Ph45efna/v27SHXCAaDKi4uVlpamhITEzV16lTt2bPHiekAAIAI5GjYaWhoUEtLi73V19dLkq677jpJ0uLFi1VZWamqqio1NDTI6/Vq/Pjx6ujosK9RUlKiuro61dbWatOmTers7NTkyZPV09PjyJwAAEBkcTTsDBo0SF6v195eeOEFDR8+XGPHjpVlWVq2bJkWLlyo6dOnKysrSzU1Ndq7d69Wr14tSfL7/Vq5cqWWLFmigoICjRw5UqtWrdK2bdu0bt06J6cGAAAiRMQ8s9Pd3a1Vq1bp5ptvlsvl0o4dO9Ta2qrCwkK7Ji4uTmPHjtXmzZslSY2Njdq/f39Ijc/nU1ZWll1zJMFgUIFAIGQDAABmipiw89xzz+mLL77QTTfdJElqbW2VJHk8npA6j8djH2ttbVVsbKwGDhx41JojqaiokNvttrf09PQwzgQAAESSiAk7K1eu1MSJE+Xz+ULGXS5XyL5lWb3GDvdNNaWlpfL7/fbW3Nzc98YBAEBEi4iws2vXLq1bt0633HKLPeb1eiWp1wpNW1ubvdrj9XrV3d2t9vb2o9YcSVxcnJKTk0M2AABgpogIO08++aTOOussTZo0yR7LyMiQ1+u1P6ElffVcz8aNG5WXlydJysnJUUxMTEhNS0uLmpqa7BoAAHBmi3a6gYMHD+rJJ5/U7NmzFR39f+24XC6VlJSovLxcmZmZyszMVHl5uRISEjRr1ixJktvt1pw5czRv3jylpqYqJSVF8+fPV3Z2tgoKCpyaEgAAiCCOh51169Zp9+7duvnmm3sdW7Bggbq6ulRUVKT29nbl5uZq7dq1SkpKsmuWLl2q6OhozZgxQ11dXRo3bpyqq6sVFRV1KqcBAAAilMuyLMvpJpwWCATkdrvl9/t5fgdAnwy790WnWwAi1s6HJn1zUR8c69/viHhmBwAA4GQh7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjOZ42Pn44491ww03KDU1VQkJCbr00kvV2NhoH7csS2VlZfL5fIqPj1d+fr62b98eco1gMKji4mKlpaUpMTFRU6dO1Z49e071VAAAQARyNOy0t7frO9/5jmJiYvTyyy/rvffe05IlSzRgwAC7ZvHixaqsrFRVVZUaGhrk9Xo1fvx4dXR02DUlJSWqq6tTbW2tNm3apM7OTk2ePFk9PT0OzAoAAEQSl2VZllMvfu+99+qNN97Q66+/fsTjlmXJ5/OppKRE99xzj6SvVnE8Ho8efvhhzZ07V36/X4MGDdJTTz2lH/zgB5KkTz75ROnp6XrppZc0YcKEb+wjEAjI7XbL7/crOTk5fBMEcMYYdu+LTrcARKydD006Kdc91r/fjq7sPP/88xo1apSuu+46nXXWWRo5cqR+85vf2Md37Nih1tZWFRYW2mNxcXEaO3asNm/eLElqbGzU/v37Q2p8Pp+ysrLsGgAAcOZyNOx89NFHWr58uTIzM/XKK6/o1ltv1Z133qnf/va3kqTW1lZJksfjCTnP4/HYx1pbWxUbG6uBAwceteZwwWBQgUAgZAMAAGaKdvLFDx48qFGjRqm8vFySNHLkSG3fvl3Lly/XP/3TP9l1Lpcr5DzLsnqNHe7raioqKrRo0aIT7B4AAJwOHF3ZGTx4sEaMGBEyduGFF2r37t2SJK/XK0m9Vmja2trs1R6v16vu7m61t7cfteZwpaWl8vv99tbc3ByW+QAAgMjjaNj5zne+ow8++CBk7C9/+YuGDh0qScrIyJDX61V9fb19vLu7Wxs3blReXp4kKScnRzExMSE1LS0tampqsmsOFxcXp+Tk5JANAACYydHbWD/+8Y+Vl5en8vJyzZgxQ//zP/+jFStWaMWKFZK+un1VUlKi8vJyZWZmKjMzU+Xl5UpISNCsWbMkSW63W3PmzNG8efOUmpqqlJQUzZ8/X9nZ2SooKHByegAAIAI4GnZGjx6turo6lZaW6v7771dGRoaWLVum66+/3q5ZsGCBurq6VFRUpPb2duXm5mrt2rVKSkqya5YuXaro6GjNmDFDXV1dGjdunKqrqxUVFeXEtAAAQARx9Ht2IgXfswPgRPE9O8DRndHfswMAAHCyEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEZzNOyUlZXJ5XKFbF6v1z5uWZbKysrk8/kUHx+v/Px8bd++PeQawWBQxcXFSktLU2JioqZOnao9e/ac6qkAAIAI5fjKzkUXXaSWlhZ727Ztm31s8eLFqqysVFVVlRoaGuT1ejV+/Hh1dHTYNSUlJaqrq1Ntba02bdqkzs5OTZ48WT09PU5MBwAARJhoxxuIjg5ZzTnEsiwtW7ZMCxcu1PTp0yVJNTU18ng8Wr16tebOnSu/36+VK1fqqaeeUkFBgSRp1apVSk9P17p16zRhwoRTOhcAABB5HF/Z+etf/yqfz6eMjAzNnDlTH330kSRpx44dam1tVWFhoV0bFxensWPHavPmzZKkxsZG7d+/P6TG5/MpKyvLrgEAAGc2R1d2cnNz9dvf/lbnnXeePv30Uz3wwAPKy8vT9u3b1draKknyeDwh53g8Hu3atUuS1NraqtjYWA0cOLBXzaHzjyQYDCoYDNr7gUAgXFMCAAARxtGwM3HiRPvf2dnZGjNmjIYPH66amhpdfvnlkiSXyxVyjmVZvcYO9001FRUVWrRo0Ql0DgAATheO38b6/xITE5Wdna2//vWv9nM8h6/QtLW12as9Xq9X3d3dam9vP2rNkZSWlsrv99tbc3NzmGcCAAAiRUSFnWAwqPfff1+DBw9WRkaGvF6v6uvr7ePd3d3auHGj8vLyJEk5OTmKiYkJqWlpaVFTU5NdcyRxcXFKTk4O2QAAgJkcvY01f/58TZkyRUOGDFFbW5seeOABBQIBzZ49Wy6XSyUlJSovL1dmZqYyMzNVXl6uhIQEzZo1S5Lkdrs1Z84czZs3T6mpqUpJSdH8+fOVnZ1tfzoLAACc2RwNO3v27NEPf/hDff755xo0aJAuv/xyvfXWWxo6dKgkacGCBerq6lJRUZHa29uVm5urtWvXKikpyb7G0qVLFR0drRkzZqirq0vjxo1TdXW1oqKinJoWAACIIC7Lsiynm3BaIBCQ2+2W3+/nlhaAPhl274tOtwBErJ0PTTop1z3Wv98R9cwOAABAuBF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYrU9h55xzztHf/va3XuNffPGFzjnnnBNuCgAAIFz6FHZ27typnp6eXuPBYFAff/zxCTcFAAAQLsf1DcrPP/+8/e9XXnlFbrfb3u/p6dGrr76qYcOGha05AACAE3VcYWfatGmSJJfLpdmzZ4cci4mJ0bBhw7RkyZKwNQcAAHCijivsHDx4UJKUkZGhhoYGpaWlnZSmAAAAwqVPPwS6Y8eOcPcBAABwUvT5V89fffVVvfrqq2pra7NXfA554oknTrgxAACAcOhT2Fm0aJHuv/9+jRo1SoMHD5bL5Qp3XwAAAGHRp7Dz+OOPq7q6WjfeeGO4+wEAAAirPn3PTnd3t/Ly8sLdCwAAQNj1aWXnlltu0erVq/Wzn/0s3P0YZ9i9LzrdAhDRdj40yekWABiuT2Fn3759WrFihdatW6eLL75YMTExIccrKyvD0hwAAMCJ6lPYeffdd3XppZdKkpqamkKO8bAyAACIJH0KO6+99lq4+wAAADgp+vSAMgAAwOmiTys7V1111dferlq/fn2fGwIAAAinPoWdQ8/rHLJ//35t3bpVTU1NvX4gFAAAwEl9CjtLly494nhZWZk6OztPqCEAAIBwCuszOzfccAO/iwUAACJKWMPOm2++qf79+4fzkgAAACekT7expk+fHrJvWZZaWlq0ZcsWvlUZAABElD6FHbfbHbLfr18/nX/++br//vtVWFgYlsYAAADCoU9h58knnwx3HwAAACdFn8LOIY2NjXr//fflcrk0YsQIjRw5Mlx9AQAAhEWfwk5bW5tmzpypDRs2aMCAAbIsS36/X1dddZVqa2s1aNCgcPcJAADQJ336NFZxcbECgYC2b9+uv//972pvb1dTU5MCgYDuvPPOcPcIAADQZ30KO2vWrNHy5ct14YUX2mMjRozQr3/9a7388st9aqSiokIul0slJSX2mGVZKisrk8/nU3x8vPLz87V9+/aQ84LBoIqLi5WWlqbExERNnTpVe/bs6VMPAADAPH0KOwcPHlRMTEyv8ZiYGB08ePC4r9fQ0KAVK1bo4osvDhlfvHixKisrVVVVpYaGBnm9Xo0fP14dHR12TUlJierq6lRbW6tNmzaps7NTkydPVk9Pz/FPDAAAGKdPYed73/ue7rrrLn3yySf22Mcff6wf//jHGjdu3HFdq7OzU9dff71+85vfaODAgfa4ZVlatmyZFi5cqOnTpysrK0s1NTXau3evVq9eLUny+/1auXKllixZooKCAo0cOVKrVq3Stm3btG7dur5MDQAAGKZPYaeqqkodHR0aNmyYhg8frnPPPVcZGRnq6OjQo48+elzXuv322zVp0iQVFBSEjO/YsUOtra0h39sTFxensWPHavPmzZK++jTY/v37Q2p8Pp+ysrLsGgAAcGbr06ex0tPT9fbbb6u+vl5//vOfZVmWRowY0SuwfJPa2lq9/fbbamho6HWstbVVkuTxeELGPR6Pdu3aZdfExsaGrAgdqjl0/pEEg0EFg0F7PxAIHFffAADg9HFcKzvr16/XiBEj7HAwfvx4FRcX684779To0aN10UUX6fXXXz+mazU3N+uuu+7SqlWrvvb3tFwuV8i+ZVm9xg73TTUVFRVyu932lp6efkw9AwCA089xhZ1ly5bpn//5n5WcnNzrmNvt1ty5c1VZWXlM12psbFRbW5tycnIUHR2t6Ohobdy4UY888oiio6PtFZ3DV2ja2trsY16vV93d3Wpvbz9qzZGUlpbK7/fbW3Nz8zH1DAAATj/HFXb+9Kc/6fvf//5RjxcWFqqxsfGYrjVu3Dht27ZNW7dutbdRo0bp+uuv19atW3XOOefI6/Wqvr7ePqe7u1sbN25UXl6eJCknJ0cxMTEhNS0tLWpqarJrjiQuLk7JyckhGwAAMNNxPbPz6aefHvEj5/bFoqP12WefHdO1kpKSlJWVFTKWmJio1NRUe7ykpETl5eXKzMxUZmamysvLlZCQoFmzZkn6ajVpzpw5mjdvnlJTU5WSkqL58+crOzv7uJ8fAgAAZjqusPMP//AP2rZtm84999wjHn/33Xc1ePDgsDQmSQsWLFBXV5eKiorU3t6u3NxcrV27VklJSXbN0qVLFR0drRkzZqirq0vjxo1TdXW1oqKiwtYHAAA4fbksy7KOtbi4uFgbNmxQQ0NDr4eKu7q6dNlll+mqq67SI488EvZGT6ZAICC32y2/3x/2W1rD7n0xrNcDTLPzoUlOtxAWvNeBoztZ7/Nj/ft9XCs7P/3pT/Xss8/qvPPO0x133KHzzz9fLpdL77//vn7961+rp6dHCxcuPOHmAQAAwuW4wo7H49HmzZt12223qbS0VIcWhVwulyZMmKDHHnvsaz8FBQAAcKod95cKDh06VC+99JLa29v14YcfyrIsZWZm9vpiPwAAgEjQp29QlqSBAwdq9OjR4ewFAAAg7Pr021gAAACnC8IOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACM5mjYWb58uS6++GIlJycrOTlZY8aM0csvv2wftyxLZWVl8vl8io+PV35+vrZv3x5yjWAwqOLiYqWlpSkxMVFTp07Vnj17TvVUAABAhHI07Jx99tl66KGHtGXLFm3ZskXf+973dM0119iBZvHixaqsrFRVVZUaGhrk9Xo1fvx4dXR02NcoKSlRXV2damtrtWnTJnV2dmry5Mnq6elxaloAACCCOBp2pkyZoquvvlrnnXeezjvvPD344IP61re+pbfeekuWZWnZsmVauHChpk+frqysLNXU1Gjv3r1avXq1JMnv92vlypVasmSJCgoKNHLkSK1atUrbtm3TunXrnJwaAACIEBHzzE5PT49qa2v15ZdfasyYMdqxY4daW1tVWFho18TFxWns2LHavHmzJKmxsVH79+8PqfH5fMrKyrJrAADAmS3a6Qa2bdumMWPGaN++ffrWt76luro6jRgxwg4rHo8npN7j8WjXrl2SpNbWVsXGxmrgwIG9alpbW4/6msFgUMFg0N4PBALhmg4AAIgwjq/snH/++dq6daveeust3XbbbZo9e7bee+89+7jL5Qqptyyr19jhvqmmoqJCbrfb3tLT009sEgAAIGI5HnZiY2N17rnnatSoUaqoqNAll1yiX/3qV/J6vZLUa4Wmra3NXu3xer3q7u5We3v7UWuOpLS0VH6/396am5vDPCsAABApHA87h7MsS8FgUBkZGfJ6vaqvr7ePdXd3a+PGjcrLy5Mk5eTkKCYmJqSmpaVFTU1Nds2RxMXF2R93P7QBAAAzOfrMzk9+8hNNnDhR6enp6ujoUG1trTZs2KA1a9bI5XKppKRE5eXlyszMVGZmpsrLy5WQkKBZs2ZJktxut+bMmaN58+YpNTVVKSkpmj9/vrKzs1VQUODk1AAAQIRwNOx8+umnuvHGG9XS0iK3262LL75Ya9as0fjx4yVJCxYsUFdXl4qKitTe3q7c3FytXbtWSUlJ9jWWLl2q6OhozZgxQ11dXRo3bpyqq6sVFRXl1LQAAEAEcVmWZTndhNMCgYDcbrf8fn/Yb2kNu/fFsF4PMM3OhyY53UJY8F4Hju5kvc+P9e93xD2zAwAAEE6EHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0RwNOxUVFRo9erSSkpJ01llnadq0afrggw9CaizLUllZmXw+n+Lj45Wfn6/t27eH1ASDQRUXFystLU2JiYmaOnWq9uzZcyqnAgAAIpSjYWfjxo26/fbb9dZbb6m+vl4HDhxQYWGhvvzyS7tm8eLFqqysVFVVlRoaGuT1ejV+/Hh1dHTYNSUlJaqrq1Ntba02bdqkzs5OTZ48WT09PU5MCwAARJBoJ198zZo1IftPPvmkzjrrLDU2NurKK6+UZVlatmyZFi5cqOnTp0uSampq5PF4tHr1as2dO1d+v18rV67UU089pYKCAknSqlWrlJ6ernXr1mnChAmnfF4AACByRNQzO36/X5KUkpIiSdqxY4daW1tVWFho18TFxWns2LHavHmzJKmxsVH79+8PqfH5fMrKyrJrAADAmcvRlZ3/z7Is3X333frud7+rrKwsSVJra6skyePxhNR6PB7t2rXLromNjdXAgQN71Rw6/3DBYFDBYNDeDwQCYZsHAACILBGzsnPHHXfo3Xff1e9+97tex1wuV8i+ZVm9xg73dTUVFRVyu932lp6e3vfGAQBARIuIsFNcXKznn39er732ms4++2x73Ov1SlKvFZq2tjZ7tcfr9aq7u1vt7e1HrTlcaWmp/H6/vTU3N4dzOgAAIII4GnYsy9Idd9yhZ599VuvXr1dGRkbI8YyMDHm9XtXX19tj3d3d2rhxo/Ly8iRJOTk5iomJCalpaWlRU1OTXXO4uLg4JScnh2wAAMBMjj6zc/vtt2v16tX6wx/+oKSkJHsFx+12Kz4+Xi6XSyUlJSovL1dmZqYyMzNVXl6uhIQEzZo1y66dM2eO5s2bp9TUVKWkpGj+/PnKzs62P50FAADOXI6GneXLl0uS8vPzQ8affPJJ3XTTTZKkBQsWqKurS0VFRWpvb1dubq7Wrl2rpKQku37p0qWKjo7WjBkz1NXVpXHjxqm6ulpRUVGnaioAACBCuSzLspxuwmmBQEBut1t+vz/st7SG3ftiWK8HmGbnQ5OcbiEseK8DR3ey3ufH+vc7Ih5QBgAAOFkIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAozkadv74xz9qypQp8vl8crlceu6550KOW5alsrIy+Xw+xcfHKz8/X9u3bw+pCQaDKi4uVlpamhITEzV16lTt2bPnFM4CAABEMkfDzpdffqlLLrlEVVVVRzy+ePFiVVZWqqqqSg0NDfJ6vRo/frw6OjrsmpKSEtXV1am2tlabNm1SZ2enJk+erJ6enlM1DQAAEMGinXzxiRMnauLEiUc8ZlmWli1bpoULF2r69OmSpJqaGnk8Hq1evVpz586V3+/XypUr9dRTT6mgoECStGrVKqWnp2vdunWaMGHCKZsLAACITBH7zM6OHTvU2tqqwsJCeywuLk5jx47V5s2bJUmNjY3av39/SI3P51NWVpZdAwAAzmyOrux8ndbWVkmSx+MJGfd4PNq1a5ddExsbq4EDB/aqOXT+kQSDQQWDQXs/EAiEq20AABBhInZl5xCXyxWyb1lWr7HDfVNNRUWF3G63vaWnp4elVwAAEHkiNux4vV5J6rVC09bWZq/2eL1edXd3q729/ag1R1JaWiq/329vzc3NYe4eAABEiogNOxkZGfJ6vaqvr7fHuru7tXHjRuXl5UmScnJyFBMTE1LT0tKipqYmu+ZI4uLilJycHLIBAAAzOfrMTmdnpz788EN7f8eOHdq6datSUlI0ZMgQlZSUqLy8XJmZmcrMzFR5ebkSEhI0a9YsSZLb7dacOXM0b948paamKiUlRfPnz1d2drb96SwAAHBmczTsbNmyRVdddZW9f/fdd0uSZs+ererqai1YsEBdXV0qKipSe3u7cnNztXbtWiUlJdnnLF26VNHR0ZoxY4a6uro0btw4VVdXKyoq6pTPBwAARB6XZVmW0004LRAIyO12y+/3h/2W1rB7Xwzr9QDT7HxoktMthAXvdeDoTtb7/Fj/fkfsMzsAAADhQNgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABjNmLDz2GOPKSMjQ/3791dOTo5ef/11p1sCAAARwIiw88wzz6ikpEQLFy7UO++8oyuuuEITJ07U7t27nW4NAAA4zIiwU1lZqTlz5uiWW27RhRdeqGXLlik9PV3Lly93ujUAAOCw0z7sdHd3q7GxUYWFhSHjhYWF2rx5s0NdAQCASBHtdAMn6vPPP1dPT488Hk/IuMfjUWtr6xHPCQaDCgaD9r7f75ckBQKBsPd3MLg37NcETHIy3ndO4L0OHN3Jep8fuq5lWV9bd9qHnUNcLlfIvmVZvcYOqaio0KJFi3qNp6enn5TeAByde5nTHQA42U72+7yjo0Nut/uox0/7sJOWlqaoqKheqzhtbW29VnsOKS0t1d13323vHzx4UH//+9+Vmpp61IAEMwQCAaWnp6u5uVnJyclOtwPgJOB9fuawLEsdHR3y+XxfW3fah53Y2Fjl5OSovr5e1157rT1eX1+va6655ojnxMXFKS4uLmRswIABJ7NNRJjk5GT+EwQMx/v8zPB1KzqHnPZhR5Luvvtu3XjjjRo1apTGjBmjFStWaPfu3br11ludbg0AADjMiLDzgx/8QH/72990//33q6WlRVlZWXrppZc0dOhQp1sDAAAOMyLsSFJRUZGKioqcbgMRLi4uTvfdd1+v25gAzMH7HIdzWd/0eS0AAIDT2Gn/pYIAAABfh7ADAACMRtgBAABGI+wAAACjEXZwxnjssceUkZGh/v37KycnR6+//rrTLQEIoz/+8Y+aMmWKfD6fXC6XnnvuOadbQoQg7OCM8Mwzz6ikpEQLFy7UO++8oyuuuEITJ07U7t27nW4NQJh8+eWXuuSSS1RVVeV0K4gwfPQcZ4Tc3Fx9+9vf1vLly+2xCy+8UNOmTVNFRYWDnQE4GVwul+rq6jRt2jSnW0EEYGUHxuvu7lZjY6MKCwtDxgsLC7V582aHugIAnCqEHRjv888/V09PjzweT8i4x+NRa2urQ10BAE4Vwg7OGC6XK2TfsqxeYwAA8xB2YLy0tDRFRUX1WsVpa2vrtdoDADAPYQfGi42NVU5Ojurr60PG6+vrlZeX51BXAIBTxZhfPQe+zt13360bb7xRo0aN0pgxY7RixQrt3r1bt956q9OtAQiTzs5Offjhh/b+jh07tHXrVqWkpGjIkCEOdgan8dFznDEee+wxLV68WC0tLcrKytLSpUt15ZVXOt0WgDDZsGGDrrrqql7js2fPVnV19alvCBGDsAMAAIzGMzsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAYqbq6WgMGDDjh67hcLj333HMnfB0AziHsAIhYN910k6ZNm+Z0GwBOc4QdAABgNMIOgNNSZWWlsrOzlZiYqPT0dBUVFamzs7NX3XPPPafzzjtP/fv31/jx49Xc3Bxy/L/+67+Uk5Oj/v3765xzztGiRYt04MCBUzUNAKcAYQfAaalfv3565JFH1NTUpJqaGq1fv14LFiwIqdm7d68efPBB1dTU6I033lAgENDMmTPt46+88opuuOEG3XnnnXrvvff07//+76qurtaDDz54qqcD4CTih0ABRKybbrpJX3zxxTE9IPwf//Efuu222/T5559L+uoB5R/96Ed66623lJubK0n685//rAsvvFD//d//rcsuu0xXXnmlJk6cqNLSUvs6q1at0oIFC/TJJ59I+uoB5bq6Op4dAk5j0U43AAB98dprr6m8vFzvvfeeAoGADhw4oH379unLL79UYmKiJCk6OlqjRo2yz7ngggs0YMAAvf/++7rsssvU2NiohoaGkJWcnp4e7du3T3v37lVCQsIpnxeA8CPsADjt7Nq1S1dffbVuvfVW/eIXv1BKSoo2bdqkOXPmaP/+/SG1Lper1/mHxg4ePKhFixZp+vTpvWr69+9/cpoHcMoRdgCcdrZs2aIDBw5oyZIl6tfvq0cPf//73/eqO3DggLZs2aLLLrtMkvTBBx/oiy++0AUXXCBJ+va3v60PPvhA55577qlrHsApR9gBENH8fr+2bt0aMjZo0CAdOHBAjz76qKZMmaI33nhDjz/+eK9zY2JiVFxcrEceeUQxMTG64447dPnll9vh5+c//7kmT56s9PR0XXfdderXr5/effddbdu2TQ888MCpmB6AU4BPYwGIaBs2bNDIkSNDtieeeEKVlZV6+OGHlZWVpaeffloVFRW9zk1ISNA999yjWbNmacyYMYqPj1dtba19fMKECXrhhRdUX1+v0aNH6/LLL1dlZaWGDh16KqcI4CTj01gAAMBorOwAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYLT/BdaoMgijCwRwAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(test['label'].value_counts().index, test['label'].value_counts().values)\n",
    "\n",
    "plt.xticks(test['label'].value_counts().index)\n",
    "\n",
    "plt.title('Test')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:44.884578684Z",
     "start_time": "2023-05-15T23:34:44.718052068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "count    11524.000000\nmean       106.895783\nstd         58.415051\nmin         11.000000\n25%         73.000000\n50%         99.000000\n75%        133.000000\nmax       3192.000000\nName: text, dtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].str.len().describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:45.121208265Z",
     "start_time": "2023-05-15T23:34:45.086760263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "count    1267.000000\nmean      109.578532\nstd        98.031030\nmin        12.000000\n25%        74.000000\n50%        98.000000\n75%       133.000000\nmax      2941.000000\nName: text, dtype: float64"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].str.len().describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:46.110029417Z",
     "start_time": "2023-05-15T23:34:46.076488619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaFYAFhluSCU",
    "outputId": "cf3c01ae-ba06-4501-d53b-8926d079f411",
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:46.865480184Z",
     "start_time": "2023-05-15T23:34:46.846763528Z"
    }
   },
   "outputs": [],
   "source": [
    "# # OLD data\n",
    "# fake = pd.read_csv('../../data/Fake.csv')\n",
    "# true = pd.read_csv('../../data/True.csv')\n",
    "#\n",
    "# fake[\"label\"] = 0\n",
    "# true[\"label\"] = 1\n",
    "#\n",
    "# df = pd.concat([fake, true], ignore_index = True)\n",
    "#\n",
    "# df['text'] = df['title'] + \" \" + df['text']\n",
    "# df.drop(columns=['title', 'date', 'subject'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieOrxB_AuTwA",
    "outputId": "f5f4e1d6-b001-4dab-b81f-7b08125dcdfc",
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:49.295602473Z",
     "start_time": "2023-05-15T23:34:48.213305128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/szymon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 846 ms, sys: 15.1 ms, total: 861 ms\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "    \n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "train['text']=train['text'].apply(denoise_text)\n",
    "test['text']=test['text'].apply(denoise_text)\n",
    "\n",
    "train.to_csv(\"../../data/train.csv\", index=False)\n",
    "test.to_csv(\"../../data/test.csv\", index=False)\n",
    "\n",
    "\n",
    "X_train = train['text'].tolist()\n",
    "y_train = train['label'].tolist()\n",
    "with open(\"../../data/X_train\", \"wb\") as fp:\n",
    "    pickle.dump(X_train, fp)\n",
    "with open(\"../../data/y_train\", \"wb\") as fp:\n",
    "    pickle.dump(y_train, fp)\n",
    "\n",
    "X_test = test['text'].tolist()\n",
    "y_test = test['label'].tolist()\n",
    "with open(\"../../data/X_test\", \"wb\") as fp:\n",
    "    pickle.dump(X_test, fp)\n",
    "with open(\"../../data/y_test\", \"wb\") as fp:\n",
    "    pickle.dump(y_test, fp)\n",
    "\n",
    "\n",
    "train_small = train.sample(frac=1).reset_index(drop=True)[:1000]\n",
    "train_small.to_csv(\"../../data/train_small.csv\", index=False)\n",
    "\n",
    "X_train_small = train_small['text'].tolist()\n",
    "y_train_small = train_small['label'].tolist()\n",
    "with open(\"../../data/small/X_train\", \"wb\") as fp:\n",
    "    pickle.dump(X_train_small, fp)\n",
    "with open(\"../../data/small/y_train\", \"wb\") as fp:\n",
    "    pickle.dump(y_train_small, fp)\n",
    "with open(\"../../data/small/X_test\", \"wb\") as fp:\n",
    "    pickle.dump(X_test, fp)\n",
    "with open(\"../../data/small/y_test\", \"wb\") as fp:\n",
    "    pickle.dump(y_test, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQMXCPQ97YRZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIG7v_fk7jbE"
   },
   "source": [
    "Reduce dataset for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3OAKnGLyuVS0",
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:50.461705265Z",
     "start_time": "2023-05-15T23:34:50.448253114Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_original = df.copy()\n",
    "# df = df.sample(frac=1).reset_index(drop=True)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA_tL8Sg7VWO"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-lrFVWwGiwt"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:57.119176954Z",
     "start_time": "2023-05-15T23:34:57.100823917Z"
    }
   },
   "outputs": [],
   "source": [
    "redo_embedding = False # recalculate embeddings\n",
    "fast = True # True if use reduced dataset (1000 obs) vs. False if full dataset (40000 obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:34:57.624687728Z",
     "start_time": "2023-05-15T23:34:57.573598628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 ms, sys: 205 µs, total: 1.79 ms\n",
      "Wall time: 1.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load data\n",
    "\n",
    "# OLD approach ------------------------\n",
    "# if fast:\n",
    "#     df_original = df.copy()\n",
    "#     df = df.sample(frac=1).reset_index(drop=True)[:1000]\n",
    "#\n",
    "# if redo_embedding:\n",
    "#     X = df['text'].tolist()\n",
    "#     y = df['label'].tolist()\n",
    "#\n",
    "#     with open(\"X\", \"wb\") as fp:\n",
    "#       pickle.dump(X, fp)\n",
    "#     with open(\"y\", \"wb\") as fp:\n",
    "#       pickle.dump(y, fp)\n",
    "# elif fast:\n",
    "#     with open(\"../../data/small/X\", \"rb\") as fp:\n",
    "#       X = pickle.load(fp)\n",
    "#     with open(\"../../data/small/y\", \"rb\") as fp:\n",
    "#       y = pickle.load(fp)\n",
    "# else:\n",
    "#     with open(\"../../data/X\", \"rb\") as fp:\n",
    "#       X = pickle.load(fp)\n",
    "#     with open(\"../../data/y\", \"rb\") as fp:\n",
    "#       y = pickle.load(fp)\n",
    "#\n",
    "# if redo_embedding:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#     with open(\"X_train\", \"wb\") as fp:\n",
    "#       pickle.dump(X_train, fp)\n",
    "#     with open(\"X_test\", \"wb\") as fp:\n",
    "#       pickle.dump(X_test, fp)\n",
    "#     with open(\"y_train\", \"wb\") as fp:\n",
    "#       pickle.dump(y_train, fp)\n",
    "#     with open(\"y_test\", \"wb\") as fp:\n",
    "#       pickle.dump(y_test, fp)\n",
    "# elif fast:\n",
    "#     with open(\"../../data/small/X_train\", \"rb\") as fp:\n",
    "#       X_train = pickle.load(fp)\n",
    "#     with open(\"../../data/small/X_test\", \"rb\") as fp:\n",
    "#       X_test = pickle.load(fp)\n",
    "#     with open(\"../../data/small/y_train\", \"rb\") as fp:\n",
    "#       y_train = pickle.load(fp)\n",
    "#     with open(\"../../data/small/y_test\", \"rb\") as fp:\n",
    "#       y_test = pickle.load(fp)\n",
    "# else:\n",
    "#     with open(\"../../data/X_train\", \"rb\") as fp:\n",
    "#       X_train = pickle.load(fp)\n",
    "#     with open(\"../../data/X_test\", \"rb\") as fp:\n",
    "#       X_test = pickle.load(fp)\n",
    "#     with open(\"../../data/y_train\", \"rb\") as fp:\n",
    "#       y_train = pickle.load(fp)\n",
    "#     with open(\"../../data/y_test\", \"rb\") as fp:\n",
    "#       y_test = pickle.load(fp)\n",
    "\n",
    "\n",
    "# NEW approach ------------------------\n",
    "if fast:\n",
    "    with open(\"../../data/small/X_train\", \"rb\") as fp:\n",
    "      X_train = pickle.load(fp)\n",
    "    with open(\"../../data/small/X_test\", \"rb\") as fp:\n",
    "      X_test = pickle.load(fp)\n",
    "    with open(\"../../data/small/y_train\", \"rb\") as fp:\n",
    "      y_train = pickle.load(fp)\n",
    "    with open(\"../../data/small/y_test\", \"rb\") as fp:\n",
    "      y_test = pickle.load(fp)\n",
    "else:\n",
    "    with open(\"../../data/X_train\", \"rb\") as fp:\n",
    "      X_train = pickle.load(fp)\n",
    "    with open(\"../../data/X_test\", \"rb\") as fp:\n",
    "      X_test = pickle.load(fp)\n",
    "    with open(\"../../data/y_train\", \"rb\") as fp:\n",
    "      y_train = pickle.load(fp)\n",
    "    with open(\"../../data/y_test\", \"rb\") as fp:\n",
    "      y_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqQEmeGREcUg"
   },
   "source": [
    "## BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbSRaebguY2a",
    "outputId": "a3fc1906-e2a4-4a92-8d1c-a656f2fdd828",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T23:35:00.406872664Z",
     "start_time": "2023-05-15T23:35:00.187131319Z"
    }
   },
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert = AutoModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bert.to(device)\n",
    "\n",
    "    def _get_bert_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512)\n",
    "        input_ids = np.array(input_ids)\n",
    "        input_ids = np.expand_dims(input_ids, axis=0)\n",
    "        input_ids = torch.tensor(input_ids).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert(input_ids)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        return last_hidden_state\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_bert_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_bert = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_bert_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_bert = np.squeeze(X_test_embeddings, axis=1)\n",
    "    \n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_bert).to_csv(\"../../data/small/embeddings/X_train_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_bert).to_csv(\"../../data/small/embeddings/X_test_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_bert).to_csv(\"../../data/embeddings/X_train_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_bert).to_csv(\"../../data/embeddings/X_test_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    \n",
    "elif fast:\n",
    "    X_train_embeddings_bert = pd.read_csv('../../data/small/embeddings/X_train_embeddings_bert.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_bert = pd.read_csv('../../data/small/embeddings/X_test_embeddings_bert.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_bert = pd.read_csv('../../data/embeddings/X_train_embeddings_bert.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_bert = pd.read_csv('../../data/embeddings/X_test_embeddings_bert.csv', sep=',', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhGA1YV7GaKD"
   },
   "source": [
    "## GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:35:02.457320524Z",
     "start_time": "2023-05-15T23:35:02.343533513Z"
    }
   },
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "\n",
    "    def load_glove_embeddings(filename):\n",
    "        embeddings_index = {}\n",
    "        with open(filename) as f:\n",
    "            for line in tqdm(f):\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                if len(values[1:]) == 300:\n",
    "                    coefs = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings_index[word] = coefs\n",
    "        return embeddings_index\n",
    "\n",
    "    glove_embeddings = load_glove_embeddings('../../glove/glove.840B.300d.txt')\n",
    "\n",
    "    def text_to_glove_embeddings(text, embeddings_index, embedding_dim):\n",
    "        embeddings = []\n",
    "        for sentence in text:\n",
    "            sentence_embeddings = []\n",
    "            for word in sentence.split():\n",
    "                if word in embeddings_index:\n",
    "                    sentence_embeddings.append(embeddings_index[word])\n",
    "            if len(sentence_embeddings) > 0:\n",
    "                embeddings.append(np.mean(sentence_embeddings, axis=0))\n",
    "            else:\n",
    "                embeddings.append(np.zeros(embedding_dim))\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    X_train_embeddings_glove = text_to_glove_embeddings(X_train, glove_embeddings, embedding_dim=300)\n",
    "    X_test_embeddings_glove = text_to_glove_embeddings(X_test, glove_embeddings, embedding_dim=300)\n",
    "    \n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_glove).to_csv(\"../../data/small/embeddings/X_train_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_glove).to_csv(\"../../data/small/embeddings/X_test_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_glove).to_csv(\"../../data/embeddings/X_train_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_glove).to_csv(\"../../data/embeddings/X_test_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_glove = pd.read_csv('../../data/small/embeddings/X_train_embeddings_glove.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_glove = pd.read_csv('../../data/small/embeddings/X_test_embeddings_glove.csv', sep=',', header=None).values\n",
    "\n",
    "else:\n",
    "    X_train_embeddings_glove = pd.read_csv('../../data/embeddings/X_train_embeddings_glove.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_glove = pd.read_csv('../../data/embeddings/X_test_embeddings_glove.csv', sep=',', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('../../word2vec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "def get_word2vec_embeddings(text):\n",
    "    embeddings = []\n",
    "    for sentence in tqdm(text):\n",
    "        tokens = sentence.split()\n",
    "        doc_vecs = [model[token] for token in tokens if token in model.key_to_index]\n",
    "        if len(doc_vecs) > 0:\n",
    "            doc_vec = np.mean(doc_vecs, axis=0)\n",
    "            embeddings.append(doc_vec)\n",
    "        else:\n",
    "            embeddings.append([0] * 300) # if vocabulary does not exist in Word2Vec append a vector of zeros\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "if redo_embedding:\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    X_train_embeddings_word2vec = get_word2vec_embeddings(X_train)\n",
    "    X_test_embeddings_word2vec = get_word2vec_embeddings(X_test)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_word2vec).to_csv(\"../../data/small/embeddings/X_train_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_word2vec).to_csv(\"../../data/small/embeddings/X_test_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_word2vec).to_csv(\"../../data/embeddings/X_train_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_word2vec).to_csv(\"../../data/embeddings/X_test_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_word2vec = pd.read_csv('../../data/small/embeddings/X_train_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_word2vec = pd.read_csv('../../data/small/embeddings/X_test_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "\n",
    "else:\n",
    "    X_train_embeddings_word2vec = pd.read_csv('../../data/embeddings/X_train_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_word2vec = pd.read_csv('../../data/embeddings/X_test_embeddings_word2vec.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:35:04.009353580Z",
     "start_time": "2023-05-15T23:35:03.852424887Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gpt2.to(device)\n",
    "\n",
    "    def _get_gpt2_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=1024)\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = gpt2.transformer.wte(input_ids)\n",
    "            mean_embedding = embeddings.mean(dim=1)\n",
    "        #     outputs = bert(input_ids)\n",
    "        #     last_hidden_state = outputs.last_hidden_state\n",
    "        #     last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "            #vector = gpt2.transformer.wte.weight[input_ids,:]\n",
    "        mean_embedding = mean_embedding.cpu().numpy()\n",
    "        return mean_embedding\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_gpt2_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_gpt2 = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_gpt2_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_gpt2 = np.squeeze(X_test_embeddings, axis=1)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_gpt2).to_csv(\"../../data/small/embeddings/X_train_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_gpt2).to_csv(\"../../data/small/embeddings/X_test_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_gpt2).to_csv(\"../../data/embeddings/X_train_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_gpt2).to_csv(\"../../data/embeddings/X_test_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_gpt2 = pd.read_csv('../../data/small/embeddings/X_train_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_gpt2 = pd.read_csv('../../data/small/embeddings/X_test_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_gpt2 = pd.read_csv('../../data/embeddings/X_train_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_gpt2 = pd.read_csv('../../data/embeddings/X_test_embeddings_gpt2.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:35:04.800124344Z",
     "start_time": "2023-05-15T23:35:04.546123849Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    roberta = AutoModel.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    roberta.to(device)\n",
    "\n",
    "    def _get_roberta_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512)\n",
    "        input_ids = np.array(input_ids)\n",
    "        input_ids = np.expand_dims(input_ids, axis=0)\n",
    "        input_ids = torch.tensor(input_ids).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = roberta(input_ids)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        return last_hidden_state\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_roberta_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_roberta = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_roberta_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_roberta = np.squeeze(X_test_embeddings, axis=1)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_roberta).to_csv(\"../../data/small/embeddings/X_train_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_roberta).to_csv(\"../../data/small/embeddings/X_test_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_roberta).to_csv(\"../../data/embeddings/X_train_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_roberta).to_csv(\"../../data/embeddings/X_test_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_roberta = pd.read_csv('../../data/small/embeddings/X_train_embeddings_roberta.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_roberta = pd.read_csv('../../data/small/embeddings/X_test_embeddings_roberta.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_roberta = pd.read_csv('../../data/embeddings/X_train_embeddings_roberta.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_roberta = pd.read_csv('../../data/embeddings/X_test_embeddings_roberta.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:35:05.409667826Z",
     "start_time": "2023-05-15T23:35:05.131990599Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMvpJtV-EiIo"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:56:43.631127930Z",
     "start_time": "2023-05-15T23:56:43.577709259Z"
    }
   },
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, n_neighbors=2, weights='uniform', metric='minkowski'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = KNeighborsClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.n_neighbors = random_search.best_params_['n_neighbors']\n",
    "        self.weights = random_search.best_params_['weights']\n",
    "        self.metric = random_search.best_params_['metric']\n",
    "\n",
    "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "        balanced_accuracy = round(balanced_accuracy_score(y_test, y_pred)*100,1)\n",
    "        auc = round(roc_auc_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "        print('Balanced accuracy:', f1, '\\n')\n",
    "        print('AUC Score:', auc, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1, balanced_accuracy, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:56:44.464420723Z",
     "start_time": "2023-05-15T23:56:44.381289561Z"
    }
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier:\n",
    "    def __init__(self, learning_rate=0.1, max_depth=5, min_child_weight=1, subsample=0.5, colsample_bytree=0.5, n_estimators=100, objective='req:squarederror'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.n_estimators = n_estimators\n",
    "        self.objective = objective\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = xgb.XGBClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.learning_rate = random_search.best_params_['learning_rate']\n",
    "        self.max_depth = random_search.best_params_['max_depth']\n",
    "        self.min_child_weight = random_search.best_params_['min_child_weight']\n",
    "        self.subsample = random_search.best_params_['subsample']\n",
    "        self.colsample_bytree = random_search.best_params_['colsample_bytree']\n",
    "        self.n_estimators = random_search.best_params_['n_estimators']\n",
    "        self.objective = random_search.best_params_['objective']\n",
    "\n",
    "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "        balanced_accuracy = round(balanced_accuracy_score(y_test, y_pred)*100,1)\n",
    "        auc = round(roc_auc_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "        print('Balanced accuracy:', f1, '\\n')\n",
    "        print('AUC Score:', auc, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1, balanced_accuracy, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:56:50.512780528Z",
     "start_time": "2023-05-15T23:56:50.425210599Z"
    }
   },
   "outputs": [],
   "source": [
    "class RFClassifier:\n",
    "    def __init__(self, n_estimators=100, max_features='sqrt', max_depth='none', bootstrap=True):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.bootstrap = bootstrap\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap, verbose=True)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = RandomForestClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.n_estimators = random_search.best_params_['n_estimators']\n",
    "        self.max_features = random_search.best_params_['max_features']\n",
    "        self.max_depth = random_search.best_params_['max_depth']\n",
    "        self.bootstrap = random_search.best_params_['bootstrap']\n",
    "\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "        balanced_accuracy = round(balanced_accuracy_score(y_test, y_pred)*100,1)\n",
    "        auc = round(roc_auc_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "        print('Balanced accuracy:', f1, '\\n')\n",
    "        print('AUC Score:', auc, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1, balanced_accuracy, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:56:51.482906191Z",
     "start_time": "2023-05-15T23:56:51.384346171Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVClassifier:\n",
    "    def __init__(self, C = 1, kernel='linear', gamma = 0.2):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma, verbose=True)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = svm.SVC()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.C = random_search.best_params_['C']\n",
    "        self.kernel = random_search.best_params_['kernel']\n",
    "        self.gamma = random_search.best_params_['gamma']\n",
    "\n",
    "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "        balanced_accuracy = round(balanced_accuracy_score(y_test, y_pred)*100,1)\n",
    "        auc = round(roc_auc_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "        print('Balanced accuracy:', f1, '\\n')\n",
    "        print('AUC Score:', auc, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1, balanced_accuracy, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T23:56:52.311108228Z",
     "start_time": "2023-05-15T23:56:52.245167193Z"
    }
   },
   "outputs": [],
   "source": [
    "class LRClassifier:\n",
    "    def __init__(self, penalty = 'l2', solver = 'libinear', C = 0.5):\n",
    "        self.penalty = penalty\n",
    "        self.solver = solver\n",
    "        self.C = C\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = LogisticRegression()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.penalty = random_search.best_params_['penalty']\n",
    "        self.solver = random_search.best_params_['solver']\n",
    "        self.C = random_search.best_params_['C']\n",
    "\n",
    "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "        balanced_accuracy = round(balanced_accuracy_score(y_test, y_pred)*100,1)\n",
    "        auc = round(roc_auc_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "        print('Balanced accuracy:', f1, '\\n')\n",
    "        print('AUC Score:', auc, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1, balanced_accuracy, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "class FakeNewsClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
    "        super(FakeNewsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "class NeuralNetworkClassifier:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=2):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train, num_epochs=10, lr=0.001):\n",
    "        self.model = FakeNewsClassifier(self.input_dim, self.hidden_dim, self.output_dim)\n",
    "        self.model = self.model.double()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        for _ in tqdm(range(num_epochs), desc=\"Epoch\"):\n",
    "            for embedding, label in zip(X_train, y_train):\n",
    "                embedding_tensor = torch.from_numpy(embedding).double().unsqueeze(0)\n",
    "                label_tensor = torch.tensor([label])\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(embedding_tensor)\n",
    "                loss = criterion(outputs, label_tensor)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        test_inputs = torch.from_numpy(X_test).double()\n",
    "        predictions = self.model(test_inputs)\n",
    "        predicted_classes = torch.argmax(predictions, dim=1)\n",
    "        predicted_classes = predicted_classes.numpy()\n",
    "        return predicted_classes\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100, 1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100, 1)\n",
    "        balanced_accuracy = round(balanced_accuracy_score(y_test, y_pred)*100,1)\n",
    "        auc = round(roc_auc_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "        print('Balanced accuracy:', f1, '\\n')\n",
    "        print('AUC Score:', auc, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1, balanced_accuracy, auc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:56:53.237760590Z",
     "start_time": "2023-05-15T23:56:53.203608219Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlaJrgisGNfg"
   },
   "source": [
    "## BERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMOZaIWp0_oy"
   },
   "source": [
    "### BERT + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "7HzI3FV7zy6t",
    "outputId": "8ca1830c-a309-4f27-f6dd-cee648ee0978",
    "ExecuteTime": {
     "end_time": "2023-05-15T23:58:06.648787352Z",
     "start_time": "2023-05-15T23:58:04.219575115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.651 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.656 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.633 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.682 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.443 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.419 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.503 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.418 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.464 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.585 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.630 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.669 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.652 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.662 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.705 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.637 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.642 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.664 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.635 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.641 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.640 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.652 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.699 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.564 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.545 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.594 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.490 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.603 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.609 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.607 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.648 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.614 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.648 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.697 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.691 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.652 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.699 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.697 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.691 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.618 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.622 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.671 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.664 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.651 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.633 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.682 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.647 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.685 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.639 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.697 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.651 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.656 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.633 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.682 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.667 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.667 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.682 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.626 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.585 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.630 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.669 total time=   0.0s\n",
      "Best parameters: {'weights': 'uniform', 'n_neighbors': 5, 'metric': 'euclidean'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[215 173]\n",
      " [ 98 514]] \n",
      "\n",
      "Accuracy: 72.9 \n",
      "\n",
      "F1 Score: 79.1 \n",
      "\n",
      "Balanced accuracy: 79.1 \n",
      "\n",
      "AUC Score: 69.7 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[150 299]\n",
      " [269 549]] \n",
      "\n",
      "Accuracy: 55.2 \n",
      "\n",
      "F1 Score: 65.9 \n",
      "\n",
      "Balanced accuracy: 65.9 \n",
      "\n",
      "AUC Score: 50.3 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_bert_train, accuracy_knn_bert_train, f1_knn_bert_train, balaccuracy_knn_bert_train, rocauc_knn_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_bert_test, accuracy_knn_bert_test, f1_knn_bert_test, balaccuracy_knn_bert_test, rocauc_knn_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg4FzG2htmwr"
   },
   "source": [
    "### BERT + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psJLbuc_win3",
    "outputId": "554936c2-e2c5-4b6f-df80-f9e4054f0dbe",
    "ExecuteTime": {
     "end_time": "2023-05-16T00:01:42.520095330Z",
     "start_time": "2023-05-15T23:59:02.847714331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.643 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.638 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.664 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.656 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.639 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.621 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.739 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.631 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.681 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.652 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.626 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.641 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.628 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.656 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.631 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.694 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.737 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.707 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.736 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.719 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.631 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.632 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.645 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.661 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.662 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.659 total time=   4.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.674 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.691 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.669 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.674 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.742 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.758 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.725 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.731 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.751 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.605 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.652 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.679 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.654 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.649 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.714 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.734 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.719 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.714 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.726 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.688 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.705 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.689 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.688 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.730 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.615 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.669 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.661 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.598 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.617 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.707 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.714 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.667 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.684 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.730 total time=   4.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.709 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.750 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.724 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.756 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.735 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.627 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.672 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.640 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.636 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.602 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.635 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.696 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.667 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.647 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.676 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.567 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.605 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.565 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.636 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.643 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.599 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.588 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.607 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.565 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.603 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.639 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.672 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.612 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.672 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.638 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.722 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.741 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.740 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.757 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.740 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.593 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.607 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.612 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.667 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.605 total time=   2.5s\n",
      "Best parameters: {'subsample': 0.7, 'objective': 'reg:squarederror', 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.5} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[115 273]\n",
      " [  2 610]] \n",
      "\n",
      "Accuracy: 72.5 \n",
      "\n",
      "F1 Score: 81.6 \n",
      "\n",
      "Balanced accuracy: 81.6 \n",
      "\n",
      "AUC Score: 64.7 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[ 16 433]\n",
      " [ 28 790]] \n",
      "\n",
      "Accuracy: 63.6 \n",
      "\n",
      "F1 Score: 77.4 \n",
      "\n",
      "Balanced accuracy: 77.4 \n",
      "\n",
      "AUC Score: 50.1 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_bert_train, accuracy_xgb_bert_train, f1_xgb_bert_train, balaccuracy_xgb_bert_train, rocauc_xgb_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_bert_test, accuracy_xgb_bert_test, f1_xgb_bert_test, balaccuracy_xgb_bert_test, rocauc_xgb_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekftGhJPFFFX"
   },
   "source": [
    "### BERT + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ks6w5IOrJYG",
    "outputId": "0341c3cf-975e-4e0c-8a26-01064b132ae1",
    "ExecuteTime": {
     "end_time": "2023-05-16T00:01:50.845889929Z",
     "start_time": "2023-05-16T00:01:42.508330177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.657 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.757 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.732 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.720 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.743 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.650 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.694 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.703 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.730 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.721 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.726 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.694 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.728 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.725 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.727 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.614 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.654 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.629 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.601 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.635 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.616 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.657 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.602 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.622 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.678 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.722 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.669 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.656 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.639 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.645 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.636 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.721 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.708 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.694 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.712 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.690 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.669 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.652 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.664 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.708 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.693 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.696 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.725 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.719 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.717 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.722 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.711 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.711 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.603 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.646 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.629 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.629 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.631 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.656 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.677 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.697 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.648 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.719 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.724 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.690 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.742 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.730 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.692 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.703 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.702 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.750 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.711 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.683 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.702 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.721 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.704 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.602 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.651 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.638 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.650 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.690 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.611 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.628 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.656 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.697 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.643 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.713 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.707 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.717 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.737 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.713 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.659 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.684 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.688 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.674 total time=   0.1s\n",
      "Best parameters: {'n_estimators': 25, 'max_features': 5, 'max_depth': None, 'bootstrap': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[388   0]\n",
      " [  0 612]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "Balanced accuracy: 100.0 \n",
      "\n",
      "AUC Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[ 66 383]\n",
      " [139 679]] \n",
      "\n",
      "Accuracy: 58.8 \n",
      "\n",
      "F1 Score: 72.2 \n",
      "\n",
      "Balanced accuracy: 72.2 \n",
      "\n",
      "AUC Score: 48.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25], \n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_bert_train, accuracy_rf_bert_train, f1_rf_bert_train, balaccuracy_rf_bert_train, rocauc_rf_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_bert_test, accuracy_rf_bert_test, f1_rf_bert_test, balaccuracy_rf_bert_test, rocauc_rf_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbX9j48J1a9j"
   },
   "source": [
    "### BERT + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSTFuYyH63Mk",
    "outputId": "6ba15a33-8e98-4a4e-9113-8c771dc0dede",
    "ExecuteTime": {
     "end_time": "2023-05-16T00:02:44.937829585Z",
     "start_time": "2023-05-16T00:02:29.750516949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.629 total time=   0.2s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.567 total time=   0.2s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.623 total time=   0.2s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.568 total time=   0.2s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.616 total time=   0.2s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.746 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.762 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.754 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.762 total time=   0.2s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.2s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.636 total time=   0.2s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.581 total time=   0.3s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.631 total time=   0.3s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.612 total time=   0.2s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.620 total time=   0.2s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.635 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.620 total time=   0.2s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.690 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.651 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.634 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.631 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.651 total time=   0.2s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.684 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.640 total time=   0.2s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.676 total time=   0.2s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.692 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.701 total time=   0.2s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.732 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.751 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.707 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.636 total time=   0.3s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.581 total time=   0.3s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.631 total time=   0.3s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.612 total time=   0.3s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.620 total time=   0.2s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.637 total time=   0.2s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.648 total time=   0.2s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.672 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.640 total time=   0.2s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.620 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.653 total time=   0.2s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.645 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.639 total time=   0.2s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.637 total time=   0.2s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.631 total time=   0.2s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.563 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.626 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.643 total time=   0.2s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.642 total time=   0.2s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.672 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.636 total time=   0.2s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.581 total time=   0.3s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.631 total time=   0.3s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.612 total time=   0.3s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.620 total time=   0.2s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.637 total time=   0.2s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.648 total time=   0.2s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.672 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.640 total time=   0.2s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.620 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.653 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.645 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.639 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.637 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.631 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.541 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.604 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.642 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.619 total time=   0.2s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.659 total time=   0.1s\n",
      "Best parameters: {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 1} \n",
      "\n",
      "[LibSVM]*.*.*\n",
      "optimization finished, #iter = 1424\n",
      "obj = -775.741729, rho = 0.322496\n",
      "nSV = 810, nBSV = 737\n",
      "Total nSV = 810\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[  0 388]\n",
      " [  0 612]] \n",
      "\n",
      "Accuracy: 61.2 \n",
      "\n",
      "F1 Score: 75.9 \n",
      "\n",
      "Balanced accuracy: 75.9 \n",
      "\n",
      "AUC Score: 50.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[  0 449]\n",
      " [  0 818]] \n",
      "\n",
      "Accuracy: 64.6 \n",
      "\n",
      "F1 Score: 78.5 \n",
      "\n",
      "Balanced accuracy: 78.5 \n",
      "\n",
      "AUC Score: 50.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_bert_train, accuracy_svc_bert_train, f1_svc_bert_train, balaccuracy_svc_bert_train, rocauc_svc_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_bert_test, accuracy_svc_bert_test, f1_svc_bert_test, balaccuracy_svc_bert_test, rocauc_svc_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYoz0OB11ayT"
   },
   "source": [
    "### BERT + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YijN0v7JCFbG",
    "outputId": "4bf95058-f264-43c2-e84d-1572b4814428",
    "ExecuteTime": {
     "end_time": "2023-05-16T00:03:27.795505833Z",
     "start_time": "2023-05-16T00:03:05.900612479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.630 total time=   0.2s\n",
      "[CV 2/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.567 total time=   0.2s\n",
      "[CV 3/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.654 total time=   0.2s\n",
      "[CV 4/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.603 total time=   0.2s\n",
      "[CV 5/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.649 total time=   0.2s\n",
      "[CV 1/5] END C=0.92, penalty=l2, solver=newton-cg;, score=0.635 total time=   0.3s\n",
      "[CV 2/5] END C=0.92, penalty=l2, solver=newton-cg;, score=0.575 total time=   0.2s\n",
      "[CV 3/5] END C=0.92, penalty=l2, solver=newton-cg;, score=0.648 total time=   0.3s\n",
      "[CV 4/5] END C=0.92, penalty=l2, solver=newton-cg;, score=0.598 total time=   0.3s\n",
      "[CV 5/5] END C=0.92, penalty=l2, solver=newton-cg;, score=0.652 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.76, penalty=none, solver=sag;, score=0.623 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.76, penalty=none, solver=sag;, score=0.577 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.76, penalty=none, solver=sag;, score=0.640 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.76, penalty=none, solver=sag;, score=0.586 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.76, penalty=none, solver=sag;, score=0.635 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.11, penalty=l2, solver=saga;, score=0.654 total time=   0.6s\n",
      "[CV 2/5] END ...C=0.11, penalty=l2, solver=saga;, score=0.636 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.11, penalty=l2, solver=saga;, score=0.684 total time=   0.6s\n",
      "[CV 4/5] END ...C=0.11, penalty=l2, solver=saga;, score=0.651 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.11, penalty=l2, solver=saga;, score=0.718 total time=   0.6s\n",
      "[CV 1/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.608 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.567 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.631 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.600 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.620 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.59, penalty=l2, solver=sag;, score=0.622 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=0.59, penalty=l2, solver=sag;, score=0.584 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.59, penalty=l2, solver=sag;, score=0.662 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=0.59, penalty=l2, solver=sag;, score=0.609 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=0.59, penalty=l2, solver=sag;, score=0.654 total time=   0.5s\n",
      "[CV 1/5] END ..C=0.77, penalty=l2, solver=lbfgs;, score=0.622 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.77, penalty=l2, solver=lbfgs;, score=0.573 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.77, penalty=l2, solver=lbfgs;, score=0.654 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.77, penalty=l2, solver=lbfgs;, score=0.598 total time=   0.1s\n",
      "[CV 5/5] END ..C=0.77, penalty=l2, solver=lbfgs;, score=0.649 total time=   0.0s\n",
      "[CV 1/5] END C=0.99, penalty=none, solver=newton-cg;, score=0.608 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.99, penalty=none, solver=newton-cg;, score=0.567 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.99, penalty=none, solver=newton-cg;, score=0.631 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.99, penalty=none, solver=newton-cg;, score=0.600 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.99, penalty=none, solver=newton-cg;, score=0.620 total time=   0.2s\n",
      "[CV 1/5] END C=0.73, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.73, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.73, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.73, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.73, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.84, penalty=l1, solver=liblinear;, score=0.643 total time=   0.2s\n",
      "[CV 2/5] END C=0.84, penalty=l1, solver=liblinear;, score=0.610 total time=   0.3s\n",
      "[CV 3/5] END C=0.84, penalty=l1, solver=liblinear;, score=0.651 total time=   0.8s\n",
      "[CV 4/5] END C=0.84, penalty=l1, solver=liblinear;, score=0.582 total time=   0.9s\n",
      "[CV 5/5] END C=0.84, penalty=l1, solver=liblinear;, score=0.662 total time=   0.3s\n",
      "[CV 1/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.34, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.34, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.34, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.34, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.34, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.68, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.68, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.68, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.68, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.68, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.19, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.19, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.19, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.19, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.19, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.06, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......C=0.91, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.91, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.91, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.91, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.91, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.622 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.581 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.664 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.592 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.652 total time=   0.6s\n",
      "[CV 1/5] END C=0.49, penalty=l2, solver=liblinear;, score=0.622 total time=   0.3s\n",
      "[CV 2/5] END C=0.49, penalty=l2, solver=liblinear;, score=0.602 total time=   0.2s\n",
      "[CV 3/5] END C=0.49, penalty=l2, solver=liblinear;, score=0.662 total time=   0.2s\n",
      "[CV 4/5] END C=0.49, penalty=l2, solver=liblinear;, score=0.607 total time=   0.2s\n",
      "[CV 5/5] END C=0.49, penalty=l2, solver=liblinear;, score=0.652 total time=   0.2s\n",
      "[CV 1/5] END C=0.92, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.92, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.92, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.92, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.92, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.62052936 0.6214335  0.61222019 0.66854839 0.60513485\n",
      " 0.62622734 0.61898497 0.60513485        nan 0.62953469        nan\n",
      "        nan        nan        nan        nan        nan 0.62208097\n",
      " 0.6286909         nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 0.11} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[222 166]\n",
      " [ 45 567]] \n",
      "\n",
      "Accuracy: 78.9 \n",
      "\n",
      "F1 Score: 84.3 \n",
      "\n",
      "Balanced accuracy: 84.3 \n",
      "\n",
      "AUC Score: 74.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[102 347]\n",
      " [215 603]] \n",
      "\n",
      "Accuracy: 55.6 \n",
      "\n",
      "F1 Score: 68.2 \n",
      "\n",
      "Balanced accuracy: 68.2 \n",
      "\n",
      "AUC Score: 48.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_bert_train, accuracy_lr_bert_train, f1_lr_bert_train, balaccuracy_lr_bert_train, rocauc_lr_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_bert_test, accuracy_lr_bert_test, f1_lr_bert_test, balaccuracy_lr_bert_test, rocauc_lr_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BERT + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [00:18<02:49, 18.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_30114/3499014566.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# Fit the model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mclassifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train_embeddings_bert\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.001\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m# Evaluate classifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_30114/2684901878.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X_train, y_train, num_epochs, lr)\u001B[0m\n\u001B[1;32m     33\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m                 \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m                 \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m                     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m                     \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_step_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36m_use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_grad_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdefaults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'differentiable'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m             \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_grad_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprev_grad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure, grad_scaler)\u001B[0m\n\u001B[1;32m    232\u001B[0m                     \u001B[0mstate_steps\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'step'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 234\u001B[0;31m             adam(params_with_grad,\n\u001B[0m\u001B[1;32m    235\u001B[0m                  \u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    236\u001B[0m                  \u001B[0mexp_avgs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    298\u001B[0m         \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_single_tensor_adam\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 300\u001B[0;31m     func(params,\n\u001B[0m\u001B[1;32m    301\u001B[0m          \u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m          \u001B[0mexp_avgs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    408\u001B[0m                 \u001B[0mdenom\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmax_exp_avg_sqs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbias_correction2_sqrt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 410\u001B[0;31m                 \u001B[0mdenom\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mexp_avg_sq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbias_correction2_sqrt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    411\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m             \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddcdiv_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexp_avg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdenom\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mstep_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_bert.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_bert.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_bert, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_bert_train, accuracy_nn_bert_train, f1_nn_bert_train, balaccuracy_nn_bert_train, rocauc_nn_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_bert_test, accuracy_nn_bert_test, f1_nn_bert_test, balaccuracy_nn_bert_test, rocauc_nn_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T23:50:31.219020488Z",
     "start_time": "2023-05-15T23:50:12.282447166Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uSk7WKhGB1v"
   },
   "source": [
    "## GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1D_jiR2GI7H"
   },
   "source": [
    "### GloVe + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "LA5swddzG28v",
    "ExecuteTime": {
     "end_time": "2023-05-16T00:23:31.279986998Z",
     "start_time": "2023-05-16T00:23:29.327000528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.598 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.587 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.556 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.559 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.607 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.578 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.603 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.552 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.601 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.598 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.587 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.578 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.593 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.590 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.609 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.606 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.505 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.544 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.609 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.581 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.498 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.512 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.559 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.574 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.540 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.603 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.627 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.579 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.641 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.599 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.603 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.603 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.451 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.442 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.450 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.571 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.641 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.617 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.446 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.436 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.449 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.482 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.525 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.492 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.495 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.563 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.510 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.574 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.608 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.578 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.596 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.505 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.455 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.497 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.543 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.434 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.590 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.599 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.587 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.644 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.560 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.570 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.563 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.578 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.588 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.595 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.587 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.641 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.603 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.552 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.601 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.586 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.574 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.608 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.578 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.596 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.619 total time=   0.0s\n",
      "Best parameters: {'weights': 'uniform', 'n_neighbors': 9, 'metric': 'euclidean'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[250 138]\n",
      " [194 418]] \n",
      "\n",
      "Accuracy: 66.8 \n",
      "\n",
      "F1 Score: 71.6 \n",
      "\n",
      "Balanced accuracy: 71.6 \n",
      "\n",
      "AUC Score: 66.4 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[188 261]\n",
      " [393 425]] \n",
      "\n",
      "Accuracy: 48.4 \n",
      "\n",
      "F1 Score: 56.5 \n",
      "\n",
      "Balanced accuracy: 56.5 \n",
      "\n",
      "AUC Score: 46.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_glove_train, accuracy_knn_glove_train, f1_knn_glove_train, balaccuracy_knn_glove_train, rocauc_knn_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_glove_test, accuracy_knn_glove_test, f1_knn_glove_test, balaccuracy_knn_glove_test, rocauc_knn_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Lfsat69GIoJ"
   },
   "source": [
    "### GloVe + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "rt7c3MSPG3PP",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:50:49.109469883Z",
     "start_time": "2023-05-07T22:49:54.138482569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.065 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.172 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.180 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.045 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.122 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.110 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.111 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.146 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.095 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.067 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.358 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.305 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.403 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.288 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.408 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.294 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.408 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.431 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.410 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.303 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.456 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.391 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.348 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.322 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.268 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.235 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.336 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.269 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.234 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.191 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.234 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.264 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.157 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.202 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.045 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.111 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.048 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.048 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.096 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.133 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.174 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.051 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.051 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.049 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.190 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.286 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.286 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.300 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.303 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.371 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.400 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.455 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.439 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.312 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.375 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.458 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.356 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.372 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.171 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.239 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.391 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.339 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.330 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.149 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.172 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.157 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.151 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.104 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.192 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.320 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.262 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.290 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.211 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.140 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.323 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.267 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.279 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.266 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.192 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.320 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.262 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.290 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.211 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.248 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.309 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.281 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.379 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.306 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.220 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.255 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.302 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.278 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.262 total time=   0.2s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 50, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.5, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[502 316]\n",
      " [279 170]] \n",
      "\n",
      "Accuracy: 53.0 \n",
      "\n",
      "F1 Score: 36.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_glove_train, accuracy_xgb_glove_train, f1_xgb_glove_train, balaccuracy_xgb_glove_train, rocauc_xgb_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_glove_test, accuracy_xgb_glove_test, f1_xgb_glove_test, balaccuracy_xgb_glove_test, rocauc_xgb_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUCEQAQXGIl5"
   },
   "source": [
    "### GloVe + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "GLutlbgvG3f8",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:50:57.279236688Z",
     "start_time": "2023-05-07T22:50:49.111845269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.180 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.171 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.167 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.229 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.312 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.196 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.218 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.122 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.065 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.171 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.189 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.126 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.292 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.200 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.227 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.216 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.257 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.108 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.196 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.176 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.091 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.136 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.250 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.205 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.047 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.119 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.152 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.188 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.225 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.065 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.171 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.202 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.138 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.278 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.184 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.330 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.222 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.192 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.154 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.081 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.189 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.227 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.125 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.243 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.248 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.186 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.220 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.175 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.257 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.304 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.275 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.281 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.189 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.071 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.140 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.220 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.299 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.315 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.270 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.165 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.196 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.143 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.090 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.222 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.102 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.126 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.180 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.220 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.162 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.187 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.082 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.218 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.208 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.182 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.182 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.167 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.210 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.129 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.265 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.101 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.122 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.133 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.183 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.136 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.309 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.222 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.247 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.353 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.214 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.267 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.111 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.246 total time=   0.0s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 5, 'max_depth': None, 'bootstrap': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[702 116]\n",
      " [376  73]] \n",
      "\n",
      "Accuracy: 61.2 \n",
      "\n",
      "F1 Score: 22.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25], \n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_glove_train, accuracy_rf_glove_train, f1_rf_glove_train, balaccuracy_rf_glove_train, rocauc_rf_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_glove_test, accuracy_rf_glove_test, f1_rf_glove_test, balaccuracy_rf_glove_test, rocauc_rf_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vldrLVlwGIg9"
   },
   "source": [
    "### GloVe + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "MqqebdmmG3qI",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:57:25.205378234Z",
     "start_time": "2023-05-07T22:50:57.283308955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.228 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.231 total time=   0.1s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.305 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.375 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.292 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.074 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.072 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.074 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.026 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.053 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.026 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.026 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.288 total time=   0.2s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.366 total time=   0.3s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.428 total time=   0.3s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.431 total time=   0.3s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.300 total time=   0.3s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.268 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.341 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.343 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.420 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.318 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.354 total time=   0.1s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.353 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.353 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.441 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.380 total time=   0.1s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.275 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.400 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.322 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.321 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.243 total time=   3.7s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.368 total time=   3.1s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.411 total time=   9.9s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.472 total time=   6.1s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.373 total time=   3.5s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.345 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.394 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.309 total time=   0.1s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.326 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.377 total time=   0.1s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.456 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.412 total time=   0.1s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.312 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.410 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.322 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.380 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.349 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.288 total time= 1.3min\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.340 total time=  53.8s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.397 total time= 1.8min\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.468 total time=  51.2s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.358 total time= 1.0min\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.345 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.394 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.309 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.326 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.377 total time=   0.1s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.456 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.412 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.301 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.425 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.322 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.348 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.371 total time=   0.1s\n",
      "Best parameters: {'kernel': 'rbf', 'gamma': 'scale', 'C': 10} \n",
      "\n",
      "[LibSVM]...*.*\n",
      "optimization finished, #iter = 4304\n",
      "obj = -2401.212245, rho = -0.561638\n",
      "nSV = 918, nBSV = 121\n",
      "Total nSV = 918\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  6 360]] \n",
      "\n",
      "Accuracy: 99.4 \n",
      "\n",
      "F1 Score: 99.2 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[565 253]\n",
      " [303 146]] \n",
      "\n",
      "Accuracy: 56.1 \n",
      "\n",
      "F1 Score: 34.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_glove_train, accuracy_svc_glove_train, f1_svc_glove_train, balaccuracy_svc_glove_train, rocauc_svc_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_glove_test, accuracy_svc_glove_test, f1_svc_glove_test, balaccuracy_svc_glove_test, rocauc_svc_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8IPkDvHGIZw"
   },
   "source": [
    "### GloVe + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "7j_OebkkG32s",
    "ExecuteTime": {
     "end_time": "2023-05-16T00:23:49.676164246Z",
     "start_time": "2023-05-16T00:23:43.437920577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.9500000000000001, penalty=l2, solver=liblinear;, score=0.655 total time=   0.1s\n",
      "[CV 2/5] END C=0.9500000000000001, penalty=l2, solver=liblinear;, score=0.659 total time=   0.0s\n",
      "[CV 3/5] END C=0.9500000000000001, penalty=l2, solver=liblinear;, score=0.682 total time=   0.0s\n",
      "[CV 4/5] END C=0.9500000000000001, penalty=l2, solver=liblinear;, score=0.672 total time=   0.0s\n",
      "[CV 5/5] END C=0.9500000000000001, penalty=l2, solver=liblinear;, score=0.644 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.92, penalty=l2, solver=saga;, score=0.655 total time=   0.2s\n",
      "[CV 2/5] END ...C=0.92, penalty=l2, solver=saga;, score=0.656 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.92, penalty=l2, solver=saga;, score=0.682 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.92, penalty=l2, solver=saga;, score=0.669 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.92, penalty=l2, solver=saga;, score=0.644 total time=   0.2s\n",
      "[CV 1/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END C=0.13, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.13, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.13, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.13, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.13, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.61, penalty=none, solver=saga;, score=0.625 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.61, penalty=none, solver=saga;, score=0.590 total time=   0.2s\n",
      "[CV 3/5] END .C=0.61, penalty=none, solver=saga;, score=0.621 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.61, penalty=none, solver=saga;, score=0.596 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.61, penalty=none, solver=saga;, score=0.623 total time=   0.2s\n",
      "[CV 1/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.720 total time=   0.0s\n",
      "[CV 2/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.722 total time=   0.0s\n",
      "[CV 3/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.737 total time=   0.0s\n",
      "[CV 4/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.724 total time=   0.0s\n",
      "[CV 5/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.699 total time=   0.0s\n",
      "[CV 1/5] END C=0.64, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.64, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.64, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.64, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.64, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.9, penalty=l1, solver=liblinear;, score=0.690 total time=   0.0s\n",
      "[CV 2/5] END C=0.9, penalty=l1, solver=liblinear;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END C=0.9, penalty=l1, solver=liblinear;, score=0.718 total time=   0.1s\n",
      "[CV 4/5] END C=0.9, penalty=l1, solver=liblinear;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END C=0.9, penalty=l1, solver=liblinear;, score=0.674 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.05, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.05, penalty=l2, solver=saga;, score=0.762 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.05, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.05, penalty=l2, solver=saga;, score=0.761 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.05, penalty=l2, solver=saga;, score=0.764 total time=   0.1s\n",
      "[CV 1/5] END C=0.4, penalty=l1, solver=liblinear;, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END C=0.4, penalty=l1, solver=liblinear;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END C=0.4, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.4, penalty=l1, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 5/5] END C=0.4, penalty=l1, solver=liblinear;, score=0.748 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.31, penalty=none, solver=saga;, score=0.627 total time=   0.2s\n",
      "[CV 2/5] END .C=0.31, penalty=none, solver=saga;, score=0.587 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.31, penalty=none, solver=saga;, score=0.627 total time=   0.2s\n",
      "[CV 4/5] END .C=0.31, penalty=none, solver=saga;, score=0.596 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.31, penalty=none, solver=saga;, score=0.629 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.669 total time=   0.0s\n",
      "[CV 2/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.706 total time=   0.0s\n",
      "[CV 4/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END C=0.6900000000000001, penalty=l2, solver=newton-cg;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END C=0.29, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.29, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.29, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.29, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.29, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.02, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.02, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.02, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.02, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.02, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.17, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.17, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.17, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.17, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.17, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.18, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.18, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.18, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.18, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.18, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.8300000000000001, penalty=l2, solver=saga;, score=0.657 total time=   0.2s\n",
      "[CV 2/5] END C=0.8300000000000001, penalty=l2, solver=saga;, score=0.659 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.8300000000000001, penalty=l2, solver=saga;, score=0.682 total time=   0.2s\n",
      "[CV 4/5] END C=0.8300000000000001, penalty=l2, solver=saga;, score=0.667 total time=   0.2s\n",
      "[CV 5/5] END C=0.8300000000000001, penalty=l2, solver=saga;, score=0.659 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.6, penalty=none, solver=sag;, score=0.608 total time=   0.2s\n",
      "[CV 2/5] END ...C=0.6, penalty=none, solver=sag;, score=0.609 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.6, penalty=none, solver=sag;, score=0.640 total time=   0.2s\n",
      "[CV 4/5] END ...C=0.6, penalty=none, solver=sag;, score=0.584 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.66204559 0.66104249 0.74902028        nan 0.61100017 0.72050059\n",
      "        nan 0.69749063 0.76036754 0.75218879 0.61304473        nan\n",
      " 0.68040814        nan        nan        nan        nan        nan\n",
      " 0.66467199 0.60988502]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.6, penalty=none, solver=sag;, score=0.608 total time=   0.2s\n",
      "Best parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 0.05} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[ 22 366]\n",
      " [  1 611]] \n",
      "\n",
      "Accuracy: 63.3 \n",
      "\n",
      "F1 Score: 76.9 \n",
      "\n",
      "Balanced accuracy: 76.9 \n",
      "\n",
      "AUC Score: 52.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[  7 442]\n",
      " [ 23 795]] \n",
      "\n",
      "Accuracy: 63.3 \n",
      "\n",
      "F1 Score: 77.4 \n",
      "\n",
      "Balanced accuracy: 77.4 \n",
      "\n",
      "AUC Score: 49.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_glove_train, accuracy_lr_glove_train, f1_lr_glove_train, balaccuracy_lr_glove_train, rocauc_lr_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_glove_test, accuracy_lr_glove_test, f1_lr_glove_test, balaccuracy_lr_glove_test, rocauc_lr_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GloVe + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:12<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[580  54]\n",
      " [ 24 342]] \n",
      "\n",
      "Accuracy: 92.2 \n",
      "\n",
      "F1 Score: 89.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[482 336]\n",
      " [266 183]] \n",
      "\n",
      "Accuracy: 52.5 \n",
      "\n",
      "F1 Score: 37.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_glove.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_glove.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_glove, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_glove_train, accuracy_nn_glove_train, f1_nn_glove_train, balaccuracy_nn_glove_train, rocauc_nn_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_glove_test, accuracy_nn_glove_test, f1_nn_glove_test, balaccuracy_nn_glove_test, rocauc_nn_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:57:44.925070324Z",
     "start_time": "2023-05-07T22:57:32.877004722Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:22:12.771807870Z",
     "start_time": "2023-05-07T23:22:10.906578192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.477 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.377 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.392 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.394 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.347 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.309 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.283 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.296 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.279 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.248 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.374 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.267 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.147 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.273 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.242 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.243 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.194 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.267 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.232 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.349 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.299 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.412 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.271 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.260 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.160 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.311 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.302 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.350 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.372 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.319 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.350 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.345 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.353 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.291 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.331 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.366 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.293 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.242 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.184 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.188 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.263 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.154 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.271 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.260 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.160 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.311 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.302 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.349 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.299 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.412 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.338 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.336 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.323 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.403 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.263 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.288 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.296 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.374 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.267 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.147 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.273 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.242 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.234 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.265 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.218 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.245 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.263 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.288 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.296 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.328 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.272 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.278 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.352 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.262 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.369 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.409 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.394 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.328 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.444 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.431 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.392 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.408 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.341 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.338 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.336 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.323 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.403 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.364 total time=   0.0s\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 2, 'metric': 'minkowski'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[515 303]\n",
      " [261 188]] \n",
      "\n",
      "Accuracy: 55.5 \n",
      "\n",
      "F1 Score: 40.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_w2v_train, accuracy_knn_w2v_train, f1_knn_w2v_train, balaccuracy_knn_w2v_train, rocauc_knn_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_w2v_test, accuracy_knn_w2v_test, f1_knn_w2v_test, balaccuracy_knn_w2v_test, rocauc_knn_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:23:39.053310202Z",
     "start_time": "2023-05-07T23:22:16.700305223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.342 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.196 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.274 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.326 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.304 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.263 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.194 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.194 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.289 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.455 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.183 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.328 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.380 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.394 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.406 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.343 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.362 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.397 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.235 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.165 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.252 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.222 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.180 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.286 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.176 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.243 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.294 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.303 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.386 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.234 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.293 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.319 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.383 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.468 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.200 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.317 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.380 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.368 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.427 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.403 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.405 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.356 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.252 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.368 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.309 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.406 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.315 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.341 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.429 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.331 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.356 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.420 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.419 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.265 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.208 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.224 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.242 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.359 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.270 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.283 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.397 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.379 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.472 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.383 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.276 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.278 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.389 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.324 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.321 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.423 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.299 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.321 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.392 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.411 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.295 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.269 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.368 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.417 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.300 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.272 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.144 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.247 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.291 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.314 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.443 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.336 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.429 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.486 total time=   0.8s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 7, 'learning_rate': 0.3, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[542 276]\n",
      " [278 171]] \n",
      "\n",
      "Accuracy: 56.3 \n",
      "\n",
      "F1 Score: 38.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_w2v_train, accuracy_xgb_w2v_train, f1_xgb_w2v_train, balaccuracy_xgb_w2v_train, rocauc_xgb_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_w2v_test, accuracy_xgb_w2v_test, f1_xgb_w2v_test, balaccuracy_xgb_w2v_test, rocauc_xgb_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:23:47.034019279Z",
     "start_time": "2023-05-07T23:23:39.056297844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.195 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.245 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.278 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.294 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.241 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.265 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.216 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.306 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.233 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.308 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.220 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.168 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.216 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.315 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.319 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.178 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.353 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.324 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.259 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.288 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.296 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.288 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.299 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.149 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.218 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.180 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.264 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.259 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.243 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.283 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.340 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.280 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.198 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.324 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.190 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.336 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.220 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.210 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.160 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.263 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.146 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.170 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.152 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.208 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.167 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.265 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.303 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.248 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.104 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.321 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.309 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.252 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.180 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.272 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.224 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.235 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.206 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.231 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.178 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.238 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.208 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.239 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.235 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.330 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.275 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.234 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.243 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.239 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.330 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.155 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.237 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.236 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.149 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.275 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.238 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.267 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.237 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.098 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.200 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.149 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.174 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.146 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.211 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.180 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.255 total time=   0.1s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 5, 'max_depth': 10, 'bootstrap': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  9 357]] \n",
      "\n",
      "Accuracy: 99.1 \n",
      "\n",
      "F1 Score: 98.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[697 121]\n",
      " [349 100]] \n",
      "\n",
      "Accuracy: 62.9 \n",
      "\n",
      "F1 Score: 29.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_w2v_train, accuracy_rf_w2v_train, f1_rf_w2v_train, balaccuracy_rf_w2v_train, rocauc_rf_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_w2v_test, accuracy_rf_w2v_test, f1_rf_w2v_test, balaccuracy_rf_w2v_test, rocauc_rf_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:25:09.019520768Z",
     "start_time": "2023-05-07T23:23:47.034251057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.168 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.229 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.349 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.226 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.051 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.025 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.165 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.122 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.140 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.027 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.025 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.099 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.125 total time=   0.1s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.198 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.051 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.101 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.074 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.409 total time=   0.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.395 total time=   0.1s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.375 total time=   0.1s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.472 total time=   0.1s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.371 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.336 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.286 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.302 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.434 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.342 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.382 total time=   0.1s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.338 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.286 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.400 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.351 total time=   0.1s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.444 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.417 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.331 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.417 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.438 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.468 total time=   0.9s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.372 total time=   0.7s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.364 total time=   0.5s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.408 total time=   0.7s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.419 total time=   0.9s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.358 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.303 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.415 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.356 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.385 total time=   0.1s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.290 total time=   0.1s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.406 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.351 total time=   0.1s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.468 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.309 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.342 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.406 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.436 total time=  18.2s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.351 total time=  13.8s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.353 total time=  13.9s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.403 total time=  15.7s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.408 total time=  10.8s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.358 total time=   0.1s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.303 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.415 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.356 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.385 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.290 total time=   0.1s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.406 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.351 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.441 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.306 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.481 total time=   0.1s\n",
      "Best parameters: {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 10} \n",
      "\n",
      "[LibSVM].*.*..*..*\n",
      "optimization finished, #iter = 5749\n",
      "obj = -12009.230044, rho = 1.037368\n",
      "nSV = 602, nBSV = 539\n",
      "Total nSV = 602\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[427 207]\n",
      " [240 126]] \n",
      "\n",
      "Accuracy: 55.3 \n",
      "\n",
      "F1 Score: 36.1 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[585 233]\n",
      " [283 166]] \n",
      "\n",
      "Accuracy: 59.3 \n",
      "\n",
      "F1 Score: 39.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_w2v_train, accuracy_svc_w2v_train, f1_svc_w2v_train, balaccuracy_svc_w2v_train, rocauc_svc_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_w2v_test, accuracy_svc_w2v_test, f1_svc_w2v_test, balaccuracy_svc_w2v_test, rocauc_svc_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:25:13.557391321Z",
     "start_time": "2023-05-07T23:25:09.022852048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.099 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.026 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.027 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.052 total time=   0.0s\n",
      "[CV 1/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.453 total time=   0.0s\n",
      "[CV 2/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.430 total time=   0.0s\n",
      "[CV 3/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.364 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.435 total time=   0.1s\n",
      "[CV 5/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.389 total time=   0.1s\n",
      "[CV 1/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.247 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.132 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.194 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.180 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.196 total time=   0.1s\n",
      "[CV 1/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.453 total time=   0.0s\n",
      "[CV 2/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.430 total time=   0.0s\n",
      "[CV 3/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.364 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.435 total time=   0.1s\n",
      "[CV 5/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.389 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.232 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.096 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.162 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.170 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.157 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.205 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.026 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.094 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.099 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.120 total time=   0.0s\n",
      "[CV 1/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.453 total time=   0.0s\n",
      "[CV 2/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.420 total time=   0.0s\n",
      "[CV 3/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.364 total time=   0.0s\n",
      "[CV 4/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.435 total time=   0.0s\n",
      "[CV 5/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.389 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.18, penalty=none, solver=sag;, score=0.446 total time=   0.2s\n",
      "[CV 2/5] END ..C=0.18, penalty=none, solver=sag;, score=0.400 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.18, penalty=none, solver=sag;, score=0.386 total time=   0.2s\n",
      "[CV 4/5] END ..C=0.18, penalty=none, solver=sag;, score=0.435 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.18, penalty=none, solver=sag;, score=0.411 total time=   0.2s\n",
      "[CV 1/5] END ..C=0.29, penalty=none, solver=sag;, score=0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.29, penalty=none, solver=sag;, score=0.387 total time=   0.2s\n",
      "[CV 3/5] END ..C=0.29, penalty=none, solver=sag;, score=0.386 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.29, penalty=none, solver=sag;, score=0.432 total time=   0.2s\n",
      "[CV 5/5] END ..C=0.29, penalty=none, solver=sag;, score=0.411 total time=   0.2s\n",
      "[CV 1/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.196 total time=   0.0s\n",
      "[CV 2/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.051 total time=   0.0s\n",
      "[CV 3/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.112 total time=   0.0s\n",
      "[CV 4/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.119 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.194 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.075 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.163 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.157 total time=   0.1s\n",
      "[CV 1/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "Best parameters: {'solver': 'sag', 'penalty': 'none', 'C': 0.18} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.04073919 0.         0.41439707        nan\n",
      " 0.18982355 0.                nan        nan 0.41439707 0.16341936\n",
      " 0.10884525 0.41239755 0.41559831 0.41230606 0.12390357 0.14859264\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[553  81]\n",
      " [133 233]] \n",
      "\n",
      "Accuracy: 78.6 \n",
      "\n",
      "F1 Score: 68.5 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[570 248]\n",
      " [271 178]] \n",
      "\n",
      "Accuracy: 59.0 \n",
      "\n",
      "F1 Score: 40.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_w2v_train, accuracy_lr_w2v_train, f1_lr_w2v_train, balaccuracy_lr_w2v_train, rocauc_lr_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_w2v_test, accuracy_lr_w2v_test, f1_lr_w2v_test, balaccuracy_lr_w2v_test, rocauc_lr_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[623  11]\n",
      " [ 33 333]] \n",
      "\n",
      "Accuracy: 95.6 \n",
      "\n",
      "F1 Score: 93.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[594 224]\n",
      " [281 168]] \n",
      "\n",
      "Accuracy: 60.1 \n",
      "\n",
      "F1 Score: 40.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_word2vec.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_word2vec.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_w2v_train, accuracy_nn_w2v_train, f1_nn_w2v_train, balaccuracy_nn_w2v_train, rocauc_nn_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_w2v_test, accuracy_nn_w2v_test, f1_nn_w2v_test, balaccuracy_nn_w2v_test, rocauc_nn_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:25:25.715074640Z",
     "start_time": "2023-05-07T23:25:13.565574017Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.525 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.485 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.502 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.476 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.490 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.557 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.526 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.549 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.463 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.571 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.619 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.576 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.630 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.620 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.623 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.621 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.592 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.632 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.566 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.547 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.539 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.484 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.523 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.537 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.544 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.507 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.518 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.552 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.674 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.579 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.589 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.674 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.579 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.589 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.585 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.450 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.531 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.472 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.472 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.595 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.691 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.642 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.652 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.646 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.677 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.623 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.589 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.641 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.664 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.622 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.582 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.595 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.592 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.554 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.536 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.498 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.444 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.595 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.674 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.579 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.589 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.556 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.485 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.485 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.467 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.649 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.691 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.648 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.619 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.576 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.630 total time=   0.0s\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 2, 'metric': 'minkowski'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[388   0]\n",
      " [  0 612]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "Balanced accuracy: 100.0 \n",
      "\n",
      "AUC Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[123 326]\n",
      " [249 569]] \n",
      "\n",
      "Accuracy: 54.6 \n",
      "\n",
      "F1 Score: 66.4 \n",
      "\n",
      "Balanced accuracy: 66.4 \n",
      "\n",
      "AUC Score: 48.5 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_gpt2_train, accuracy_knn_gpt2_train, f1_knn_gpt2_train, balaccuracy_knn_gpt2_train, rocauc_knn_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_gpt2_test, accuracy_knn_gpt2_test, f1_knn_gpt2_test, balaccuracy_knn_gpt2_test, rocauc_knn_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T00:24:10.345440138Z",
     "start_time": "2023-05-16T00:24:07.813297926Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.047 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.169 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.052 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.027 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.096 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.395 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.288 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.436 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.490 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.400 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.395 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.338 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.388 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.384 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.369 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.237 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.288 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.214 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.222 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.243 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.374 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.344 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.331 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.403 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.433 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.374 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.352 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.392 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.424 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.370 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.067 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.156 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.233 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.140 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.133 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.304 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.322 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.330 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.353 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.300 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.365 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.340 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.405 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.392 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.310 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.453 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.440 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.378 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.430 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.346 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.259 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.268 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.341 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.239 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.319 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.269 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.368 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.305 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.356 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.269 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.252 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.265 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.281 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.157 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.239 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.291 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.240 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.216 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.090 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.234 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.195 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.026 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.156 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.277 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.317 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.377 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.395 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.302 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.341 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.368 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.370 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.288 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.390 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.070 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.176 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.101 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.074 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.174 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.026 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.100 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.027 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.000 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.098 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.025 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.101 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.053 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.000 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.050 total time=   0.4s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 50, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.5, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[498 320]\n",
      " [281 168]] \n",
      "\n",
      "Accuracy: 52.6 \n",
      "\n",
      "F1 Score: 35.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_gpt2_train, accuracy_xgb_gpt2_train, f1_xgb_gpt2_train, balaccuracy_xgb_gpt2_train, rocauc_xgb_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_gpt2_test, accuracy_xgb_gpt2_test, f1_xgb_gpt2_test, balaccuracy_xgb_gpt2_test, rocauc_xgb_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:30:44.593169713Z",
     "start_time": "2023-05-07T23:28:49.828915125Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.130 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.224 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.216 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.211 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.224 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.162 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.141 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.222 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.143 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.226 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.112 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.132 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.202 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.196 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.232 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.187 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.196 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.272 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.315 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.241 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.118 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.183 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.269 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.167 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.206 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.098 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.317 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.237 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.306 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.154 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.173 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.273 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.151 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.184 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.143 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.118 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.188 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.208 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.160 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.226 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.214 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.299 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.126 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.321 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.245 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.151 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.182 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.116 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.133 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.132 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.154 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.108 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.330 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.176 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.143 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.204 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.130 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.133 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.085 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.187 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.263 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.213 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.163 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.173 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.220 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.160 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.308 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.239 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.283 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.210 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.231 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.188 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.157 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.263 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.218 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.156 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.156 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.146 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.159 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.088 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.147 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.124 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.229 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.132 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.184 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.204 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.176 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.245 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.202 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.044 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.165 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.148 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.222 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.262 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.276 total time=   0.1s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 10, 'max_depth': None, 'bootstrap': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [ 24 342]] \n",
      "\n",
      "Accuracy: 97.6 \n",
      "\n",
      "F1 Score: 96.6 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[682 136]\n",
      " [394  55]] \n",
      "\n",
      "Accuracy: 58.2 \n",
      "\n",
      "F1 Score: 17.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_gpt2_train, accuracy_rf_gpt2_train, f1_rf_gpt2_train, balaccuracy_rf_gpt2_train, rocauc_rf_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_gpt2_test, accuracy_rf_gpt2_test, f1_rf_gpt2_test, balaccuracy_rf_gpt2_test, rocauc_rf_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:30:53.841555531Z",
     "start_time": "2023-05-07T23:30:44.596917843Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.759 total time=   0.2s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.752 total time=   0.1s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.755 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.728 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.764 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.764 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.742 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.754 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.762 total time=   0.2s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.762 total time=   0.2s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.2s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.656 total time=   0.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.606 total time=   0.1s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.641 total time=   0.1s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.607 total time=   0.1s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.643 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.664 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.632 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.650 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.636 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.627 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.687 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.621 total time=   0.2s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.653 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.662 total time=   0.2s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.659 total time=   0.2s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.736 total time=   0.2s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.732 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.719 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.704 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.701 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.621 total time=   0.2s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.563 total time=   0.2s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.577 total time=   0.2s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.562 total time=   0.2s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.606 total time=   0.2s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.617 total time=   0.2s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.586 total time=   0.2s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.581 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.596 total time=   0.2s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.613 total time=   0.2s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.625 total time=   0.2s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.587 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.553 total time=   0.2s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.604 total time=   0.2s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.603 total time=   0.2s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.669 total time=   0.2s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.607 total time=   0.2s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.642 total time=   0.2s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.579 total time=   0.2s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.617 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.632 total time=   0.2s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.563 total time=   0.2s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.579 total time=   0.2s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.563 total time=   0.2s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.589 total time=   0.2s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.617 total time=   0.1s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.586 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.581 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.596 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.613 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.625 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.587 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.553 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.604 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.603 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.645 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.615 total time=   0.4s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.571 total time=   0.3s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.560 total time=   0.2s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.571 total time=   0.4s\n",
      "Best parameters: {'kernel': 'rbf', 'gamma': 'scale', 'C': 1} \n",
      "\n",
      "[LibSVM]*.*\n",
      "optimization finished, #iter = 1208\n",
      "obj = -724.622298, rho = 0.412279\n",
      "nSV = 898, nBSV = 629\n",
      "Total nSV = 898\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[  5 383]\n",
      " [  0 612]] \n",
      "\n",
      "Accuracy: 61.7 \n",
      "\n",
      "F1 Score: 76.2 \n",
      "\n",
      "Balanced accuracy: 76.2 \n",
      "\n",
      "AUC Score: 50.6 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[  0 449]\n",
      " [  0 818]] \n",
      "\n",
      "Accuracy: 64.6 \n",
      "\n",
      "F1 Score: 78.5 \n",
      "\n",
      "Balanced accuracy: 78.5 \n",
      "\n",
      "AUC Score: 50.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_gpt2_train, accuracy_svc_gpt2_train, f1_svc_gpt2_train, balaccuracy_svc_gpt2_train, rocauc_svc_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_gpt2_test, accuracy_svc_gpt2_test, f1_svc_gpt2_test, balaccuracy_svc_gpt2_test, rocauc_svc_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T00:24:34.341119408Z",
     "start_time": "2023-05-16T00:24:19.308406773Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.027 total time=   0.1s\n",
      "[CV 3/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.027 total time=   0.1s\n",
      "[CV 5/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.026 total time=   0.1s\n",
      "[CV 1/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.024 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.052 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.052 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.051 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.8s\n",
      "[CV 1/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.372 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.405 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.417 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.398 total time=   0.2s\n",
      "[CV 5/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.384 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.28, penalty=none, solver=saga;, score=0.343 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.28, penalty=none, solver=saga;, score=0.386 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.28, penalty=none, solver=saga;, score=0.421 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.28, penalty=none, solver=saga;, score=0.372 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.28, penalty=none, solver=saga;, score=0.331 total time=   0.5s\n",
      "[CV 1/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.392 total time=   0.0s\n",
      "[CV 2/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.431 total time=   0.1s\n",
      "[CV 3/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.428 total time=   0.1s\n",
      "[CV 4/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.416 total time=   0.2s\n",
      "[CV 5/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.381 total time=   0.1s\n",
      "[CV 1/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.392 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.431 total time=   0.1s\n",
      "[CV 3/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.428 total time=   0.1s\n",
      "[CV 4/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.416 total time=   0.1s\n",
      "[CV 5/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.381 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.027 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.027 total time=   0.2s\n",
      "[CV 5/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.026 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.372 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.405 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.417 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.398 total time=   0.2s\n",
      "[CV 5/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.384 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 2/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 3/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 4/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 5/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "Best parameters: {'solver': 'lbfgs', 'penalty': 'none', 'C': 0.62} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[528 290]\n",
      " [278 171]] \n",
      "\n",
      "Accuracy: 55.2 \n",
      "\n",
      "F1 Score: 37.6 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.0160019         nan        nan        nan 0.03585491\n",
      " 0.                nan 0.         0.39505574 0.37075679        nan\n",
      " 0.40943603 0.40943603 0.0160019  0.39505574 0.         0.\n",
      " 0.                nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_gpt2_train, accuracy_lr_gpt2_train, f1_lr_gpt2_train, balaccuracy_lr_gpt2_train, rocauc_lr_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_gpt2_test, accuracy_lr_gpt2_test, f1_lr_gpt2_test, balaccuracy_lr_gpt2_test, rocauc_lr_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:31:22.111973788Z",
     "start_time": "2023-05-07T23:31:08.306438107Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [02:03<00:00, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[595  39]\n",
      " [121 245]] \n",
      "\n",
      "Accuracy: 84.0 \n",
      "\n",
      "F1 Score: 75.4 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[602 216]\n",
      " [336 113]] \n",
      "\n",
      "Accuracy: 56.4 \n",
      "\n",
      "F1 Score: 29.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_gpt2.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_gpt2.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_gpt2_train, accuracy_nn_gpt2_train, f1_nn_gpt2_train, balaccuracy_nn_gpt2_train, rocauc_nn_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_gpt2_test, accuracy_nn_gpt2_test, f1_nn_gpt2_test, balaccuracy_nn_gpt2_test, rocauc_nn_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:33:25.485043955Z",
     "start_time": "2023-05-07T23:31:22.109432257Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.657 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.682 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.686 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.654 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.703 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.691 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.689 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.712 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.684 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.688 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.527 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.474 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.451 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.488 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.520 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.706 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.662 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.677 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.689 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.674 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.669 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.681 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.684 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.705 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.664 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.672 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.687 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.698 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.701 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.688 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.691 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.689 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.712 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.684 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.688 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.651 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.639 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.693 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.636 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.644 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.646 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.584 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.641 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.706 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.681 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.657 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.682 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.686 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.654 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.703 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.706 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.634 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.681 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.719 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.707 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.598 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.635 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.645 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.705 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.684 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.657 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.656 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.703 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.656 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.699 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.498 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.441 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.490 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.498 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.527 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.637 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.606 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.622 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.529 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.661 total time=   0.0s\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 9, 'metric': 'manhattan'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[388   0]\n",
      " [  0 612]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "Balanced accuracy: 100.0 \n",
      "\n",
      "AUC Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[ 84 365]\n",
      " [205 613]] \n",
      "\n",
      "Accuracy: 55.0 \n",
      "\n",
      "F1 Score: 68.3 \n",
      "\n",
      "Balanced accuracy: 68.3 \n",
      "\n",
      "AUC Score: 46.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_roberta_train, accuracy_knn_roberta_train, f1_knn_roberta_train, balaccuracy_knn_roberta_train, rocauc_knn_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_roberta_test, accuracy_knn_roberta_test, f1_knn_roberta_test, balaccuracy_knn_roberta_test, rocauc_knn_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T00:24:56.599176132Z",
     "start_time": "2023-05-16T00:24:50.501166616Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.191 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.159 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.180 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.163 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.067 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.370 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.384 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.403 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.458 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.338 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.349 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.349 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.403 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.369 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.319 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.385 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.436 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.426 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.371 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.380 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.239 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.443 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.226 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.288 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.311 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.366 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.366 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.422 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.331 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.268 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.343 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.248 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.211 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.123 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.049 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.027 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.051 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.310 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.232 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.226 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.252 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.156 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.048 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.159 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.026 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.025 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.242 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.072 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.172 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.071 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.149 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.375 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.214 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.330 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.248 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.376 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.327 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.423 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.383 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.392 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.366 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.350 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.351 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.358 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.335 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.138 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.072 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.159 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.027 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.072 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.304 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.260 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.312 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.288 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.304 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.426 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.422 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.458 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.397 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.371 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.412 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.324 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.387 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.350 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.290 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.254 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.339 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.345 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.397 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.351 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.448 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   0.3s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 9, 'learning_rate': 0.5, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[517 301]\n",
      " [283 166]] \n",
      "\n",
      "Accuracy: 53.9 \n",
      "\n",
      "F1 Score: 36.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_roberta_train, accuracy_xgb_roberta_train, f1_xgb_roberta_train, balaccuracy_xgb_roberta_train, rocauc_xgb_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_roberta_test, accuracy_xgb_roberta_test, f1_xgb_roberta_test, balaccuracy_xgb_roberta_test, rocauc_xgb_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:35:19.810190187Z",
     "start_time": "2023-05-07T23:33:28.563846853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.236 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.137 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.218 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.176 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.246 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.144 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.241 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.194 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.210 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.247 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.143 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.163 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.147 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.184 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.117 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.264 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.263 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.194 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.238 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.152 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.194 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.275 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.263 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.226 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.180 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.175 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.211 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.171 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.173 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.204 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.176 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.194 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.165 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.327 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.228 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.125 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.204 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.176 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.160 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.163 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.312 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.198 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.202 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.257 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.215 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.233 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.239 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.188 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.202 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.213 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.216 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.111 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.157 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.140 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.072 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.126 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.242 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.137 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.198 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.102 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.124 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.143 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.170 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.132 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.138 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.182 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.263 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.243 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.110 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.250 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.180 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.116 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.238 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.135 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.135 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.214 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.212 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.235 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.119 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.182 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.180 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.168 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.178 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 5, 'max_depth': 10, 'bootstrap': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [ 12 354]] \n",
      "\n",
      "Accuracy: 98.8 \n",
      "\n",
      "F1 Score: 98.3 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[718 100]\n",
      " [389  60]] \n",
      "\n",
      "Accuracy: 61.4 \n",
      "\n",
      "F1 Score: 19.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_roberta_train, accuracy_rf_roberta_train, f1_rf_roberta_train, balaccuracy_rf_roberta_train, rocauc_rf_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_roberta_test, accuracy_rf_roberta_test, f1_rf_roberta_test, balaccuracy_rf_roberta_test, rocauc_rf_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:35:29.560046583Z",
     "start_time": "2023-05-07T23:35:19.814050068Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.756 total time=   0.2s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.751 total time=   0.1s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.752 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.752 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.762 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.762 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.762 total time=   0.2s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.762 total time=   0.2s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.2s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.2s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.2s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.2s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.2s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.625 total time=   0.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.644 total time=   0.1s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.609 total time=   0.1s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.654 total time=   0.1s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.648 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.762 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.762 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.762 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.762 total time=   0.2s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.758 total time=   0.2s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.2s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.762 total time=   0.2s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.2s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.596 total time=   0.2s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.635 total time=   0.3s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.559 total time=   0.2s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.606 total time=   0.3s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.576 total time=   0.3s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.712 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.711 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.699 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.742 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.701 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.721 total time=   0.2s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.752 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.734 total time=   0.2s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.756 total time=   0.2s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.727 total time=   0.2s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.699 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.674 total time=   0.2s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.678 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.678 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.698 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.620 total time=   0.6s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.617 total time=   0.7s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.545 total time=   0.8s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.608 total time=   1.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.596 total time=   0.7s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.634 total time=   0.3s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.649 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.580 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.617 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.610 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.629 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.649 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.575 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.645 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.613 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.591 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.631 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.617 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.587 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.624 total time=   0.1s\n",
      "Best parameters: {'kernel': 'poly', 'gamma': 'scale', 'C': 1} \n",
      "\n",
      "[LibSVM]*\n",
      "optimization finished, #iter = 872\n",
      "obj = -775.290135, rho = 1.001617\n",
      "nSV = 840, nBSV = 701\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "Total nSV = 840\n",
      "\n",
      "Confusion matrix\n",
      " [[  0 388]\n",
      " [  0 612]] \n",
      "\n",
      "Accuracy: 61.2 \n",
      "\n",
      "F1 Score: 75.9 \n",
      "\n",
      "Balanced accuracy: 75.9 \n",
      "\n",
      "AUC Score: 50.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[  0 449]\n",
      " [  0 818]] \n",
      "\n",
      "Accuracy: 64.6 \n",
      "\n",
      "F1 Score: 78.5 \n",
      "\n",
      "Balanced accuracy: 78.5 \n",
      "\n",
      "AUC Score: 50.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_roberta_train, accuracy_svc_roberta_train, f1_svc_roberta_train, balaccuracy_svc_roberta_train, rocauc_svc_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_roberta_test, accuracy_svc_roberta_test, f1_svc_roberta_test, balaccuracy_svc_roberta_test, rocauc_svc_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-16T00:25:29.468085286Z",
     "start_time": "2023-05-16T00:25:13.027115290Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.276 total time=   0.1s\n",
      "[CV 2/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.307 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.359 total time=   0.1s\n",
      "[CV 4/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.400 total time=   0.1s\n",
      "[CV 5/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.241 total time=   0.1s\n",
      "[CV 1/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.371 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.353 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.366 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.391 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.299 total time=   0.6s\n",
      "[CV 1/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.72, penalty=none, solver=sag;, score=0.246 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.72, penalty=none, solver=sag;, score=0.227 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.72, penalty=none, solver=sag;, score=0.232 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.72, penalty=none, solver=sag;, score=0.220 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.72, penalty=none, solver=sag;, score=0.154 total time=   0.4s\n",
      "[CV 1/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.93, penalty=none, solver=sag;, score=0.246 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.93, penalty=none, solver=sag;, score=0.229 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.93, penalty=none, solver=sag;, score=0.234 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.93, penalty=none, solver=sag;, score=0.220 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.93, penalty=none, solver=sag;, score=0.154 total time=   0.5s\n",
      "[CV 1/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n",
      "[CV 4/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n",
      "[CV 1/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.276 total time=   0.1s\n",
      "[CV 2/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.307 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "65 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.                nan 0.31640145        nan 0.35601159        nan\n",
      "        nan        nan        nan 0.21568143        nan 0.21657222\n",
      "        nan        nan        nan        nan 0.         0.31640145\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.359 total time=   0.1s\n",
      "[CV 4/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.400 total time=   0.1s\n",
      "[CV 5/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.241 total time=   0.1s\n",
      "[CV 1/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "Best parameters: {'solver': 'newton-cg', 'penalty': 'none', 'C': 0.49} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[470 348]\n",
      " [262 187]] \n",
      "\n",
      "Accuracy: 51.9 \n",
      "\n",
      "F1 Score: 38.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_roberta_train, accuracy_lr_roberta_train, f1_lr_roberta_train, balaccuracy_lr_roberta_train, rocauc_lr_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_roberta_test, accuracy_lr_roberta_test, f1_lr_roberta_test, balaccuracy_lr_roberta_test, rocauc_lr_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:36:00.139727255Z",
     "start_time": "2023-05-07T23:35:44.844837105Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [02:14<00:00, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[619  15]\n",
      " [314  52]] \n",
      "\n",
      "Accuracy: 67.1 \n",
      "\n",
      "F1 Score: 24.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[767  51]\n",
      " [424  25]] \n",
      "\n",
      "Accuracy: 62.5 \n",
      "\n",
      "F1 Score: 9.5 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_roberta.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_roberta.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_roberta, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_roberta_train, accuracy_nn_roberta_train, f1_nn_roberta_train, balaccuracy_nn_roberta_train, rocauc_nn_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_roberta_test, accuracy_nn_roberta_test, f1_nn_roberta_test, balaccuracy_nn_roberta_test, rocauc_nn_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:38:14.319036212Z",
     "start_time": "2023-05-07T23:36:00.138966910Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:48:58.760982365Z",
     "start_time": "2023-05-07T23:48:58.687210213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤════════════╤════════════╕\n",
      "│ Model                   │   Accuracy │   F1-Score │\n",
      "╞═════════════════════════╪════════════╪════════════╡\n",
      "│ LR+GloVe                │       53.4 │       33.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+GloVe               │       53.7 │       34.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+GloVe               │       56.1 │       34.4 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+GloVe      │       61.2 │       22.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+GloVe           │       53   │       36.4 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+GloVe     │       52.5 │       37.8 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+Word2Vec             │       59   │       40.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+Word2Vec            │       55.5 │       40   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+Word2Vec            │       59.3 │       39.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest + Word2Vec │       62.9 │       29.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+Word2Vec        │       56.3 │       38.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+Word2Vec  │       60.1 │       40   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+BERT                 │       52.8 │       34.6 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+BERT                │       53.1 │       35.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+BERT                │       50.4 │       33   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+BERT       │       57.9 │       22.4 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+BERT            │       52.3 │       34.8 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+BERT      │       59.6 │       17.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+RoBERTa              │       51.9 │       38   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+RoBERTa             │       52.8 │       38.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+RoBERTa             │       52.9 │       36   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+RoBERTa    │       61.4 │       19.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+RoBERTa         │       53.9 │       36.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+RoBERTa   │       62.5 │        9.5 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+GPT2                 │       55.2 │       37.6 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+GPT2                │       48.5 │       46.6 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+GPT2                │       55.6 │       35.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+GPT2       │       58.2 │       17.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+GPT2            │       52.6 │       35.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+GPT2      │       56.4 │       29   │\n",
      "╘═════════════════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "data = [[\"LR+GloVe\", accuracy_lr_glove_test, f1_lr_glove_test, balaccuracy_lr_glove_test, rocauc_lr_glove_test],\n",
    "        [\"KNN+GloVe\", accuracy_knn_glove_test, f1_knn_glove_test, balaccuracy_knn_glove_test, rocauc_knn_glove_test],\n",
    "        [\"SVC+GloVe\", accuracy_svc_glove_test, f1_svc_glove_test, balaccuracy_svc_glove_test, rocauc_svc_glove_test],\n",
    "        [\"RandomForest+GloVe\", accuracy_rf_glove_test, f1_rf_glove_test, balaccuracy_rf_glove_test, rocauc_rf_glove_test],\n",
    "        [\"XGBoost+GloVe\", accuracy_xgb_glove_test, f1_xgb_glove_test, balaccuracy_xgb_glove_test, rocauc_xgb_glove_test],\n",
    "        [\"NeuralNetwork+GloVe\", accuracy_nn_glove_test, f1_nn_glove_test, balaccuracy_nn_glove_test, rocauc_nn_glove_test],\n",
    "        [\"LR+Word2Vec\", accuracy_lr_w2v_test, f1_lr_w2v_test, balaccuracy_lr_w2v_test, rocauc_lr_w2v_test],\n",
    "        [\"KNN+Word2Vec\", accuracy_knn_w2v_test, f1_knn_w2v_test, balaccuracy_knn_w2v_test, rocauc_knn_w2v_test],\n",
    "        [\"SVC+Word2Vec\", accuracy_svc_w2v_test, f1_svc_w2v_test, balaccuracy_svc_w2v_test, rocauc_svc_w2v_test],\n",
    "        [\"RandomForest + Word2Vec\", accuracy_rf_w2v_test, f1_rf_w2v_test, balaccuracy_rf_w2v_test, rocauc_rf_w2v_test],\n",
    "        [\"XGBoost+Word2Vec\", accuracy_xgb_w2v_test, f1_xgb_w2v_test, balaccuracy_xgb_w2v_test, rocauc_xgb_w2v_test],\n",
    "        [\"NeuralNetwork+Word2Vec\", accuracy_nn_w2v_test, f1_nn_w2v_test, balaccuracy_nn_w2v_test, rocauc_nn_w2v_test],\n",
    "        [\"LR+BERT\", accuracy_lr_bert_test, f1_lr_bert_test, balaccuracy_lr_bert_test, rocauc_lr_bert_test],\n",
    "        [\"KNN+BERT\", accuracy_knn_bert_test, f1_knn_bert_test, balaccuracy_knn_bert_test, rocauc_knn_bert_test],\n",
    "        [\"SVC+BERT\", accuracy_svc_bert_test, f1_svc_bert_test, balaccuracy_svc_bert_test, rocauc_svc_bert_test],\n",
    "        [\"RandomForest+BERT\", accuracy_rf_bert_test, f1_rf_bert_test, balaccuracy_rf_bert_test, rocauc_rf_bert_test],\n",
    "        [\"XGBoost+BERT\", accuracy_xgb_bert_test, f1_xgb_bert_test, balaccuracy_xgb_bert_test, rocauc_xgb_bert_test],\n",
    "        [\"NeuralNetwork+BERT\", accuracy_nn_bert_test, f1_nn_bert_test, balaccuracy_nn_bert_test, rocauc_nn_bert_test],\n",
    "        [\"LR+RoBERTa\", accuracy_lr_roberta_test, f1_lr_roberta_test, balaccuracy_lr_roberta_test, rocauc_lr_roberta_test],\n",
    "        [\"KNN+RoBERTa\", accuracy_knn_roberta_test, f1_knn_roberta_test, balaccuracy_knn_roberta_test, rocauc_knn_roberta_test],\n",
    "        [\"SVC+RoBERTa\", accuracy_svc_roberta_test, f1_svc_roberta_test, balaccuracy_svc_roberta_test, rocauc_svc_roberta_test],\n",
    "        [\"RandomForest+RoBERTa\", accuracy_rf_roberta_test, f1_rf_roberta_test, balaccuracy_rf_roberta_test, rocauc_rf_roberta_test],\n",
    "        [\"XGBoost+RoBERTa\", accuracy_xgb_roberta_test, f1_xgb_roberta_test, balaccuracy_xgb_roberta_test, rocauc_xgb_roberta_test],\n",
    "        [\"NeuralNetwork+RoBERTa\", accuracy_nn_roberta_test, f1_nn_roberta_test, balaccuracy_nn_roberta_test, rocauc_nn_roberta_test],\n",
    "        [\"LR+GPT2\", accuracy_lr_gpt2_test, f1_lr_gpt2_test, balaccuracy_lr_gpt2_test, rocauc_lr_gpt2_test],\n",
    "        [\"KNN+GPT2\", accuracy_knn_gpt2_test, f1_knn_gpt2_test, balaccuracy_knn_gpt2_test, rocauc_knn_gpt2_test],\n",
    "        [\"SVC+GPT2\", accuracy_svc_gpt2_test, f1_svc_gpt2_test, balaccuracy_svc_gpt2_test, rocauc_svc_gpt2_test],\n",
    "        [\"RandomForest+GPT2\", accuracy_rf_gpt2_test, f1_rf_gpt2_test, balaccuracy_rf_gpt2_test, rocauc_rf_gpt2_test],\n",
    "        [\"XGBoost+GPT2\", accuracy_xgb_gpt2_test, f1_xgb_gpt2_test, balaccuracy_xgb_gpt2_test, rocauc_xgb_gpt2_test],\n",
    "        [\"NeuralNetwork+GPT2\", accuracy_nn_gpt2_test, f1_nn_gpt2_test, balaccuracy_nn_gpt2_test, rocauc_nn_gpt2_test]]\n",
    "  \n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#save results to csv\n",
    "if fast:\n",
    "    with open(\"results_fast_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(col_names)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "else:\n",
    "    with open(\"results_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(col_names)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "#display table\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      " Model                   &   Accuracy &   F1-Score \\\\\n",
      "\\hline\n",
      " LR+GloVe                &       53.4 &       33.2 \\\\\n",
      " KNN+GloVe               &       53.7 &       34.7 \\\\\n",
      " SVC+GloVe               &       56.1 &       34.4 \\\\\n",
      " RandomForest+GloVe      &       61.2 &       22.9 \\\\\n",
      " XGBoost+GloVe           &       53   &       36.4 \\\\\n",
      " NeuralNetwork+GloVe     &       52.5 &       37.8 \\\\\n",
      " LR+Word2Vec             &       59   &       40.7 \\\\\n",
      " KNN+Word2Vec            &       55.5 &       40   \\\\\n",
      " SVC+Word2Vec            &       59.3 &       39.2 \\\\\n",
      " RandomForest + Word2Vec &       62.9 &       29.9 \\\\\n",
      " XGBoost+Word2Vec        &       56.3 &       38.2 \\\\\n",
      " NeuralNetwork+Word2Vec  &       60.1 &       40   \\\\\n",
      " LR+BERT                 &       52.8 &       34.6 \\\\\n",
      " KNN+BERT                &       53.1 &       35.7 \\\\\n",
      " SVC+BERT                &       50.4 &       33   \\\\\n",
      " RandomForest+BERT       &       57.9 &       22.4 \\\\\n",
      " XGBoost+BERT            &       52.3 &       34.8 \\\\\n",
      " NeuralNetwork+BERT      &       59.6 &       17.9 \\\\\n",
      " LR+RoBERTa              &       51.9 &       38   \\\\\n",
      " KNN+RoBERTa             &       52.8 &       38.2 \\\\\n",
      " SVC+RoBERTa             &       52.9 &       36   \\\\\n",
      " RandomForest+RoBERTa    &       61.4 &       19.7 \\\\\n",
      " XGBoost+RoBERTa         &       53.9 &       36.2 \\\\\n",
      " NeuralNetwork+RoBERTa   &       62.5 &        9.5 \\\\\n",
      " LR+GPT2                 &       55.2 &       37.6 \\\\\n",
      " KNN+GPT2                &       48.5 &       46.6 \\\\\n",
      " SVC+GPT2                &       55.6 &       35.7 \\\\\n",
      " RandomForest+GPT2       &       58.2 &       17.2 \\\\\n",
      " XGBoost+GPT2            &       52.6 &       35.9 \\\\\n",
      " NeuralNetwork+GPT2      &       56.4 &       29   \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# print(tabulate(data, headers=col_names, tablefmt=\"latex\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:49:00.904880155Z",
     "start_time": "2023-05-07T23:49:00.878387236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       53.4 │       33.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       59   │       40.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       52.8 │       34.6 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       51.9 │       38   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       55.2 │       37.6 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# #create data\n",
    "# lr_results = [\n",
    "#     [\"GloVe\", accuracy_lr_glove_test, f1_lr_glove_test],\n",
    "#     [\"Word2Vec\", accuracy_lr_w2v_test, f1_lr_w2v_test],\n",
    "#     [\"BERT\", accuracy_lr_bert_test, f1_lr_bert_test],\n",
    "#     [\"RoBERTa\", accuracy_lr_roberta_test, f1_lr_roberta_test],\n",
    "#     [\"GPT2\", accuracy_lr_gpt2_test, f1_lr_gpt2_test]\n",
    "# ]\n",
    "#\n",
    "# #define header names\n",
    "# col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "#\n",
    "# #display table\n",
    "# print(\"Logistic Regression\")\n",
    "# # print(tabulate(lr_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:44.648347738Z",
     "start_time": "2023-05-08T00:11:44.628206561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       53.7 │       34.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       55.5 │       40   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       53.1 │       35.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       52.8 │       38.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       48.5 │       46.6 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# #create data\n",
    "# knn_results = [\n",
    "#     [\"GloVe\", accuracy_knn_glove_test, f1_knn_glove_test],\n",
    "#     [\"Word2Vec\", accuracy_knn_w2v_test, f1_knn_w2v_test],\n",
    "#     [\"BERT\", accuracy_knn_bert_test, f1_knn_bert_test],\n",
    "#     [\"RoBERTa\", accuracy_knn_roberta_test, f1_knn_roberta_test],\n",
    "#     [\"GPT2\", accuracy_knn_gpt2_test, f1_knn_gpt2_test]\n",
    "# ]\n",
    "#\n",
    "# #define header names\n",
    "# col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "#\n",
    "# #display table\n",
    "# print(\"KNN\")\n",
    "# print(tabulate(knn_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:45.623006697Z",
     "start_time": "2023-05-08T00:11:45.607642365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       56.1 │       34.4 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       59.3 │       39.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       50.4 │       33   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       52.9 │       36   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       55.6 │       35.7 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# #create data\n",
    "# svc_results = [\n",
    "#     [\"GloVe\", accuracy_svc_glove_test, f1_svc_glove_test],\n",
    "#     [\"Word2Vec\", accuracy_svc_w2v_test, f1_svc_w2v_test],\n",
    "#     [\"BERT\", accuracy_svc_bert_test, f1_svc_bert_test],\n",
    "#     [\"RoBERTa\", accuracy_svc_roberta_test, f1_svc_roberta_test],\n",
    "#     [\"GPT2\", accuracy_svc_gpt2_test, f1_svc_gpt2_test]\n",
    "# ]\n",
    "#\n",
    "# #define header names\n",
    "# col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "#\n",
    "# #display table\n",
    "# print(\"SVM Classifier\")\n",
    "# print(tabulate(svc_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:46.045799687Z",
     "start_time": "2023-05-08T00:11:46.031440509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       61.2 │       22.9 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       62.9 │       29.9 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       57.9 │       22.4 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       61.4 │       19.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       58.2 │       17.2 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# #create data\n",
    "# rf_results = [\n",
    "#     [\"GloVe\", accuracy_rf_glove_test, f1_rf_glove_test],\n",
    "#     [\"Word2Vec\", accuracy_rf_w2v_test, f1_rf_w2v_test],\n",
    "#     [\"BERT\", accuracy_rf_bert_test, f1_rf_bert_test],\n",
    "#     [\"RoBERTa\", accuracy_rf_roberta_test, f1_rf_roberta_test],\n",
    "#     [\"GPT2\", accuracy_rf_gpt2_test, f1_rf_gpt2_test]\n",
    "# ]\n",
    "#\n",
    "# #define header names\n",
    "# col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "#\n",
    "# #display table\n",
    "# print(\"Random Forest\")\n",
    "# print(tabulate(rf_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:46.310402046Z",
     "start_time": "2023-05-08T00:11:46.299016397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       53   │       36.4 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       56.3 │       38.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       52.3 │       34.8 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       53.9 │       36.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       52.6 │       35.9 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# #create data\n",
    "# xgb_results = [\n",
    "#     [\"GloVe\", accuracy_xgb_glove_test, f1_xgb_glove_test],\n",
    "#     [\"Word2Vec\", accuracy_xgb_w2v_test, f1_xgb_w2v_test],\n",
    "#     [\"BERT\", accuracy_xgb_bert_test, f1_xgb_bert_test],\n",
    "#     [\"RoBERTa\", accuracy_xgb_roberta_test, f1_xgb_roberta_test],\n",
    "#     [\"GPT2\", accuracy_xgb_gpt2_test, f1_xgb_gpt2_test]\n",
    "# ]\n",
    "#\n",
    "# #define header names\n",
    "# col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "#\n",
    "# #display table\n",
    "# print(\"XGBoost\")\n",
    "# print(tabulate(xgb_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:46.663167632Z",
     "start_time": "2023-05-08T00:11:46.636014024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       52.5 │       37.8 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       60.1 │       40   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       59.6 │       17.9 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       62.5 │        9.5 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       56.4 │       29   │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "nn_results = [\n",
    "    [\"GloVe\", accuracy_nn_glove_test, f1_nn_glove_test],\n",
    "    [\"Word2Vec\", accuracy_nn_w2v_test, f1_nn_w2v_test],\n",
    "    [\"BERT\", accuracy_nn_bert_test, f1_nn_bert_test],\n",
    "    [\"RoBERTa\", accuracy_nn_roberta_test, f1_nn_roberta_test],\n",
    "    [\"GPT2\", accuracy_nn_gpt2_test, f1_nn_gpt2_test]\n",
    "]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"NeuralNetwork\")\n",
    "print(tabulate(nn_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:47.147217610Z",
     "start_time": "2023-05-08T00:11:47.088596164Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24t1eSrlFLK6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
