{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpFId1mjCySe"
   },
   "source": [
    "# Word Embeddings + various classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TCU7NPLUuQrU",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:41:26.147484316Z",
     "start_time": "2023-05-07T22:41:16.947585142Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 00:41:20.063165: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gensim\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/liar_dataset/train.tsv', sep=\"\\t\", usecols=[1, 2], names = [\"label\", \"text\"])\n",
    "test = pd.read_csv('../../data/liar_dataset/test.tsv', sep=\"\\t\", usecols=[1, 2], names = [\"label\", \"text\"])\n",
    "valid = pd.read_csv('../../data/liar_dataset/valid.tsv', sep=\"\\t\", usecols=[1, 2], names = [\"label\", \"text\"])\n",
    "\n",
    "train = pd.concat([train, valid])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:45.075887687Z",
     "start_time": "2023-05-07T22:44:45.030695255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "half-true      2362\nfalse          2258\nmostly-true    2213\nbarely-true    1891\ntrue           1845\npants-fire      955\nName: label, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:45.648448115Z",
     "start_time": "2023-05-07T22:44:45.614265438Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "convert_text_labels = lambda x: 1 if x in ['true', 'mostly-true'] else 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:45.648986141Z",
     "start_time": "2023-05-07T22:44:45.615796488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train['label'] = train['label'].apply(convert_text_labels)\n",
    "test['label'] = test['label'].apply(convert_text_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:45.711945497Z",
     "start_time": "2023-05-07T22:44:45.657863669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "count    11524.000000\nmean       106.895783\nstd         58.415051\nmin         11.000000\n25%         73.000000\n50%         99.000000\n75%        133.000000\nmax       3192.000000\nName: text, dtype: float64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].str.len().describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:45.728608048Z",
     "start_time": "2023-05-07T22:44:45.658218547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaFYAFhluSCU",
    "outputId": "cf3c01ae-ba06-4501-d53b-8926d079f411",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:46.207932420Z",
     "start_time": "2023-05-07T22:44:45.828200167Z"
    }
   },
   "outputs": [],
   "source": [
    "# # OLD data\n",
    "# fake = pd.read_csv('../../data/Fake.csv')\n",
    "# true = pd.read_csv('../../data/True.csv')\n",
    "#\n",
    "# fake[\"label\"] = 0\n",
    "# true[\"label\"] = 1\n",
    "#\n",
    "# df = pd.concat([fake, true], ignore_index = True)\n",
    "#\n",
    "# df['text'] = df['title'] + \" \" + df['text']\n",
    "# df.drop(columns=['title', 'date', 'subject'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieOrxB_AuTwA",
    "outputId": "f5f4e1d6-b001-4dab-b81f-7b08125dcdfc",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:46.721441289Z",
     "start_time": "2023-05-07T22:44:45.915242159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/szymon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 773 ms, sys: 4.1 ms, total: 777 ms\n",
      "Wall time: 776 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "    \n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "train['text']=train['text'].apply(denoise_text)\n",
    "test['text']=test['text'].apply(denoise_text)\n",
    "\n",
    "train.to_csv(\"../../data/train.csv\", index=False)\n",
    "test.to_csv(\"../../data/test.csv\", index=False)\n",
    "\n",
    "\n",
    "X_train = train['text'].tolist()\n",
    "y_train = train['label'].tolist()\n",
    "with open(\"../../data/X_train\", \"wb\") as fp:\n",
    "    pickle.dump(X_train, fp)\n",
    "with open(\"../../data/y_train\", \"wb\") as fp:\n",
    "    pickle.dump(y_train, fp)\n",
    "\n",
    "X_test = test['text'].tolist()\n",
    "y_test = test['label'].tolist()\n",
    "with open(\"../../data/X_test\", \"wb\") as fp:\n",
    "    pickle.dump(X_test, fp)\n",
    "with open(\"../../data/y_test\", \"wb\") as fp:\n",
    "    pickle.dump(y_test, fp)\n",
    "\n",
    "\n",
    "train_small = train.sample(frac=1).reset_index(drop=True)[:1000]\n",
    "train_small.to_csv(\"../../data/train_small.csv\", index=False)\n",
    "\n",
    "X_train_small = train_small['text'].tolist()\n",
    "y_train_small = train_small['label'].tolist()\n",
    "with open(\"../../data/small/X_train\", \"wb\") as fp:\n",
    "    pickle.dump(X_train_small, fp)\n",
    "with open(\"../../data/small/y_train\", \"wb\") as fp:\n",
    "    pickle.dump(y_train_small, fp)\n",
    "with open(\"../../data/small/X_test\", \"wb\") as fp:\n",
    "    pickle.dump(X_test, fp)\n",
    "with open(\"../../data/small/y_test\", \"wb\") as fp:\n",
    "    pickle.dump(y_test, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQMXCPQ97YRZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIG7v_fk7jbE"
   },
   "source": [
    "Reduce dataset for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3OAKnGLyuVS0",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:47.684017850Z",
     "start_time": "2023-05-07T22:44:47.575934001Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_original = df.copy()\n",
    "# df = df.sample(frac=1).reset_index(drop=True)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA_tL8Sg7VWO"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-lrFVWwGiwt"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:04:25.619485765Z",
     "start_time": "2023-05-07T23:04:25.609537853Z"
    }
   },
   "outputs": [],
   "source": [
    "redo_embedding = True # recalculate embeddings\n",
    "fast = True # True if use reduced dataset (1000 obs) vs. False if full dataset (40000 obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:48.801047032Z",
     "start_time": "2023-05-07T22:44:48.793951905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 ms, sys: 132 µs, total: 1.92 ms\n",
      "Wall time: 1.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load data\n",
    "\n",
    "# OLD approach ------------------------\n",
    "# if fast:\n",
    "#     df_original = df.copy()\n",
    "#     df = df.sample(frac=1).reset_index(drop=True)[:1000]\n",
    "#\n",
    "# if redo_embedding:\n",
    "#     X = df['text'].tolist()\n",
    "#     y = df['label'].tolist()\n",
    "#\n",
    "#     with open(\"X\", \"wb\") as fp:\n",
    "#       pickle.dump(X, fp)\n",
    "#     with open(\"y\", \"wb\") as fp:\n",
    "#       pickle.dump(y, fp)\n",
    "# elif fast:\n",
    "#     with open(\"../../data/small/X\", \"rb\") as fp:\n",
    "#       X = pickle.load(fp)\n",
    "#     with open(\"../../data/small/y\", \"rb\") as fp:\n",
    "#       y = pickle.load(fp)\n",
    "# else:\n",
    "#     with open(\"../../data/X\", \"rb\") as fp:\n",
    "#       X = pickle.load(fp)\n",
    "#     with open(\"../../data/y\", \"rb\") as fp:\n",
    "#       y = pickle.load(fp)\n",
    "#\n",
    "# if redo_embedding:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#     with open(\"X_train\", \"wb\") as fp:\n",
    "#       pickle.dump(X_train, fp)\n",
    "#     with open(\"X_test\", \"wb\") as fp:\n",
    "#       pickle.dump(X_test, fp)\n",
    "#     with open(\"y_train\", \"wb\") as fp:\n",
    "#       pickle.dump(y_train, fp)\n",
    "#     with open(\"y_test\", \"wb\") as fp:\n",
    "#       pickle.dump(y_test, fp)\n",
    "# elif fast:\n",
    "#     with open(\"../../data/small/X_train\", \"rb\") as fp:\n",
    "#       X_train = pickle.load(fp)\n",
    "#     with open(\"../../data/small/X_test\", \"rb\") as fp:\n",
    "#       X_test = pickle.load(fp)\n",
    "#     with open(\"../../data/small/y_train\", \"rb\") as fp:\n",
    "#       y_train = pickle.load(fp)\n",
    "#     with open(\"../../data/small/y_test\", \"rb\") as fp:\n",
    "#       y_test = pickle.load(fp)\n",
    "# else:\n",
    "#     with open(\"../../data/X_train\", \"rb\") as fp:\n",
    "#       X_train = pickle.load(fp)\n",
    "#     with open(\"../../data/X_test\", \"rb\") as fp:\n",
    "#       X_test = pickle.load(fp)\n",
    "#     with open(\"../../data/y_train\", \"rb\") as fp:\n",
    "#       y_train = pickle.load(fp)\n",
    "#     with open(\"../../data/y_test\", \"rb\") as fp:\n",
    "#       y_test = pickle.load(fp)\n",
    "\n",
    "\n",
    "# NEW approach ------------------------\n",
    "if fast:\n",
    "    with open(\"../../data/small/X_train\", \"rb\") as fp:\n",
    "      X_train = pickle.load(fp)\n",
    "    with open(\"../../data/small/X_test\", \"rb\") as fp:\n",
    "      X_test = pickle.load(fp)\n",
    "    with open(\"../../data/small/y_train\", \"rb\") as fp:\n",
    "      y_train = pickle.load(fp)\n",
    "    with open(\"../../data/small/y_test\", \"rb\") as fp:\n",
    "      y_test = pickle.load(fp)\n",
    "else:\n",
    "    with open(\"../../data/X_train\", \"rb\") as fp:\n",
    "      X_train = pickle.load(fp)\n",
    "    with open(\"../../data/X_test\", \"rb\") as fp:\n",
    "      X_test = pickle.load(fp)\n",
    "    with open(\"../../data/y_train\", \"rb\") as fp:\n",
    "      y_train = pickle.load(fp)\n",
    "    with open(\"../../data/y_test\", \"rb\") as fp:\n",
    "      y_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqQEmeGREcUg"
   },
   "source": [
    "## BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbSRaebguY2a",
    "outputId": "a3fc1906-e2a4-4a92-8d1c-a656f2fdd828",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:49.030977727Z",
     "start_time": "2023-05-07T22:44:48.794411342Z"
    }
   },
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert = AutoModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bert.to(device)\n",
    "\n",
    "    def _get_bert_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512)\n",
    "        input_ids = np.array(input_ids)\n",
    "        input_ids = np.expand_dims(input_ids, axis=0)\n",
    "        input_ids = torch.tensor(input_ids).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert(input_ids)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        return last_hidden_state\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_bert_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_bert = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_bert_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_bert = np.squeeze(X_test_embeddings, axis=1)\n",
    "    \n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_bert).to_csv(\"../../data/small/embeddings/X_train_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_bert).to_csv(\"../../data/small/embeddings/X_test_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_bert).to_csv(\"../../data/embeddings/X_train_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_bert).to_csv(\"../../data/embeddings/X_test_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    \n",
    "elif fast:\n",
    "    X_train_embeddings_bert = pd.read_csv('../../data/small/embeddings/X_train_embeddings_bert.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_bert = pd.read_csv('../../data/small/embeddings/X_test_embeddings_bert.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_bert = pd.read_csv('../../data/embeddings/X_train_embeddings_bert.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_bert = pd.read_csv('../../data/embeddings/X_test_embeddings_bert.csv', sep=',', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhGA1YV7GaKD"
   },
   "source": [
    "## GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:02:04.361948561Z",
     "start_time": "2023-05-07T23:02:04.249613194Z"
    }
   },
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "\n",
    "    def load_glove_embeddings(filename):\n",
    "        embeddings_index = {}\n",
    "        with open(filename) as f:\n",
    "            for line in tqdm(f):\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                if len(values[1:]) == 300:\n",
    "                    coefs = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings_index[word] = coefs\n",
    "        return embeddings_index\n",
    "\n",
    "    glove_embeddings = load_glove_embeddings('../../glove/glove.840B.300d.txt')\n",
    "\n",
    "    def text_to_glove_embeddings(text, embeddings_index, embedding_dim):\n",
    "        embeddings = []\n",
    "        for sentence in text:\n",
    "            sentence_embeddings = []\n",
    "            for word in sentence.split():\n",
    "                if word in embeddings_index:\n",
    "                    sentence_embeddings.append(embeddings_index[word])\n",
    "            if len(sentence_embeddings) > 0:\n",
    "                embeddings.append(np.mean(sentence_embeddings, axis=0))\n",
    "            else:\n",
    "                embeddings.append(np.zeros(embedding_dim))\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    X_train_embeddings_glove = text_to_glove_embeddings(X_train, glove_embeddings, embedding_dim=300)\n",
    "    X_test_embeddings_glove = text_to_glove_embeddings(X_test, glove_embeddings, embedding_dim=300)\n",
    "    \n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_glove).to_csv(\"../../data/small/embeddings/X_train_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_glove).to_csv(\"../../data/small/embeddings/X_test_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_glove).to_csv(\"../../data/embeddings/X_train_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_glove).to_csv(\"../../data/embeddings/X_test_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_glove = pd.read_csv('../../data/small/embeddings/X_train_embeddings_glove.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_glove = pd.read_csv('../../data/small/embeddings/X_test_embeddings_glove.csv', sep=',', header=None).values\n",
    "\n",
    "else:\n",
    "    X_train_embeddings_glove = pd.read_csv('../../data/embeddings/X_train_embeddings_glove.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_glove = pd.read_csv('../../data/embeddings/X_test_embeddings_glove.csv', sep=',', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 15135.06it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 109051.90it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 87078.98it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 186413.51it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 229376.00it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 139810.13it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 131072.00it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 145467.19it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 92794.34it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 118706.72it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 184076.04it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 87746.95it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 202950.19it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 142524.89it/s]\n",
      "  1%|▏         | 14/1000 [00:00<00:07, 139.68it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 152733.76it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 216015.66it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 262144.00it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 126334.46it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 156796.41it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 65196.44it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 240656.79it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 180123.48it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 223101.28it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 266910.25it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 174037.51it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 239674.51it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 224444.36it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 246723.76it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 199728.76it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 83330.54it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 177224.11it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 247939.15it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 207492.07it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 102801.57it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 237413.43it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 229040.49it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 159479.24it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 112851.23it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 249817.48it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 187804.66it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 188205.95it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 266056.60it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 100663.30it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 82241.25it/s]\n",
      "  4%|▍         | 44/1000 [00:00<00:04, 197.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 217321.45it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 118566.90it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 106184.91it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 169711.72it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 307341.24it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 209715.20it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 133576.56it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 200597.15it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 230879.12it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 27743.44it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 71610.07it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 67650.06it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 107334.55it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 140512.70it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 131586.01it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 146312.93it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 205315.58it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 146882.24it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 187454.93it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 150693.56it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 172154.27it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 207638.81it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 159025.74it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 257846.56it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 231943.08it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 189573.06it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 67468.70it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 25515.19it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 71462.58it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 158004.60it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 235323.99it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 107546.26it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 310142.20it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 197557.80it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 125203.10it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 176771.43it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 202950.19it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 67963.26it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 37249.59it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 76029.68it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 100582.83it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 174762.67it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 85890.18it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 148830.14it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 176337.11it/s]\n",
      "  9%|▉         | 89/1000 [00:00<00:03, 302.34it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 183589.06it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 262144.00it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 143395.01it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 164482.51it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 105149.68it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 147766.81it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 240656.79it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 97290.56it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 152307.13it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 197515.70it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 174335.37it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 167772.16it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 185823.59it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 41063.12it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 61560.23it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 50231.19it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 87078.98it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 71933.97it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 95016.60it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 143969.24it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 118149.41it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 62368.83it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 18568.00it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 53773.13it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 11972.32it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 26658.71it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 41425.22it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 25257.94it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 56584.20it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 46995.00it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 72751.88it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 22671.91it/s]\n",
      " 12%|█▏        | 121/1000 [00:00<00:02, 304.35it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 16619.33it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 13706.88it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 80659.69it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 25970.92it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 19905.97it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 48645.28it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 81355.03it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 45039.51it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 33137.84it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 43919.41it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 32695.02it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 11351.30it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 9127.97it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 36247.07it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 29495.81it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 36884.58it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 74048.24it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 20841.26it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 34505.24it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 46247.63it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 154391.56it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 64329.82it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 50291.41it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 104656.34it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 87746.95it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 132219.74it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 109528.68it/s]\n",
      "\n",
      "100%|██████████| 25/25 [00:00<00:00, 186247.96it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 70295.60it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 86184.33it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 64860.37it/s]\n",
      " 15%|█▌        | 152/1000 [00:00<00:03, 281.27it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 101885.93it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 109552.72it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 54330.36it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 88970.08it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 143489.35it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 165928.51it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 143150.31it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 177813.39it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 81920.00it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 125059.52it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 150468.30it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 125059.52it/s]\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 27962.03it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 182361.04it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 141494.59it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 121734.42it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 119350.11it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 109734.70it/s]\n",
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 249784.85it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 176683.14it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 116508.44it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 122705.70it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 178903.96it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 80401.99it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 98883.39it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 138390.74it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 137723.41it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 123361.88it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 111254.75it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 52824.99it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 174762.67it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 77385.68it/s]\n",
      " 18%|█▊        | 184/1000 [00:00<00:02, 293.29it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 81707.22it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 129599.28it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 149796.57it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 43873.47it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 90125.54it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 138742.88it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 94786.53it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 84026.12it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 68598.43it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 123361.88it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 195887.82it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 218453.33it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 129387.27it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 105296.33it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 156894.16it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 49784.02it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 85404.38it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 105916.77it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 58138.87it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 43240.25it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 84368.18it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 121354.18it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 49228.92it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 57587.70it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 84222.97it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 77314.36it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 91333.25it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 59074.70it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 84192.23it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 93047.70it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 96738.48it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 55924.05it/s]\n",
      " 22%|██▏       | 216/1000 [00:00<00:02, 299.75it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 114520.25it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 77385.68it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 63550.06it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 81574.79it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 120295.53it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 79512.87it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 138884.24it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 144216.76it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 101885.93it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 136098.36it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 70690.52it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 133152.51it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 83886.08it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 103648.37it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 141092.80it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 100129.27it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 99600.89it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 115055.72it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 81329.99it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 82727.89it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 121574.03it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 128315.23it/s]\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 26296.58it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 57985.77it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 122760.12it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 37560.93it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 190650.18it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 112222.18it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 153594.23it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 80881.90it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 88434.12it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 173728.57it/s]\n",
      " 25%|██▍       | 248/1000 [00:00<00:02, 304.47it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 106377.28it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 141525.60it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 172960.99it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 68947.46it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 168145.82it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 120266.78it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 83886.08it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 100663.30it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 132173.45it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 84519.98it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 140689.44it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 227951.30it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 117964.80it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 95635.60it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 146970.22it/s]\n",
      "\n",
      "100%|██████████| 35/35 [00:00<00:00, 217160.71it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 143489.35it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 132198.69it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 208227.86it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 91180.52it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 162305.04it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 151487.28it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 98523.92it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 60349.70it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 101917.67it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 148800.14it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 122760.12it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 141836.37it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 91678.78it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 115087.61it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 159133.49it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 49636.73it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 54635.22it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 144988.29it/s]\n",
      " 28%|██▊       | 282/1000 [00:00<00:02, 314.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 99864.38it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 138884.24it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 66225.85it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 97997.76it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 124407.32it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 88612.06it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 176602.27it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 176337.11it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 170879.05it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 166293.99it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 111682.65it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 174762.67it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 117323.19it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 156430.92it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 109100.39it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 115971.54it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 78545.02it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 122282.92it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 231303.53it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 159783.01it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 171429.32it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 101624.11it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 101571.46it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 124460.06it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 132990.13it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 106334.47it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 140530.80it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 122560.83it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 134003.32it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 113359.57it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 135815.56it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 159432.61it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 133759.13it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 206893.92it/s]\n",
      " 32%|███▏      | 316/1000 [00:01<00:02, 320.24it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 227951.30it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 138742.88it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 43240.25it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 77451.64it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 89105.09it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 111308.43it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 77101.18it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 39831.95it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 131798.83it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 91180.52it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 137518.16it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 97769.32it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 95189.88it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 79013.58it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 75166.74it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 52692.26it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 139810.13it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 55084.67it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 57456.22it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 112061.56it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 103138.62it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 72315.59it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 58743.75it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 65027.97it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 150513.30it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 105649.97it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 149553.79it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 139536.53it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 90524.55it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 82510.90it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 109511.85it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 201473.12it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 83582.14it/s]\n",
      " 35%|███▍      | 349/1000 [00:01<00:02, 308.69it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 151767.58it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 54755.93it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 17416.89it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 64280.52it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 65281.00it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 103199.04it/s]\n",
      "\n",
      "100%|██████████| 25/25 [00:00<00:00, 131730.65it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 44417.74it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 70071.90it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 85598.04it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 60611.33it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 136858.29it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 76260.07it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 166818.91it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 59074.70it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 93902.33it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 135300.13it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 159403.48it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 118706.72it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 148830.14it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 185897.13it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 53773.13it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 165202.35it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 176602.27it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 94077.85it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 99126.83it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 107758.80it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 94737.87it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 91846.07it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 58254.22it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 71493.82it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 108590.39it/s]\n",
      " 38%|███▊      | 381/1000 [00:01<00:02, 298.84it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 16600.15it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 95055.05it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 130133.54it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 141381.03it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 170500.16it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 194180.74it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 161798.08it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 148734.18it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 166111.05it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 131072.00it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 181149.34it/s]\n",
      "\n",
      "100%|██████████| 25/25 [00:00<00:00, 154202.35it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 151767.58it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 121574.03it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 43389.35it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 65027.97it/s]\n",
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 191739.61it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 95325.09it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 117397.82it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 141994.67it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 98855.65it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 150333.48it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 98112.37it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 122760.12it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 82062.47it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 105875.63it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 60262.99it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 154464.45it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 89512.59it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 195589.31it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 159614.11it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 152307.13it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 145543.67it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 231182.11it/s]\n",
      " 42%|████▏     | 415/1000 [00:01<00:01, 308.46it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 132104.06it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 97541.95it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 72944.42it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 80401.99it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 191161.31it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 112147.17it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 115632.44it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 198156.09it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 101944.89it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 66275.68it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 154335.86it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 140662.63it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 183814.12it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 114650.68it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 108942.96it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 67432.54it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 108240.10it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 125411.08it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 104278.28it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 112147.17it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 97683.94it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 124275.67it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 69082.65it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 89958.26it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 113359.57it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 51909.70it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 93206.76it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 73954.98it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 166661.09it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 62072.15it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 116757.93it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 117323.19it/s]\n",
      " 45%|████▍     | 447/1000 [00:01<00:01, 311.62it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 102508.45it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 120463.04it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 80659.69it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 86480.49it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 83676.89it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 103350.41it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 82062.47it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 90006.52it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 64826.96it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 69483.95it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 73800.07it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 297468.37it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 179025.17it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 70492.50it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 143804.71it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 234016.96it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 85598.04it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 177608.96it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 175284.35it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 85250.08it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 146934.22it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 143150.31it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 175677.65it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 192989.45it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 141154.46it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 155344.59it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 151340.87it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 179435.47it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 165732.38it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 215092.51it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 127583.39it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 130618.46it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 213528.20it/s]\n",
      " 48%|████▊     | 480/1000 [00:01<00:01, 314.05it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 219310.01it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 181753.17it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 62137.84it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 133683.00it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 220752.84it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 235025.66it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 107088.61it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 143640.55it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 164776.23it/s]\n",
      "\n",
      "100%|██████████| 31/31 [00:00<00:00, 269758.14it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 207638.81it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 100663.30it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 144134.16it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 92691.80it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 166440.63it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 124737.67it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 138273.76it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 96346.95it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 122461.43it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 143150.31it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 209715.20it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 87746.95it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 62601.55it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 192595.59it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 163741.60it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 203184.28it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 134217.73it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 65128.94it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 10272.96it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 41838.44it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 13540.93it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 65536.00it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 31138.11it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 126058.32it/s]\n",
      " 51%|█████▏    | 514/1000 [00:01<00:01, 317.93it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 92618.70it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 176602.27it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 129276.49it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 116105.30it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 133455.13it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 66459.04it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 131705.20it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 115864.75it/s]\n",
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 194330.69it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 130331.48it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 123361.88it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 95325.09it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 187454.93it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 75121.86it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 133642.04it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 29641.72it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 69759.73it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 50686.45it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 86125.34it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 119837.26it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 86659.17it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 60164.20it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 60963.72it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 68759.08it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 79304.07it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 114769.51it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 129653.91it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 48657.82it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 37544.92it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 83385.77it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 86608.05it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 75573.05it/s]\n",
      " 55%|█████▍    | 546/1000 [00:01<00:01, 305.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 159277.37it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 205603.14it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 35772.32it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 114019.91it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 83055.52it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 55627.37it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 110376.42it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 41995.53it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 31985.03it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 62096.02it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 32463.65it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 38682.65it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 26341.04it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 93553.25it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 68120.95it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 58486.31it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 136074.75it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 64693.63it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 69518.85it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 66576.25it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 181235.36it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 163741.60it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 171976.02it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 78293.67it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 99864.38it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 106997.55it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 148168.35it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 152520.15it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 92911.80it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 104256.12it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 123969.58it/s]\n",
      " 58%|█████▊    | 577/1000 [00:01<00:01, 295.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 70374.23it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 139147.53it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 32455.92it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 128902.96it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 112530.11it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 109798.53it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 225313.85it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 148470.94it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 78489.90it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 64035.18it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 27200.42it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 25420.02it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 21836.58it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 43919.41it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 55512.85it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 123908.54it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 68385.39it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 148239.43it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 140591.20it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 137344.97it/s]\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 84222.97it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 23889.45it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 36157.79it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 96791.63it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 46500.04it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 108942.96it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 156683.77it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 64231.30it/s]\n",
      "\n",
      "100%|██████████| 25/25 [00:00<00:00, 104752.85it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 64133.09it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 149796.57it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 230275.51it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 158608.13it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 202950.19it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 141154.46it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 233016.89it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 194672.34it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 46019.01it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 21683.99it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 40672.04it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 77672.30it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 26829.24it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 64157.61it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 98227.26it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 15559.16it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 38130.04it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 88925.17it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 58743.75it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 90103.20it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 87838.83it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 148034.26it/s]\n",
      " 14%|█▍        | 181/1267 [00:00<00:02, 386.43it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 165732.38it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 114130.72it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 140329.87it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 187639.92it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 212211.81it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 108473.38it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 189326.22it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 110792.94it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 130618.46it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 112977.89it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 150284.51it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 100262.25it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 176337.11it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 116972.62it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 93000.09it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 76260.07it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 153535.25it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 76858.97it/s]\n",
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 300487.45it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 298526.98it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 243419.43it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 106184.91it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 125203.10it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 133417.22it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 90687.65it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 112097.21it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 94608.36it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 23527.46it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 212754.55it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 265639.25it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 197637.36it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 166818.91it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 261327.35it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 43464.29it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 68759.08it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 78154.73it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 75346.78it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 103268.85it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 65281.00it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 140985.01it/s]\n",
      " 17%|█▋        | 221/1267 [00:00<00:02, 388.91it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 48884.66it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 198827.05it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 77314.36it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 92794.34it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 181049.09it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 197711.30it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 122164.19it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 218453.33it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 175809.15it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 169125.16it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 59353.36it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 219214.49it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 181796.46it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 90851.35it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 184076.04it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 210240.80it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 152059.36it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 164189.84it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 84611.32it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 249311.78it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 212369.82it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 167772.16it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 241705.65it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 259441.48it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 209715.20it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 61380.06it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 77152.75it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 56789.42it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 77912.77it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 69775.85it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 111423.64it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 101475.10it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 94254.02it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 120027.78it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 115505.79it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 85598.04it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 95325.09it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 154798.57it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 102612.94it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 141381.03it/s]\n",
      " 21%|██        | 261/1267 [00:00<00:02, 367.62it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 139452.56it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 141258.94it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 86928.58it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 80919.05it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 70889.65it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 151967.54it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 77195.78it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 142987.64it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 176231.26it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 264756.73it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 143150.31it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 201556.94it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 190650.18it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 180788.97it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 123692.61it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 116508.44it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 154903.27it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 156587.35it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 74308.54it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 61119.18it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 50457.79it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 71224.03it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 64527.75it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 137668.62it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 138390.74it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 118483.16it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 77433.30it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 133455.13it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 83330.54it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 127745.30it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 60349.70it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 32665.92it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 86724.33it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 83582.14it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 78643.20it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 77672.30it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 128266.18it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 127583.39it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 128210.17it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 162885.59it/s]\n",
      " 24%|██▍       | 301/1267 [00:00<00:02, 375.54it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 129339.77it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 185588.67it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 100764.06it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 14671.10it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 63657.23it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 68634.07it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 83607.39it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 103477.89it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 124583.29it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 109931.35it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 132149.30it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 99318.67it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 64089.53it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 115819.05it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 54917.24it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 92182.51it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 89936.34it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 115831.07it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 95325.09it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 87685.80it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 88725.66it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 110231.38it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 109226.67it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 117501.82it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 72315.59it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 93526.50it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 69905.07it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 64956.04it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 120241.43it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 100462.37it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 86381.55it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 73441.12it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 152705.24it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 112447.83it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 88487.43it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 126081.28it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 183589.06it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 160757.30it/s]\n",
      " 27%|██▋       | 339/1267 [00:00<00:02, 371.35it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 155986.51it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 146143.00it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 75301.69it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 15982.65it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 39199.10it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 143768.99it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 50291.41it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 105590.87it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 108942.96it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 78643.20it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 127327.09it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 82601.17it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 56552.41it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 112061.56it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 87051.59it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 62446.21it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 63019.59it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 83147.00it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 88404.53it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 119435.79it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 79137.81it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 78479.70it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 16320.25it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 20400.31it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 70407.98it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 68634.07it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 100548.38it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 107941.65it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 78106.22it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 80573.61it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 133152.51it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 93206.76it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 134300.37it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 137650.90it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 107546.26it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 124025.12it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 137268.13it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 186413.51it/s]\n",
      " 30%|██▉       | 377/1267 [00:01<00:02, 349.56it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 115704.94it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 96698.65it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 133505.70it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 59074.70it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 94543.74it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 106184.91it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 63429.93it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 82891.38it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 50533.78it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 104656.34it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 43886.59it/s]\n",
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 192937.98it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 82704.59it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 139810.13it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 142987.64it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 110792.94it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 206991.63it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 125672.03it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 210372.61it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 36684.87it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 91180.52it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 169581.02it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 237413.43it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 172154.27it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 131528.70it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 189216.72it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 145888.83it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 198468.64it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 91678.78it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 82241.25it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 124583.29it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 161319.38it/s]\n",
      "\n",
      "100%|██████████| 27/27 [00:00<00:00, 218200.79it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 240298.67it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 95144.89it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 118149.41it/s]\n",
      " 33%|███▎      | 413/1267 [00:01<00:02, 350.69it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 175890.17it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 110376.42it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 126009.13it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 194845.42it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 71331.70it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 114688.00it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 142582.57it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 145955.63it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 68385.39it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 178481.02it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 97541.95it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 57587.70it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 126588.65it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 87078.98it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 104670.69it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 123937.44it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 112490.91it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 119636.19it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 124460.06it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 62601.55it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 108162.57it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 145467.19it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 154441.43it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 170808.76it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 126673.61it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 155006.89it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 56048.61it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 94371.84it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 75573.05it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 100517.09it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 129339.77it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 103350.41it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 86579.67it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 128923.28it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 79739.62it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 69905.07it/s]\n",
      " 35%|███▌      | 449/1267 [00:01<00:02, 338.00it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 69905.07it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 73103.34it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 90307.98it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 95919.63it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 153567.19it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 127100.12it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 109850.82it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 77993.26it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 119269.31it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 105443.40it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 17331.83it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 81329.99it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 172368.66it/s]\n",
      "\n",
      "100%|██████████| 29/29 [00:00<00:00, 294515.29it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 137196.86it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 59283.45it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 91000.68it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 88925.17it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 153567.19it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 117964.80it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 117964.80it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 168333.27it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 183357.55it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 102927.71it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 154076.47it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 172154.27it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 51542.91it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 103268.85it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 48279.76it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 61862.89it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 146143.00it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 215092.51it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 127652.73it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 257122.08it/s]\n",
      " 38%|███▊      | 483/1267 [00:01<00:02, 337.98it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 187106.50it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 112347.43it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 181309.97it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 142840.07it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 146312.93it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 110376.42it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 185497.47it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 127421.89it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 124583.29it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 141525.60it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 48960.75it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 144216.76it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 190141.78it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 106334.47it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 88168.55it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 45262.27it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 114044.52it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 140591.20it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 116078.52it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 96791.63it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 102023.61it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 150094.38it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 105336.40it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 127583.39it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 63743.22it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 143089.26it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 128397.06it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 154771.37it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 236775.23it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 149311.79it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 122560.83it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 219862.71it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 136400.13it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 210416.59it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 149796.57it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 134756.76it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 170879.05it/s]\n",
      " 41%|████      | 520/1267 [00:01<00:02, 344.64it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 269153.20it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 173448.66it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 142784.82it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 196388.82it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 238162.37it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 153567.19it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 82241.25it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 168192.64it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 147367.44it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 144943.55it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 155344.59it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 45100.04it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 99568.05it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 82420.82it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 51995.50it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 192841.56it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 144010.44it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 197844.53it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 242270.27it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 194672.34it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 149130.81it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 172605.10it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 156633.76it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 246723.76it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 138654.68it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 155344.59it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 181571.60it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 155344.59it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 245920.10it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 148470.94it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 142784.82it/s]\n",
      "\n",
      "100%|██████████| 24/24 [00:00<00:00, 234646.38it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 203455.04it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 143640.55it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 191992.79it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 182361.04it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 117597.31it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 244667.73it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 263319.53it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 165876.43it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 174762.67it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 179755.89it/s]\n",
      " 44%|████▍     | 562/1267 [00:01<00:01, 364.48it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 255750.24it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 179435.47it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 229539.02it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 128659.63it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 259824.14it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 177224.11it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 241979.08it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 297096.53it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 274393.72it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 167772.16it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 180270.95it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 218721.37it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 146653.99it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 222214.78it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 98304.00it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 146004.25it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 122910.01it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 89621.88it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 97921.49it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 191271.19it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 99189.62it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 155869.41it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 129912.07it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 189087.48it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 189930.75it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 167029.81it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 205758.31it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 201473.12it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 154628.72it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 131758.24it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 119269.31it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 152520.15it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 150775.63it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 200463.06it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 192105.53it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 229376.00it/s]\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 46863.73it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 150468.30it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 127652.73it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 140479.08it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 229824.88it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 218453.33it/s]\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 64035.18it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 200791.15it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 316835.91it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 208968.88it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 170808.76it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 167772.16it/s]\n",
      " 48%|████▊     | 610/1267 [00:01<00:01, 396.38it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 131659.77it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 151146.09it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 183084.70it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 156503.88it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 156397.78it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 105517.08it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 91907.06it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 61422.86it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 99391.09it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 15650.39it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 88612.06it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 115766.35it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 93848.45it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 92691.80it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 139191.50it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 83220.32it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 91401.30it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 147291.61it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 90092.45it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 122806.20it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 90307.98it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 148800.14it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 18631.00it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 101270.92it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 80466.26it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 105336.40it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 106861.25it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 68049.18it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 78925.08it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 139810.13it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 93775.09it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 75743.64it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 62869.65it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 107546.26it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 45466.71it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 58389.38it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 121826.26it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 141579.88it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 143531.32it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 201947.97it/s]\n",
      " 51%|█████▏    | 650/1267 [00:01<00:01, 378.16it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 276114.06it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 253432.27it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 115439.56it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 221585.87it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 145257.28it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 120989.54it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 198064.36it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 209715.20it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 244922.86it/s]\n",
      "\n",
      "100%|██████████| 25/25 [00:00<00:00, 293718.77it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 159952.27it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 204984.78it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 139810.13it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 218290.91it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 199728.76it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 180930.76it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 61166.93it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 54189.97it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 78398.21it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 82964.25it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 76858.97it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 81442.80it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 84346.15it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 76398.98it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 74898.29it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 105738.76it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 145748.02it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 94893.76it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 124045.96it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 101067.57it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 176868.24it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 125829.12it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 113359.57it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 141699.46it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 121378.57it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 63550.06it/s]\n",
      "\n",
      "100%|██████████| 26/26 [00:00<00:00, 143112.73it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 101067.57it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 27462.70it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 157567.77it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 138084.08it/s]\n",
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 114912.44it/s]\n",
      " 55%|█████▍    | 693/1267 [00:01<00:01, 391.35it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 77060.70it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 48865.68it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 137518.16it/s]\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 71392.41it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 118387.61it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 157944.50it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 40960.00it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 135518.71it/s]\n",
      "\n",
      "100%|██████████| 21/21 [00:00<00:00, 122333.87it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 103446.96it/s]\n",
      "\n",
      "100%|██████████| 323/323 [00:00<00:00, 450535.48it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 99864.38it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 137723.41it/s]\n",
      "\n",
      "100%|██████████| 25/25 [00:00<00:00, 241051.95it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 107892.06it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 87381.33it/s]\n",
      "\n",
      "100%|██████████| 22/22 [00:00<00:00, 138342.86it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 77672.30it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 55043.36it/s]\n",
      "\n",
      "100%|██████████| 19/19 [00:00<00:00, 129580.12it/s]\n",
      "\n",
      "100%|██████████| 26/26 [00:00<00:00, 137344.97it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 94893.76it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 74518.09it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 105819.60it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 107546.26it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 129553.79it/s]\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 35444.82it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 86381.55it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 64669.89it/s]\n",
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 146113.05it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 92589.49it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 74415.07it/s]\n",
      "\n",
      "100%|██████████| 18/18 [00:00<00:00, 131758.24it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 70577.23it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 63913.20it/s]\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 57852.47it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 109931.35it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 91180.52it/s]\n",
      "\n",
      "100%|██████████| 6/6 [00:00<00:00, 63872.65it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 115591.06it/s]\n",
      " 58%|█████▊    | 733/1267 [00:01<00:01, 350.84it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 107546.26it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 90524.55it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 162011.74it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 207492.07it/s]\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 200463.06it/s]\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 123882.40it/s]\n",
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 177451.32it/s]\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 208412.62it/s]\n",
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 215883.29it/s]\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 161319.38it/s]\n",
      "\n",
      "100%|██████████| 15/15 [00:00<00:00, 227951.30it/s]\n",
      "\n",
      "100%|██████████| 28/28 [00:00<00:00, 333637.82it/s]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 174762.67it/s]\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 101803.50it/s]\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 273244.56it/s]\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if redo_embedding:\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('../../word2vec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "def get_word2vec_embeddings(text):\n",
    "    embeddings = []\n",
    "    for sentence in tqdm(text):\n",
    "        tokens = sentence.split()\n",
    "        doc_vecs = [model[token] for token in tokens if token in model.key_to_index]\n",
    "        if len(doc_vecs) > 0:\n",
    "            doc_vec = np.mean(doc_vecs, axis=0)\n",
    "            embeddings.append(doc_vec)\n",
    "        else:\n",
    "            embeddings.append([0] * 300) # if vocabulary does not exist in Word2Vec append a vector of zeros\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "if redo_embedding:\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    X_train_embeddings_word2vec = get_word2vec_embeddings(X_train)\n",
    "    X_test_embeddings_word2vec = get_word2vec_embeddings(X_test)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_word2vec).to_csv(\"../../data/small/embeddings/X_train_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_word2vec).to_csv(\"../../data/small/embeddings/X_test_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_word2vec).to_csv(\"../../data/embeddings/X_train_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_word2vec).to_csv(\"../../data/embeddings/X_test_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_word2vec = pd.read_csv('../../data/small/embeddings/X_train_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_word2vec = pd.read_csv('../../data/small/embeddings/X_test_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "\n",
    "else:\n",
    "    X_train_embeddings_word2vec = pd.read_csv('../../data/embeddings/X_train_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_word2vec = pd.read_csv('../../data/embeddings/X_test_embeddings_word2vec.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:21:39.772718271Z",
     "start_time": "2023-05-07T23:20:47.702440507Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gpt2.to(device)\n",
    "\n",
    "    def _get_gpt2_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=1024)\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = gpt2.transformer.wte(input_ids)\n",
    "            mean_embedding = embeddings.mean(dim=1)\n",
    "        #     outputs = bert(input_ids)\n",
    "        #     last_hidden_state = outputs.last_hidden_state\n",
    "        #     last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "            #vector = gpt2.transformer.wte.weight[input_ids,:]\n",
    "        mean_embedding = mean_embedding.cpu().numpy()\n",
    "        return mean_embedding\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_gpt2_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_gpt2 = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_gpt2_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_gpt2 = np.squeeze(X_test_embeddings, axis=1)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_gpt2).to_csv(\"../../data/small/embeddings/X_train_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_gpt2).to_csv(\"../../data/small/embeddings/X_test_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_gpt2).to_csv(\"../../data/embeddings/X_train_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_gpt2).to_csv(\"../../data/embeddings/X_test_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_gpt2 = pd.read_csv('../../data/small/embeddings/X_train_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_gpt2 = pd.read_csv('../../data/small/embeddings/X_test_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_gpt2 = pd.read_csv('../../data/embeddings/X_train_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_gpt2 = pd.read_csv('../../data/embeddings/X_test_embeddings_gpt2.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:50.925384332Z",
     "start_time": "2023-05-07T22:44:50.600597382Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    roberta = AutoModel.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    roberta.to(device)\n",
    "\n",
    "    def _get_roberta_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512)\n",
    "        input_ids = np.array(input_ids)\n",
    "        input_ids = np.expand_dims(input_ids, axis=0)\n",
    "        input_ids = torch.tensor(input_ids).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = roberta(input_ids)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        return last_hidden_state\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_roberta_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_roberta = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_roberta_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_roberta = np.squeeze(X_test_embeddings, axis=1)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_roberta).to_csv(\"../../data/small/embeddings/X_train_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_roberta).to_csv(\"../../data/small/embeddings/X_test_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_roberta).to_csv(\"../../data/embeddings/X_train_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_roberta).to_csv(\"../../data/embeddings/X_test_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_roberta = pd.read_csv('../../data/small/embeddings/X_train_embeddings_roberta.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_roberta = pd.read_csv('../../data/small/embeddings/X_test_embeddings_roberta.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_roberta = pd.read_csv('../../data/embeddings/X_train_embeddings_roberta.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_roberta = pd.read_csv('../../data/embeddings/X_test_embeddings_roberta.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:51.806290889Z",
     "start_time": "2023-05-07T22:44:51.506679729Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMvpJtV-EiIo"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:57.028869089Z",
     "start_time": "2023-05-07T22:44:56.998356730Z"
    }
   },
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, n_neighbors=2, weights='uniform', metric='minkowski'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = KNeighborsClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.n_neighbors = random_search.best_params_['n_neighbors']\n",
    "        self.weights = random_search.best_params_['weights']\n",
    "        self.metric = random_search.best_params_['metric']\n",
    "\n",
    "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:57.383466953Z",
     "start_time": "2023-05-07T22:44:57.310402837Z"
    }
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier:\n",
    "    def __init__(self, learning_rate=0.1, max_depth=5, min_child_weight=1, subsample=0.5, colsample_bytree=0.5, n_estimators=100, objective='req:squarederror'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.n_estimators = n_estimators\n",
    "        self.objective = objective\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = xgb.XGBClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.learning_rate = random_search.best_params_['learning_rate']\n",
    "        self.max_depth = random_search.best_params_['max_depth']\n",
    "        self.min_child_weight = random_search.best_params_['min_child_weight']\n",
    "        self.subsample = random_search.best_params_['subsample']\n",
    "        self.colsample_bytree = random_search.best_params_['colsample_bytree']\n",
    "        self.n_estimators = random_search.best_params_['n_estimators']\n",
    "        self.objective = random_search.best_params_['objective']\n",
    "\n",
    "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:57.648081482Z",
     "start_time": "2023-05-07T22:44:57.580320765Z"
    }
   },
   "outputs": [],
   "source": [
    "class RFClassifier:\n",
    "    def __init__(self, n_estimators=100, max_features='sqrt', max_depth='none', bootstrap=True):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.bootstrap = bootstrap\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap, verbose=True)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = RandomForestClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.n_estimators = random_search.best_params_['n_estimators']\n",
    "        self.max_features = random_search.best_params_['max_features']\n",
    "        self.max_depth = random_search.best_params_['max_depth']\n",
    "        self.bootstrap = random_search.best_params_['bootstrap']\n",
    "\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:58.249356711Z",
     "start_time": "2023-05-07T22:44:58.139968961Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVClassifier:\n",
    "    def __init__(self, C = 1, kernel='linear', gamma = 0.2):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma, verbose=True)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = svm.SVC()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.C = random_search.best_params_['C']\n",
    "        self.kernel = random_search.best_params_['kernel']\n",
    "        self.gamma = random_search.best_params_['gamma']\n",
    "\n",
    "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:58.842465149Z",
     "start_time": "2023-05-07T22:44:58.777239176Z"
    }
   },
   "outputs": [],
   "source": [
    "class LRClassifier:\n",
    "    def __init__(self, penalty = 'l2', solver = 'libinear', C = 0.5):\n",
    "        self.penalty = penalty\n",
    "        self.solver = solver\n",
    "        self.C = C\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = LogisticRegression()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, scoring=\"f1\", verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        print('Best parameters:', random_search.best_params_, '\\n')\n",
    "        self.penalty = random_search.best_params_['penalty']\n",
    "        self.solver = random_search.best_params_['solver']\n",
    "        self.C = random_search.best_params_['C']\n",
    "\n",
    "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class FakeNewsClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
    "        super(FakeNewsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "class NeuralNetworkClassifier:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=2):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train, num_epochs=10, lr=0.001):\n",
    "        self.model = FakeNewsClassifier(self.input_dim, self.hidden_dim, self.output_dim)\n",
    "        self.model = self.model.double()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        for _ in tqdm(range(num_epochs), desc=\"Epoch\"):\n",
    "            for embedding, label in zip(X_train, y_train):\n",
    "                embedding_tensor = torch.from_numpy(embedding).double().unsqueeze(0)\n",
    "                label_tensor = torch.tensor([label])\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(embedding_tensor)\n",
    "                loss = criterion(outputs, label_tensor)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        test_inputs = torch.from_numpy(X_test).double()\n",
    "        predictions = self.model(test_inputs)\n",
    "        predicted_classes = torch.argmax(predictions, dim=1)\n",
    "        predicted_classes = predicted_classes.numpy()\n",
    "        return predicted_classes\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100, 1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:44:59.519296030Z",
     "start_time": "2023-05-07T22:44:59.413850056Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlaJrgisGNfg"
   },
   "source": [
    "## BERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMOZaIWp0_oy"
   },
   "source": [
    "### BERT + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "7HzI3FV7zy6t",
    "outputId": "8ca1830c-a309-4f27-f6dd-cee648ee0978",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:45:10.351331545Z",
     "start_time": "2023-05-07T22:45:07.166850957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.403 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.431 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.349 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.304 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.384 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.295 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.390 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.248 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.269 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.362 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.319 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.388 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.318 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.224 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.434 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.275 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.270 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.183 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.344 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.312 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.359 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.234 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.243 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.349 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.391 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.315 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.386 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.336 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.412 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.258 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.328 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.385 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.369 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.326 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.316 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.411 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.369 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.183 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.252 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.347 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.331 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.299 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.226 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.248 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.388 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.391 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.315 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.386 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.210 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.216 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.192 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.144 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.214 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.288 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.391 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.288 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.315 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.386 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.369 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.183 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.252 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.347 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.257 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.242 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.165 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.178 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.212 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.336 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.412 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.258 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.328 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.385 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.275 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.270 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.183 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.344 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.338 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.371 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.245 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.305 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.424 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.224 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.231 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.226 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.120 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.310 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.275 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.288 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.270 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.183 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.344 total time=   0.0s\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 2, 'metric': 'euclidean'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[508 310]\n",
      " [284 165]] \n",
      "\n",
      "Accuracy: 53.1 \n",
      "\n",
      "F1 Score: 35.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_bert_train, accuracy_knn_bert_train, f1_knn_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_bert_test, accuracy_knn_bert_test, f1_knn_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg4FzG2htmwr"
   },
   "source": [
    "### BERT + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psJLbuc_win3",
    "outputId": "554936c2-e2c5-4b6f-df80-f9e4054f0dbe",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:47:24.624941644Z",
     "start_time": "2023-05-07T22:45:10.356610194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.364 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.409 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.318 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.366 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.316 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.299 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.326 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.395 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.376 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.321 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.411 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.366 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.338 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.369 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.369 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.372 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.373 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.424 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.413 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.418 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.446 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.365 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.241 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.338 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.447 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.273 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.115 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.138 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.048 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.046 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.050 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.135 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.146 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.118 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.093 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.072 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.357 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.392 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.344 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.336 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.359 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.092 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.025 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.049 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.025 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.326 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.341 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.411 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.264 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.336 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.460 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.386 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.372 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.382 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.437 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.149 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.170 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.140 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.067 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.114 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.368 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.356 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.353 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.427 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.405 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.306 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.449 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.281 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.361 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.264 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.268 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.204 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.183 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.146 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.339 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.330 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.319 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.204 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.048 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.119 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.026 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.025 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.075 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.317 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.255 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.243 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.293 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.216 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.384 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.281 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.350 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.304 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.294 total time=   0.6s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.5, 'colsample_bytree': 0.5} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[502 316]\n",
      " [288 161]] \n",
      "\n",
      "Accuracy: 52.3 \n",
      "\n",
      "F1 Score: 34.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_bert_train, accuracy_xgb_bert_train, f1_xgb_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_bert_test, accuracy_xgb_bert_test, f1_xgb_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekftGhJPFFFX"
   },
   "source": [
    "### BERT + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ks6w5IOrJYG",
    "outputId": "0341c3cf-975e-4e0c-8a26-01064b132ae1",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:47:32.822016179Z",
     "start_time": "2023-05-07T22:47:24.627664738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.162 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.204 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.218 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.235 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.216 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.264 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.144 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.220 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.269 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.200 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.198 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.224 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.222 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.173 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.124 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.180 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.189 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.176 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.191 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.208 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.192 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.143 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.141 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.163 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.108 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.162 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.224 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.275 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.157 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.243 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.208 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.262 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.122 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.214 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.158 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.259 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.081 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.267 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.162 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.286 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.321 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.128 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.136 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.283 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.136 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.156 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.189 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.128 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.133 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.108 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.048 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.189 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.212 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.222 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.232 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.220 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.170 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.132 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.196 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.194 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.114 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.158 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.165 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.189 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.186 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.216 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.206 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.086 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.352 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.242 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.170 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.084 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.045 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.163 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.196 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.283 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.086 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.269 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.220 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.163 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.068 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.154 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.200 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.292 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.063 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.146 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.196 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.320 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.216 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.210 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.099 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.232 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.255 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.239 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.233 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.100 total time=   0.0s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 10, 'max_depth': 10, 'bootstrap': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[633   1]\n",
      " [ 34 332]] \n",
      "\n",
      "Accuracy: 96.5 \n",
      "\n",
      "F1 Score: 95.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[657 161]\n",
      " [372  77]] \n",
      "\n",
      "Accuracy: 57.9 \n",
      "\n",
      "F1 Score: 22.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25], \n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_bert_train, accuracy_rf_bert_train, f1_rf_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_bert_test, accuracy_rf_bert_test, f1_rf_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbX9j48J1a9j"
   },
   "source": [
    "### BERT + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSTFuYyH63Mk",
    "outputId": "6ba15a33-8e98-4a4e-9113-8c771dc0dede",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:47:48.134280209Z",
     "start_time": "2023-05-07T22:47:32.803606937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.384 total time=   0.2s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.365 total time=   0.2s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.378 total time=   0.2s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.351 total time=   0.2s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.351 total time=   0.2s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.411 total time=   0.3s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.381 total time=   0.3s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.342 total time=   0.2s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.346 total time=   0.3s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.377 total time=   0.3s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.315 total time=   0.2s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.365 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.339 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.385 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.339 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.336 total time=   0.2s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.283 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.272 total time=   0.2s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.328 total time=   0.2s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.196 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.196 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.252 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.245 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.168 total time=   0.2s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.411 total time=   0.3s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.381 total time=   0.3s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.342 total time=   0.3s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.346 total time=   0.3s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.377 total time=   0.3s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.351 total time=   0.2s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.444 total time=   0.2s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.346 total time=   0.2s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.377 total time=   0.2s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.323 total time=   0.2s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.358 total time=   0.2s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.440 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.358 total time=   0.2s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.369 total time=   0.2s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.343 total time=   0.2s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.380 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.370 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.392 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.377 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.411 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.411 total time=   0.3s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.381 total time=   0.3s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.342 total time=   0.3s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.346 total time=   0.3s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.377 total time=   0.3s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.351 total time=   0.2s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.444 total time=   0.2s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.346 total time=   0.2s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.377 total time=   0.2s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.323 total time=   0.2s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.358 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.440 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.358 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.369 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.343 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.411 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.319 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.367 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.387 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.411 total time=   0.1s\n",
      "Best parameters: {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 100} \n",
      "\n",
      "[LibSVM]..*.*..*\n",
      "optimization finished, #iter = 5531\n",
      "obj = -188925.256460, rho = -126.620439\n",
      "nSV = 508, nBSV = 421\n",
      "Total nSV = 508\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[445 189]\n",
      " [199 167]] \n",
      "\n",
      "Accuracy: 61.2 \n",
      "\n",
      "F1 Score: 46.3 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[483 335]\n",
      " [294 155]] \n",
      "\n",
      "Accuracy: 50.4 \n",
      "\n",
      "F1 Score: 33.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_bert_train, accuracy_svc_bert_train, f1_svc_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_bert_test, accuracy_svc_bert_test, f1_svc_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYoz0OB11ayT"
   },
   "source": [
    "### BERT + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YijN0v7JCFbG",
    "outputId": "4bf95058-f264-43c2-e84d-1572b4814428",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:48:07.460881427Z",
     "start_time": "2023-05-07T22:47:48.119432837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.84, penalty=none, solver=sag;, score=0.384 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.84, penalty=none, solver=sag;, score=0.381 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.84, penalty=none, solver=sag;, score=0.400 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.84, penalty=none, solver=sag;, score=0.384 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.84, penalty=none, solver=sag;, score=0.343 total time=   0.4s\n",
      "[CV 1/5] END C=0.31, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.31, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.31, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.31, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.31, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.93, penalty=l1, solver=liblinear;, score=0.331 total time=   0.6s\n",
      "[CV 2/5] END C=0.93, penalty=l1, solver=liblinear;, score=0.371 total time=   0.4s\n",
      "[CV 3/5] END C=0.93, penalty=l1, solver=liblinear;, score=0.283 total time=   0.6s\n",
      "[CV 4/5] END C=0.93, penalty=l1, solver=liblinear;, score=0.350 total time=   0.5s\n",
      "[CV 5/5] END C=0.93, penalty=l1, solver=liblinear;, score=0.351 total time=   0.5s\n",
      "[CV 1/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......C=0.76, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.76, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.76, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.76, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.76, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.85, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.85, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.85, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.85, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.85, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.34, penalty=l2, solver=newton-cg;, score=0.312 total time=   0.2s\n",
      "[CV 2/5] END C=0.34, penalty=l2, solver=newton-cg;, score=0.392 total time=   0.3s\n",
      "[CV 3/5] END C=0.34, penalty=l2, solver=newton-cg;, score=0.317 total time=   0.2s\n",
      "[CV 4/5] END C=0.34, penalty=l2, solver=newton-cg;, score=0.365 total time=   0.2s\n",
      "[CV 5/5] END C=0.34, penalty=l2, solver=newton-cg;, score=0.317 total time=   0.2s\n",
      "[CV 1/5] END .....C=0.0, penalty=l2, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=0.0, penalty=l2, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=0.0, penalty=l2, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=0.0, penalty=l2, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=0.0, penalty=l2, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:811: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1.0 / C, sample_weight),\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + 0.5 * alpha * np.dot(w, w)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:127: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:811: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1.0 / C, sample_weight),\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + 0.5 * alpha * np.dot(w, w)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:127: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:811: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1.0 / C, sample_weight),\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + 0.5 * alpha * np.dot(w, w)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:127: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:811: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1.0 / C, sample_weight),\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + 0.5 * alpha * np.dot(w, w)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:127: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:811: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1.0 / C, sample_weight),\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + 0.5 * alpha * np.dot(w, w)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:127: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.222 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.281 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.220 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.237 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.212 total time=   0.8s\n",
      "[CV 1/5] END C=0.86, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.86, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.86, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.86, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.86, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......C=0.05, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.05, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.05, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.05, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.05, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.99, penalty=l2, solver=saga;, score=0.308 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.99, penalty=l2, solver=saga;, score=0.400 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.99, penalty=l2, solver=saga;, score=0.385 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.99, penalty=l2, solver=saga;, score=0.397 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.99, penalty=l2, solver=saga;, score=0.304 total time=   0.5s\n",
      "[CV 1/5] END C=0.97, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.97, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.97, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.97, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.97, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5700000000000001, penalty=l2, solver=liblinear;, score=0.328 total time=   0.2s\n",
      "[CV 2/5] END C=0.5700000000000001, penalty=l2, solver=liblinear;, score=0.397 total time=   0.2s\n",
      "[CV 3/5] END C=0.5700000000000001, penalty=l2, solver=liblinear;, score=0.361 total time=   0.3s\n",
      "[CV 4/5] END C=0.5700000000000001, penalty=l2, solver=liblinear;, score=0.371 total time=   0.2s\n",
      "[CV 5/5] END C=0.5700000000000001, penalty=l2, solver=liblinear;, score=0.306 total time=   0.2s\n",
      "[CV 1/5] END ....C=0.92, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.92, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.92, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.92, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.92, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.8200000000000001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8200000000000001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8200000000000001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8200000000000001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8200000000000001, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.78, penalty=none, solver=saga;, score=0.350 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.78, penalty=none, solver=saga;, score=0.395 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.78, penalty=none, solver=saga;, score=0.397 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.78, penalty=none, solver=saga;, score=0.400 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.78, penalty=none, solver=saga;, score=0.331 total time=   0.5s\n",
      "[CV 1/5] END C=0.32, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.32, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.32, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.32, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.32, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.46, penalty=l2, solver=sag;, score=0.323 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=0.46, penalty=l2, solver=sag;, score=0.403 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.46, penalty=l2, solver=sag;, score=0.341 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=0.46, penalty=l2, solver=sag;, score=0.374 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
      "    fold_coefs_ = Parallel(\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 806, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py\", line 362, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 122, in _logistic_loss_and_grad\n",
      "    out = -np.sum(sample_weight * log_logistic(yz)) + 0.5 * alpha * np.dot(w, w)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py\", line 785, in log_logistic\n",
      "    X = check_array(X, dtype=np.float64)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.37829543        nan 0.33727944        nan        nan        nan\n",
      " 0.34063978        nan 0.23438681        nan        nan 0.35880812\n",
      "        nan 0.35288018        nan        nan 0.37456174        nan\n",
      " 0.34722453        nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=0.46, penalty=l2, solver=sag;, score=0.295 total time=   0.4s\n",
      "[CV 1/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'solver': 'sag', 'penalty': 'none', 'C': 0.84} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[618  16]\n",
      " [ 41 325]] \n",
      "\n",
      "Accuracy: 94.3 \n",
      "\n",
      "F1 Score: 91.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[511 307]\n",
      " [291 158]] \n",
      "\n",
      "Accuracy: 52.8 \n",
      "\n",
      "F1 Score: 34.6 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_bert_train, accuracy_lr_bert_train, f1_lr_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_bert_test, accuracy_lr_bert_test, f1_lr_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BERT + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [01:44<00:00, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[615  19]\n",
      " [222 144]] \n",
      "\n",
      "Accuracy: 75.9 \n",
      "\n",
      "F1 Score: 54.4 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[699 119]\n",
      " [393  56]] \n",
      "\n",
      "Accuracy: 59.6 \n",
      "\n",
      "F1 Score: 17.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_bert.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_bert.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_bert, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_bert_train, accuracy_nn_bert_train, f1_nn_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_bert_test, accuracy_nn_bert_test, f1_nn_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:49:52.260097145Z",
     "start_time": "2023-05-07T22:48:07.464626945Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uSk7WKhGB1v"
   },
   "source": [
    "## GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1D_jiR2GI7H"
   },
   "source": [
    "### GloVe + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LA5swddzG28v",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:49:54.135352017Z",
     "start_time": "2023-05-07T22:49:52.216015694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.392 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.360 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.385 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.341 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.279 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.392 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.360 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.385 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.341 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.279 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.408 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.331 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.442 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.324 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.305 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.333 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.365 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.353 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.420 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.376 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.309 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.437 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.347 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.325 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.397 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.462 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.444 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.319 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.220 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.364 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.294 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.256 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.375 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.348 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.444 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.394 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.303 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.360 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.173 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.268 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.276 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.352 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.307 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.369 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.426 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.279 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.405 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.324 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.351 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.275 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.347 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.306 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.336 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.234 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.423 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.320 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.461 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.349 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.331 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.333 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.365 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.353 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.420 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.288 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.428 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.307 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.455 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.375 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.342 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.376 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.309 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.437 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.347 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.325 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.314 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.171 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.214 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.296 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.360 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.173 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.268 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.276 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.427 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.316 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.476 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.421 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.344 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.330 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.317 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.336 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.270 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.212 total time=   0.0s\n",
      "Best parameters: {'weights': 'uniform', 'n_neighbors': 5, 'metric': 'minkowski'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[506 128]\n",
      " [161 205]] \n",
      "\n",
      "Accuracy: 71.1 \n",
      "\n",
      "F1 Score: 58.7 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[525 293]\n",
      " [293 156]] \n",
      "\n",
      "Accuracy: 53.7 \n",
      "\n",
      "F1 Score: 34.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_glove_train, accuracy_knn_glove_train, f1_knn_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_glove_test, accuracy_knn_glove_test, f1_knn_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Lfsat69GIoJ"
   },
   "source": [
    "### GloVe + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "rt7c3MSPG3PP",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:50:49.109469883Z",
     "start_time": "2023-05-07T22:49:54.138482569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.065 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.172 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.180 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.045 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.122 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.110 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.111 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.146 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.095 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.067 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.358 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.305 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.403 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.288 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.408 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.294 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.408 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.431 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.410 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.303 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.456 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.391 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.348 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.322 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.268 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.235 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.336 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.269 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.234 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.191 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.234 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.264 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.157 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.202 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.045 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.111 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.048 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.048 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.096 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.133 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.174 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.051 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.051 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.049 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.190 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.286 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.286 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.300 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.303 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.371 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.400 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.455 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.439 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.312 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.375 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.458 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.356 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.372 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.171 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.239 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.391 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.339 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.330 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.149 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.172 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.157 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.151 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.104 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.192 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.320 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.262 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.290 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.211 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.140 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.323 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.267 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.279 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.266 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.192 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.320 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.262 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.290 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.211 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.248 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.309 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.281 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.379 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.306 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.220 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.255 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.302 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.278 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.262 total time=   0.2s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 50, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.5, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[502 316]\n",
      " [279 170]] \n",
      "\n",
      "Accuracy: 53.0 \n",
      "\n",
      "F1 Score: 36.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_glove_train, accuracy_xgb_glove_train, f1_xgb_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_glove_test, accuracy_xgb_glove_test, f1_xgb_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUCEQAQXGIl5"
   },
   "source": [
    "### GloVe + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "GLutlbgvG3f8",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:50:57.279236688Z",
     "start_time": "2023-05-07T22:50:49.111845269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.180 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.171 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.167 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.229 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.312 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.196 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.218 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.122 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.065 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.171 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.189 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.126 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.292 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.200 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.227 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.216 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.257 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.108 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.196 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.176 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.091 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.136 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.250 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.205 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.047 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.119 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.152 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.188 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.225 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.065 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.171 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.202 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.138 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.278 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.184 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.330 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.222 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.192 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.154 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.081 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.189 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.227 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.125 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.243 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.248 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.186 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.220 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.175 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.257 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.304 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.275 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.281 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.189 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.071 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.140 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.220 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.299 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.315 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.270 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.165 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.196 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.143 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.090 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.222 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.102 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.126 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.180 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.220 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.162 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.187 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.082 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.218 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.208 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.182 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.182 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.167 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.210 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.129 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.265 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.101 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.122 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.133 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.183 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.136 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.309 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.222 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.247 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.353 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.214 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.267 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.111 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.246 total time=   0.0s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 5, 'max_depth': None, 'bootstrap': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[702 116]\n",
      " [376  73]] \n",
      "\n",
      "Accuracy: 61.2 \n",
      "\n",
      "F1 Score: 22.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25], \n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_glove_train, accuracy_rf_glove_train, f1_rf_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_glove_test, accuracy_rf_glove_test, f1_rf_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vldrLVlwGIg9"
   },
   "source": [
    "### GloVe + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "MqqebdmmG3qI",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:57:25.205378234Z",
     "start_time": "2023-05-07T22:50:57.283308955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.228 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.231 total time=   0.1s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.305 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.375 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.292 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.074 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.072 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.074 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.026 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.053 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.026 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.026 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.288 total time=   0.2s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.366 total time=   0.3s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.428 total time=   0.3s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.431 total time=   0.3s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.300 total time=   0.3s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.268 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.341 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.343 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.420 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.318 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.354 total time=   0.1s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.353 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.353 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.441 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.380 total time=   0.1s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.275 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.400 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.322 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.321 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.243 total time=   3.7s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.368 total time=   3.1s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.411 total time=   9.9s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.472 total time=   6.1s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.373 total time=   3.5s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.345 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.394 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.309 total time=   0.1s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.326 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.377 total time=   0.1s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.456 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.412 total time=   0.1s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.312 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.410 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.322 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.380 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.349 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.288 total time= 1.3min\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.340 total time=  53.8s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.397 total time= 1.8min\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.468 total time=  51.2s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.358 total time= 1.0min\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.345 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.394 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.326 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.309 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.326 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.377 total time=   0.1s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.456 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.412 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.301 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.425 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.322 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.348 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.371 total time=   0.1s\n",
      "Best parameters: {'kernel': 'rbf', 'gamma': 'scale', 'C': 10} \n",
      "\n",
      "[LibSVM]...*.*\n",
      "optimization finished, #iter = 4304\n",
      "obj = -2401.212245, rho = -0.561638\n",
      "nSV = 918, nBSV = 121\n",
      "Total nSV = 918\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  6 360]] \n",
      "\n",
      "Accuracy: 99.4 \n",
      "\n",
      "F1 Score: 99.2 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[565 253]\n",
      " [303 146]] \n",
      "\n",
      "Accuracy: 56.1 \n",
      "\n",
      "F1 Score: 34.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_glove_train, accuracy_svc_glove_train, f1_svc_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_glove_test, accuracy_svc_glove_test, f1_svc_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8IPkDvHGIZw"
   },
   "source": [
    "### GloVe + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "7j_OebkkG32s",
    "ExecuteTime": {
     "end_time": "2023-05-07T22:57:32.874966613Z",
     "start_time": "2023-05-07T22:57:25.203046088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.46, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.46, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.46, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.46, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.46, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......C=0.14, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.14, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.14, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.14, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.14, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.21, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.21, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.21, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.21, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.21, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.6, penalty=l1, solver=saga;, score=0.086 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=0.6, penalty=l1, solver=saga;, score=0.172 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.6, penalty=l1, solver=saga;, score=0.111 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=0.6, penalty=l1, solver=saga;, score=0.157 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=0.6, penalty=l1, solver=saga;, score=0.047 total time=   0.3s\n",
      "[CV 1/5] END C=0.37, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.37, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.37, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.37, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.37, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.12, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.12, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.12, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=0.12, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.12, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.73, penalty=l1, solver=liblinear;, score=0.102 total time=   0.1s\n",
      "[CV 2/5] END C=0.73, penalty=l1, solver=liblinear;, score=0.165 total time=   0.0s\n",
      "[CV 3/5] END C=0.73, penalty=l1, solver=liblinear;, score=0.147 total time=   0.1s\n",
      "[CV 4/5] END C=0.73, penalty=l1, solver=liblinear;, score=0.194 total time=   0.1s\n",
      "[CV 5/5] END C=0.73, penalty=l1, solver=liblinear;, score=0.162 total time=   0.1s\n",
      "[CV 1/5] END C=0.26, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.26, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.26, penalty=l1, solver=liblinear;, score=0.027 total time=   0.0s\n",
      "[CV 4/5] END C=0.26, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.26, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.62, penalty=none, solver=newton-cg;, score=0.360 total time=   0.1s\n",
      "[CV 2/5] END C=0.62, penalty=none, solver=newton-cg;, score=0.369 total time=   0.1s\n",
      "[CV 3/5] END C=0.62, penalty=none, solver=newton-cg;, score=0.443 total time=   0.1s\n",
      "[CV 4/5] END C=0.62, penalty=none, solver=newton-cg;, score=0.478 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.62, penalty=none, solver=newton-cg;, score=0.408 total time=   0.1s\n",
      "[CV 1/5] END C=0.55, penalty=none, solver=newton-cg;, score=0.360 total time=   0.1s\n",
      "[CV 2/5] END C=0.55, penalty=none, solver=newton-cg;, score=0.369 total time=   0.1s\n",
      "[CV 3/5] END C=0.55, penalty=none, solver=newton-cg;, score=0.443 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.55, penalty=none, solver=newton-cg;, score=0.478 total time=   0.1s\n",
      "[CV 5/5] END C=0.55, penalty=none, solver=newton-cg;, score=0.408 total time=   0.1s\n",
      "[CV 1/5] END ......C=0.04, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.04, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.04, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.04, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.04, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.81, penalty=l2, solver=sag;, score=0.185 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.81, penalty=l2, solver=sag;, score=0.304 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.81, penalty=l2, solver=sag;, score=0.273 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.81, penalty=l2, solver=sag;, score=0.283 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.81, penalty=l2, solver=sag;, score=0.267 total time=   0.1s\n",
      "[CV 1/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.154 total time=   0.1s\n",
      "[CV 2/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.210 total time=   0.1s\n",
      "[CV 3/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.178 total time=   0.1s\n",
      "[CV 4/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.198 total time=   0.1s\n",
      "[CV 5/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.243 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.88, penalty=l2, solver=saga;, score=0.183 total time=   0.2s\n",
      "[CV 2/5] END ...C=0.88, penalty=l2, solver=saga;, score=0.316 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.88, penalty=l2, solver=saga;, score=0.268 total time=   0.2s\n",
      "[CV 4/5] END ...C=0.88, penalty=l2, solver=saga;, score=0.302 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.88, penalty=l2, solver=saga;, score=0.264 total time=   0.2s\n",
      "[CV 1/5] END C=0.34, penalty=none, solver=newton-cg;, score=0.360 total time=   0.1s\n",
      "[CV 2/5] END C=0.34, penalty=none, solver=newton-cg;, score=0.369 total time=   0.1s\n",
      "[CV 3/5] END C=0.34, penalty=none, solver=newton-cg;, score=0.443 total time=   0.1s\n",
      "[CV 4/5] END C=0.34, penalty=none, solver=newton-cg;, score=0.478 total time=   0.1s\n",
      "[CV 5/5] END C=0.34, penalty=none, solver=newton-cg;, score=0.408 total time=   0.1s\n",
      "[CV 1/5] END C=0.86, penalty=none, solver=newton-cg;, score=0.360 total time=   0.1s\n",
      "[CV 2/5] END C=0.86, penalty=none, solver=newton-cg;, score=0.369 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.86, penalty=none, solver=newton-cg;, score=0.443 total time=   0.1s\n",
      "[CV 4/5] END C=0.86, penalty=none, solver=newton-cg;, score=0.478 total time=   0.1s\n",
      "[CV 5/5] END C=0.86, penalty=none, solver=newton-cg;, score=0.408 total time=   0.1s\n",
      "[CV 1/5] END ......C=0.32, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.32, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.32, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.32, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.32, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.92, penalty=none, solver=sag;, score=0.324 total time=   0.2s\n",
      "[CV 2/5] END ..C=0.92, penalty=none, solver=sag;, score=0.329 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.92, penalty=none, solver=sag;, score=0.347 total time=   0.2s\n",
      "[CV 4/5] END ..C=0.92, penalty=none, solver=sag;, score=0.444 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.92, penalty=none, solver=sag;, score=0.352 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.93, penalty=l1, solver=saga;, score=0.136 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.93, penalty=l1, solver=saga;, score=0.243 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.93, penalty=l1, solver=saga;, score=0.214 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.93, penalty=l1, solver=saga;, score=0.212 total time=   0.3s\n",
      "[CV 5/5] END ...C=0.93, penalty=l1, solver=saga;, score=0.226 total time=   0.3s\n",
      "[CV 1/5] END ....C=0.28, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.28, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.28, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.28, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.28, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "Best parameters: {'solver': 'newton-cg', 'penalty': 'none', 'C': 0.62} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[547  87]\n",
      " [133 233]] \n",
      "\n",
      "Accuracy: 78.0 \n",
      "\n",
      "F1 Score: 67.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[529 289]\n",
      " [302 147]] \n",
      "\n",
      "Accuracy: 53.4 \n",
      "\n",
      "F1 Score: 33.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.11470756        nan 0.\n",
      " 0.15390445 0.00540541 0.41165239 0.41165239        nan 0.26229678\n",
      " 0.19651965 0.26663659 0.41165239 0.41165239        nan 0.35925122\n",
      " 0.20609175        nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_glove_train, accuracy_lr_glove_train, f1_lr_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_glove_test, accuracy_lr_glove_test, f1_lr_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GloVe + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:12<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[580  54]\n",
      " [ 24 342]] \n",
      "\n",
      "Accuracy: 92.2 \n",
      "\n",
      "F1 Score: 89.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[482 336]\n",
      " [266 183]] \n",
      "\n",
      "Accuracy: 52.5 \n",
      "\n",
      "F1 Score: 37.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_glove.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_glove.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_glove, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_glove_train, accuracy_nn_glove_train, f1_nn_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_glove_test, accuracy_nn_glove_test, f1_nn_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T22:57:44.925070324Z",
     "start_time": "2023-05-07T22:57:32.877004722Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:22:12.771807870Z",
     "start_time": "2023-05-07T23:22:10.906578192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.477 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.377 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.392 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.394 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.347 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.309 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.283 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.296 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.279 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.248 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.374 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.267 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.147 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.273 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.242 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.243 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.194 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.267 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.232 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.349 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.299 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.412 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.271 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.260 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.160 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.311 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.302 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.350 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.372 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.319 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.350 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.345 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.353 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.291 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.331 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.366 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.293 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.242 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.184 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.188 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.263 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.154 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.271 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.260 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.160 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.311 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.302 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.349 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.299 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.412 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.338 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.336 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.323 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.403 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.263 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.288 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.296 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.374 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.267 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.147 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.273 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.242 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.234 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.265 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.218 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.245 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.263 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.288 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.296 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.328 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.272 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.278 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.352 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.262 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.369 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.409 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.394 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.328 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.444 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.431 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.392 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.408 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.341 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.338 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.336 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.323 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.403 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.364 total time=   0.0s\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 2, 'metric': 'minkowski'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[515 303]\n",
      " [261 188]] \n",
      "\n",
      "Accuracy: 55.5 \n",
      "\n",
      "F1 Score: 40.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_w2v_train, accuracy_knn_w2v_train, f1_knn_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_w2v_test, accuracy_knn_w2v_test, f1_knn_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:23:39.053310202Z",
     "start_time": "2023-05-07T23:22:16.700305223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.342 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.196 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.274 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.326 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.304 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.263 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.194 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.194 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.289 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.455 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.183 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.328 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.380 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.394 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.406 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.343 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.362 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.397 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.235 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.165 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.252 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.222 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.180 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.286 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.176 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.243 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.294 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.303 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.386 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.234 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.293 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.319 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.383 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.468 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.200 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.317 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.380 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.368 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.427 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.403 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.405 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.356 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.252 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.368 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.309 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.406 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.315 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.341 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.429 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.331 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.356 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.420 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.419 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.265 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.208 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.224 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.242 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.359 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.270 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.283 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.397 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.379 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.472 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.383 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.276 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.278 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.389 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.324 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.321 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.423 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.299 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.321 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.392 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.411 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.295 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.269 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.368 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.417 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.300 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.272 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.144 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.247 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.291 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.314 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.443 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.336 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.429 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.486 total time=   0.8s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 7, 'learning_rate': 0.3, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[542 276]\n",
      " [278 171]] \n",
      "\n",
      "Accuracy: 56.3 \n",
      "\n",
      "F1 Score: 38.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_w2v_train, accuracy_xgb_w2v_train, f1_xgb_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_w2v_test, accuracy_xgb_w2v_test, f1_xgb_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:23:47.034019279Z",
     "start_time": "2023-05-07T23:23:39.056297844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.195 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.245 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.278 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.294 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.241 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.265 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.216 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.306 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.233 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.308 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.220 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.168 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.216 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.315 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.319 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.178 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.353 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.324 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.259 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.288 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.296 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.288 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.299 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.149 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.218 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.180 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.264 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.259 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.243 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.283 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.340 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.280 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.198 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.324 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.190 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.336 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.220 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.210 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.160 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.263 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.146 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.170 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.152 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.208 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.167 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.265 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.303 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.248 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.104 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.321 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.309 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.252 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.180 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.272 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.224 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.235 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.206 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.231 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.178 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.238 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.208 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.239 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.235 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.330 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.275 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.234 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.243 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.239 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.330 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.155 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.237 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.236 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.149 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.275 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.238 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.267 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.237 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.098 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.200 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.149 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.174 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.146 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.211 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.180 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.255 total time=   0.1s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 5, 'max_depth': 10, 'bootstrap': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  9 357]] \n",
      "\n",
      "Accuracy: 99.1 \n",
      "\n",
      "F1 Score: 98.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[697 121]\n",
      " [349 100]] \n",
      "\n",
      "Accuracy: 62.9 \n",
      "\n",
      "F1 Score: 29.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_w2v_train, accuracy_rf_w2v_train, f1_rf_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_w2v_test, accuracy_rf_w2v_test, f1_rf_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:25:09.019520768Z",
     "start_time": "2023-05-07T23:23:47.034251057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.168 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.229 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.349 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.226 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.051 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.025 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.165 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.122 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.140 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.027 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.025 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.099 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.125 total time=   0.1s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.198 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.051 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.101 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.074 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.409 total time=   0.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.395 total time=   0.1s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.375 total time=   0.1s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.472 total time=   0.1s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.371 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.336 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.286 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.302 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.434 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.342 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.382 total time=   0.1s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.338 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.286 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.400 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.351 total time=   0.1s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.444 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.417 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.331 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.417 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.438 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.468 total time=   0.9s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.372 total time=   0.7s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.364 total time=   0.5s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.408 total time=   0.7s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.419 total time=   0.9s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.358 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.303 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.415 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.356 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.385 total time=   0.1s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.290 total time=   0.1s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.406 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.351 total time=   0.1s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.468 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.309 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.342 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.406 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.436 total time=  18.2s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.351 total time=  13.8s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.353 total time=  13.9s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.403 total time=  15.7s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.408 total time=  10.8s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.358 total time=   0.1s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.303 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.415 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.356 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.385 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.290 total time=   0.1s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.406 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.351 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.441 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.306 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.429 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.481 total time=   0.1s\n",
      "Best parameters: {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 10} \n",
      "\n",
      "[LibSVM].*.*..*..*\n",
      "optimization finished, #iter = 5749\n",
      "obj = -12009.230044, rho = 1.037368\n",
      "nSV = 602, nBSV = 539\n",
      "Total nSV = 602\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[427 207]\n",
      " [240 126]] \n",
      "\n",
      "Accuracy: 55.3 \n",
      "\n",
      "F1 Score: 36.1 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[585 233]\n",
      " [283 166]] \n",
      "\n",
      "Accuracy: 59.3 \n",
      "\n",
      "F1 Score: 39.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_w2v_train, accuracy_svc_w2v_train, f1_svc_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_w2v_test, accuracy_svc_w2v_test, f1_svc_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:25:13.557391321Z",
     "start_time": "2023-05-07T23:25:09.022852048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.03, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.099 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.026 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.027 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.2, penalty=l2, solver=lbfgs;, score=0.052 total time=   0.0s\n",
      "[CV 1/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.43, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.453 total time=   0.0s\n",
      "[CV 2/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.430 total time=   0.0s\n",
      "[CV 3/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.364 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.435 total time=   0.1s\n",
      "[CV 5/5] END C=0.05, penalty=none, solver=newton-cg;, score=0.389 total time=   0.1s\n",
      "[CV 1/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.75, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.247 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.132 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.194 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.180 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.86, penalty=l2, solver=saga;, score=0.196 total time=   0.1s\n",
      "[CV 1/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.17, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.56, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.9400000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.453 total time=   0.0s\n",
      "[CV 2/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.430 total time=   0.0s\n",
      "[CV 3/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.364 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.435 total time=   0.1s\n",
      "[CV 5/5] END C=0.47000000000000003, penalty=none, solver=newton-cg;, score=0.389 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.232 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.096 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.162 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.170 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.67, penalty=l2, solver=saga;, score=0.157 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.205 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.026 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.094 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.099 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.120 total time=   0.0s\n",
      "[CV 1/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.453 total time=   0.0s\n",
      "[CV 2/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.420 total time=   0.0s\n",
      "[CV 3/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.364 total time=   0.0s\n",
      "[CV 4/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.435 total time=   0.0s\n",
      "[CV 5/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.389 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.18, penalty=none, solver=sag;, score=0.446 total time=   0.2s\n",
      "[CV 2/5] END ..C=0.18, penalty=none, solver=sag;, score=0.400 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.18, penalty=none, solver=sag;, score=0.386 total time=   0.2s\n",
      "[CV 4/5] END ..C=0.18, penalty=none, solver=sag;, score=0.435 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.18, penalty=none, solver=sag;, score=0.411 total time=   0.2s\n",
      "[CV 1/5] END ..C=0.29, penalty=none, solver=sag;, score=0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.29, penalty=none, solver=sag;, score=0.387 total time=   0.2s\n",
      "[CV 3/5] END ..C=0.29, penalty=none, solver=sag;, score=0.386 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.29, penalty=none, solver=sag;, score=0.432 total time=   0.2s\n",
      "[CV 5/5] END ..C=0.29, penalty=none, solver=sag;, score=0.411 total time=   0.2s\n",
      "[CV 1/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.196 total time=   0.0s\n",
      "[CV 2/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.051 total time=   0.0s\n",
      "[CV 3/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.112 total time=   0.0s\n",
      "[CV 4/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.4, penalty=l2, solver=newton-cg;, score=0.119 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.194 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.075 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.163 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.62, penalty=l2, solver=saga;, score=0.157 total time=   0.1s\n",
      "[CV 1/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.53, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.24, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "Best parameters: {'solver': 'sag', 'penalty': 'none', 'C': 0.18} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.04073919 0.         0.41439707        nan\n",
      " 0.18982355 0.                nan        nan 0.41439707 0.16341936\n",
      " 0.10884525 0.41239755 0.41559831 0.41230606 0.12390357 0.14859264\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[553  81]\n",
      " [133 233]] \n",
      "\n",
      "Accuracy: 78.6 \n",
      "\n",
      "F1 Score: 68.5 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[570 248]\n",
      " [271 178]] \n",
      "\n",
      "Accuracy: 59.0 \n",
      "\n",
      "F1 Score: 40.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_w2v_train, accuracy_lr_w2v_train, f1_lr_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_w2v_test, accuracy_lr_w2v_test, f1_lr_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[623  11]\n",
      " [ 33 333]] \n",
      "\n",
      "Accuracy: 95.6 \n",
      "\n",
      "F1 Score: 93.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[594 224]\n",
      " [281 168]] \n",
      "\n",
      "Accuracy: 60.1 \n",
      "\n",
      "F1 Score: 40.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_word2vec.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_word2vec.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_w2v_train, accuracy_nn_w2v_train, f1_nn_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_w2v_test, accuracy_nn_w2v_test, f1_nn_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:25:25.715074640Z",
     "start_time": "2023-05-07T23:25:13.565574017Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.455 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.449 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.495 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.395 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.490 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.214 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.338 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.214 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.330 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.236 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.298 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.360 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.254 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.381 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.346 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.366 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.281 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.306 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.352 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.402 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.442 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.442 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.365 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.472 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.355 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.407 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.284 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.381 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.403 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.268 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.309 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.274 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.239 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.372 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.352 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.449 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.390 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.345 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.471 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.336 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.324 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.212 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.310 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.283 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.383 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.413 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.376 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.382 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.397 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.419 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.373 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.328 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.395 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.320 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.321 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.276 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.248 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.291 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.293 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.228 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.385 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.326 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.214 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.338 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.214 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.330 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.236 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.355 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.407 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.284 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.381 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.403 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.405 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.319 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.319 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.392 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.352 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.449 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.390 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.345 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.471 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.398 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.442 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.439 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.322 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.449 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.455 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.449 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.495 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.395 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.490 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.293 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.430 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.228 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.385 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.326 total time=   0.1s\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 2, 'metric': 'minkowski'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[331 487]\n",
      " [165 284]] \n",
      "\n",
      "Accuracy: 48.5 \n",
      "\n",
      "F1 Score: 46.6 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_gpt2_train, accuracy_knn_gpt2_train, f1_knn_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_gpt2_test, accuracy_knn_gpt2_test, f1_knn_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:28:46.965188512Z",
     "start_time": "2023-05-07T23:28:43.983273446Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.047 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.169 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.052 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.027 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.096 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.395 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.288 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.436 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.490 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.400 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.395 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.338 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.388 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.384 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.369 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.237 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.288 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.214 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.222 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.243 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.374 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.344 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.331 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.403 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.433 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.374 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.352 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.392 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.424 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.370 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.067 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.156 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.233 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.140 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.133 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.304 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.322 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.330 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.353 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.300 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.365 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.340 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.405 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.392 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.310 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.453 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.440 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.378 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.430 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.346 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.259 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.268 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.341 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.239 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.319 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.269 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.368 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.305 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.356 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.269 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.252 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.361 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.348 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.265 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.281 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.157 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.239 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.291 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.240 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.216 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.090 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.234 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.195 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.026 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.156 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.277 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.317 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.377 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.395 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.302 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.341 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.368 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.370 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.288 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.390 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.070 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.176 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.101 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.074 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.174 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.026 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.100 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.027 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.000 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.098 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.025 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.101 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.053 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.000 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.050 total time=   0.4s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 50, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.5, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[498 320]\n",
      " [281 168]] \n",
      "\n",
      "Accuracy: 52.6 \n",
      "\n",
      "F1 Score: 35.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_gpt2_train, accuracy_xgb_gpt2_train, f1_xgb_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_gpt2_test, accuracy_xgb_gpt2_test, f1_xgb_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:30:44.593169713Z",
     "start_time": "2023-05-07T23:28:49.828915125Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.130 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.224 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.216 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.211 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.224 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.162 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.141 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.222 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.143 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.226 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.112 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.132 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.202 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.196 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.232 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.187 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.196 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.272 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.315 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.241 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.118 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.183 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.269 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.167 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.206 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.098 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.317 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.237 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.306 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.154 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.173 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.273 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.151 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.184 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.143 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.118 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.188 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.208 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.160 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.226 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.214 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.299 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.126 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.321 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.245 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.151 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.182 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.116 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.133 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.132 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.154 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.108 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.330 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.176 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.143 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.204 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.130 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.133 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.085 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.187 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.263 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.213 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.163 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.173 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.220 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.160 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.308 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.239 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.283 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.210 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.231 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.188 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.157 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.263 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.218 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.204 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.156 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.156 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.146 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.159 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.088 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.147 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.124 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.229 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.132 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.184 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.204 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.176 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.245 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.202 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.044 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.165 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.148 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.222 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.262 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.276 total time=   0.1s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 10, 'max_depth': None, 'bootstrap': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [ 24 342]] \n",
      "\n",
      "Accuracy: 97.6 \n",
      "\n",
      "F1 Score: 96.6 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[682 136]\n",
      " [394  55]] \n",
      "\n",
      "Accuracy: 58.2 \n",
      "\n",
      "F1 Score: 17.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_gpt2_train, accuracy_rf_gpt2_train, f1_rf_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_gpt2_test, accuracy_rf_gpt2_test, f1_rf_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:30:53.841555531Z",
     "start_time": "2023-05-07T23:30:44.596917843Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.071 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.027 total time=   0.2s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.103 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.053 total time=   0.2s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.053 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.333 total time=   0.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.413 total time=   0.1s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.446 total time=   0.1s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.372 total time=   0.2s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.385 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.326 total time=   0.2s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.366 total time=   0.2s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.446 total time=   0.2s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.430 total time=   0.2s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.365 total time=   0.2s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.290 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.365 total time=   0.2s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.336 total time=   0.2s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.342 total time=   0.2s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.146 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.168 total time=   0.2s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.227 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.152 total time=   0.2s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.196 total time=   0.2s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.369 total time=   0.2s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.420 total time=   0.2s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.432 total time=   0.2s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.392 total time=   0.2s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.378 total time=   0.2s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.400 total time=   0.2s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.411 total time=   0.2s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.443 total time=   0.2s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.414 total time=   0.2s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.388 total time=   0.2s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.412 total time=   0.2s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.405 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.447 total time=   0.2s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.400 total time=   0.2s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.373 total time=   0.2s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.397 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.353 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.355 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.350 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.381 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.369 total time=   0.2s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.395 total time=   0.2s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.434 total time=   0.2s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.417 total time=   0.2s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.389 total time=   0.2s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.400 total time=   0.2s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.411 total time=   0.2s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.443 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.414 total time=   0.2s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.388 total time=   0.2s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.412 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.405 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.447 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.400 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.373 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.395 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.382 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.369 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.359 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.416 total time=   0.2s\n",
      "Best parameters: {'kernel': 'poly', 'gamma': 'scale', 'C': 100} \n",
      "\n",
      "[LibSVM]....*..*\n",
      "optimization finished, #iter = 6284\n",
      "obj = -3589.504408, rho = -0.263840\n",
      "nSV = 824, nBSV = 0\n",
      "Total nSV = 824\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[549 269]\n",
      " [293 156]] \n",
      "\n",
      "Accuracy: 55.6 \n",
      "\n",
      "F1 Score: 35.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_gpt2_train, accuracy_svc_gpt2_train, f1_svc_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_gpt2_test, accuracy_svc_gpt2_test, f1_svc_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:31:08.338644523Z",
     "start_time": "2023-05-07T23:30:53.847702692Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8300000000000001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.027 total time=   0.1s\n",
      "[CV 3/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.027 total time=   0.1s\n",
      "[CV 5/5] END C=0.62, penalty=l2, solver=newton-cg;, score=0.026 total time=   0.1s\n",
      "[CV 1/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.22, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.81, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.48, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.024 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.052 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.052 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.92, penalty=l2, solver=sag;, score=0.051 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.97, penalty=l1, solver=saga;, score=0.000 total time=   0.8s\n",
      "[CV 1/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.09, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END C=0.41000000000000003, penalty=l2, solver=sag;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.372 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.405 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.417 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.398 total time=   0.2s\n",
      "[CV 5/5] END C=0.44, penalty=none, solver=newton-cg;, score=0.384 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.28, penalty=none, solver=saga;, score=0.343 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.28, penalty=none, solver=saga;, score=0.386 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.28, penalty=none, solver=saga;, score=0.421 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.28, penalty=none, solver=saga;, score=0.372 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.28, penalty=none, solver=saga;, score=0.331 total time=   0.5s\n",
      "[CV 1/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.392 total time=   0.0s\n",
      "[CV 2/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.431 total time=   0.1s\n",
      "[CV 3/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.428 total time=   0.1s\n",
      "[CV 4/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.416 total time=   0.2s\n",
      "[CV 5/5] END C=0.62, penalty=none, solver=lbfgs;, score=0.381 total time=   0.1s\n",
      "[CV 1/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.392 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.431 total time=   0.1s\n",
      "[CV 3/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.428 total time=   0.1s\n",
      "[CV 4/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.416 total time=   0.1s\n",
      "[CV 5/5] END C=0.64, penalty=none, solver=lbfgs;, score=0.381 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.027 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.027 total time=   0.2s\n",
      "[CV 5/5] END ....C=0.66, penalty=l2, solver=sag;, score=0.026 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.372 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.405 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.417 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.398 total time=   0.2s\n",
      "[CV 5/5] END C=0.39, penalty=none, solver=newton-cg;, score=0.384 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.2, penalty=l1, solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END C=0.4, penalty=l2, solver=liblinear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 2/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 3/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 4/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.3s\n",
      "[CV 5/5] END ...C=0.39, penalty=l2, solver=saga;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.88, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "Best parameters: {'solver': 'lbfgs', 'penalty': 'none', 'C': 0.62} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[528 290]\n",
      " [278 171]] \n",
      "\n",
      "Accuracy: 55.2 \n",
      "\n",
      "F1 Score: 37.6 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.0160019         nan        nan        nan 0.03585491\n",
      " 0.                nan 0.         0.39505574 0.37075679        nan\n",
      " 0.40943603 0.40943603 0.0160019  0.39505574 0.         0.\n",
      " 0.                nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_gpt2_train, accuracy_lr_gpt2_train, f1_lr_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_gpt2_test, accuracy_lr_gpt2_test, f1_lr_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:31:22.111973788Z",
     "start_time": "2023-05-07T23:31:08.306438107Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [02:03<00:00, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[595  39]\n",
      " [121 245]] \n",
      "\n",
      "Accuracy: 84.0 \n",
      "\n",
      "F1 Score: 75.4 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[602 216]\n",
      " [336 113]] \n",
      "\n",
      "Accuracy: 56.4 \n",
      "\n",
      "F1 Score: 29.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_gpt2.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_gpt2.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_gpt2_train, accuracy_nn_gpt2_train, f1_nn_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_gpt2_test, accuracy_nn_gpt2_test, f1_nn_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:33:25.485043955Z",
     "start_time": "2023-05-07T23:31:22.109432257Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.405 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.351 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.446 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.350 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.256 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.216 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.262 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.305 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.261 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.370 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.477 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.468 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.413 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.322 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.370 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.472 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.344 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.329 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.408 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.275 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.451 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.338 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.397 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.311 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.359 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.320 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.381 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.367 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.299 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.397 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.346 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.326 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.397 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.311 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.359 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.320 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.381 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.305 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.278 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.230 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.405 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.351 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.446 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.350 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.365 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.388 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.353 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.357 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.343 total time=   0.1s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.408 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.275 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.451 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.338 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.342 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.346 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.417 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.329 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.276 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.280 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.299 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.226 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.248 total time=   0.1s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.408 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.275 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.451 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.338 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.173 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.170 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.271 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.356 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.370 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.477 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.468 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.413 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.405 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.351 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.446 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.350 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.322 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.374 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.336 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.391 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.340 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.338 total time=   0.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.374 total time=   0.1s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.336 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.391 total time=   0.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.340 total time=   0.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.338 total time=   0.1s\n",
      "Best parameters: {'weights': 'distance', 'n_neighbors': 2, 'metric': 'euclidean'} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[484 334]\n",
      " [264 185]] \n",
      "\n",
      "Accuracy: 52.8 \n",
      "\n",
      "F1 Score: 38.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_roberta_train, accuracy_knn_roberta_train, f1_knn_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_roberta_test, accuracy_knn_roberta_test, f1_knn_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:33:28.558230256Z",
     "start_time": "2023-05-07T23:33:25.487213029Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.191 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.159 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.180 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.163 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.067 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.370 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.384 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.403 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.458 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.338 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.349 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.349 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.403 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.369 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.319 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.385 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.436 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.426 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.371 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.380 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.239 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.443 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.226 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.288 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.311 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.366 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.366 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.422 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.331 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.268 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.343 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.248 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.211 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.123 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.000 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.049 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.027 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.051 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.310 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.232 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.226 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.252 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.156 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.048 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.159 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.026 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.025 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.242 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.072 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.172 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.071 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.149 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.375 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.214 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.330 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.248 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.376 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.327 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.423 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.383 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.392 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.366 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.350 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.351 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.358 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.335 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.138 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.072 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.159 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.027 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.072 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.304 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.347 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.260 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.312 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.288 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.304 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.426 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.422 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.458 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.397 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.371 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.412 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.324 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.387 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.350 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.290 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.286 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.254 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.339 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.345 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.397 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.351 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.448 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.364 total time=   0.3s\n",
      "Best parameters: {'subsample': 0.5, 'objective': 'reg:squarederror', 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 9, 'learning_rate': 0.5, 'colsample_bytree': 0.7} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[517 301]\n",
      " [283 166]] \n",
      "\n",
      "Accuracy: 53.9 \n",
      "\n",
      "F1 Score: 36.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_roberta_train, accuracy_xgb_roberta_train, f1_xgb_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_roberta_test, accuracy_xgb_roberta_test, f1_xgb_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:35:19.810190187Z",
     "start_time": "2023-05-07T23:33:28.563846853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.236 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.137 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.218 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.176 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.246 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.144 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.241 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.194 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.210 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.247 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.143 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.163 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.147 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.184 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.117 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.264 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.263 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.194 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.238 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.152 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.194 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.275 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.263 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.226 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.180 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.175 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.211 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.171 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.173 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.204 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.176 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.194 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.165 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.327 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.228 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.125 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.204 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.176 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.206 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.160 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.163 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.312 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.198 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.202 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.257 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.215 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.233 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.229 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.239 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.188 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.202 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.213 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.216 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.111 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.157 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.140 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.072 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.126 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.245 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.242 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.137 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.198 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.102 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.124 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.143 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.283 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.170 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.132 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.138 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.182 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.263 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.243 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.110 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.250 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.180 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.116 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.238 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.135 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.135 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.214 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.212 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.235 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.119 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.182 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.180 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.168 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.178 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.120 total time=   0.1s\n",
      "Best parameters: {'n_estimators': 10, 'max_features': 5, 'max_depth': 10, 'bootstrap': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [ 12 354]] \n",
      "\n",
      "Accuracy: 98.8 \n",
      "\n",
      "F1 Score: 98.3 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[718 100]\n",
      " [389  60]] \n",
      "\n",
      "Accuracy: 61.4 \n",
      "\n",
      "F1 Score: 19.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_roberta_train, accuracy_rf_roberta_train, f1_rf_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_roberta_test, accuracy_rf_roberta_test, f1_rf_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:35:29.560046583Z",
     "start_time": "2023-05-07T23:35:19.814050068Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.292 total time=   0.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.258 total time=   0.1s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.310 total time=   0.1s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.397 total time=   0.1s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.151 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.338 total time=   0.3s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.362 total time=   0.3s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.400 total time=   0.3s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.406 total time=   0.3s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.297 total time=   0.2s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.130 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.119 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.132 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.052 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.069 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.051 total time=   0.1s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.053 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.053 total time=   0.2s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.027 total time=   0.2s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.168 total time=   0.1s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.278 total time=   0.1s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.173 total time=   0.1s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.330 total time=   0.1s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.152 total time=   0.1s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.369 total time=   0.6s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.342 total time=   0.6s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.346 total time=   0.6s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.406 total time=   0.8s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.314 total time=   0.6s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.318 total time=   0.2s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.273 total time=   0.1s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.387 total time=   0.2s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.344 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.195 total time=   0.2s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.308 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.264 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.333 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.381 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.113 total time=   0.2s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.301 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.331 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.347 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.443 total time=   0.1s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.409 total time=   0.1s\n",
      "Best parameters: {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 1000} \n",
      "\n",
      "[LibSVM]*\n",
      "optimization finished, #iter = 353\n",
      "obj = -2981181.146607, rho = 2639.916889\n",
      "nSV = 485, nBSV = 450\n",
      "Total nSV = 485\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[424 210]\n",
      " [217 149]] \n",
      "\n",
      "Accuracy: 57.3 \n",
      "\n",
      "F1 Score: 41.1 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[502 316]\n",
      " [281 168]] \n",
      "\n",
      "Accuracy: 52.9 \n",
      "\n",
      "F1 Score: 36.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_roberta_train, accuracy_svc_roberta_train, f1_svc_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_roberta_test, accuracy_svc_roberta_test, f1_svc_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:35:44.841565149Z",
     "start_time": "2023-05-07T23:35:29.563433268Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.3, penalty=l2, solver=lbfgs;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.76, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.276 total time=   0.1s\n",
      "[CV 2/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.307 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.359 total time=   0.1s\n",
      "[CV 4/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.400 total time=   0.1s\n",
      "[CV 5/5] END C=0.81, penalty=none, solver=lbfgs;, score=0.241 total time=   0.1s\n",
      "[CV 1/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.371 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.353 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.366 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.391 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.49, penalty=none, solver=newton-cg;, score=0.299 total time=   0.6s\n",
      "[CV 1/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5700000000000001, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.15, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.46, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.81, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.72, penalty=none, solver=sag;, score=0.246 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.72, penalty=none, solver=sag;, score=0.227 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.72, penalty=none, solver=sag;, score=0.232 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.72, penalty=none, solver=sag;, score=0.220 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.72, penalty=none, solver=sag;, score=0.154 total time=   0.4s\n",
      "[CV 1/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.9400000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.93, penalty=none, solver=sag;, score=0.246 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.93, penalty=none, solver=sag;, score=0.229 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.93, penalty=none, solver=sag;, score=0.234 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.93, penalty=none, solver=sag;, score=0.220 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.93, penalty=none, solver=sag;, score=0.154 total time=   0.5s\n",
      "[CV 1/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.98, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.61, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.33, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.41000000000000003, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n",
      "[CV 4/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.59, penalty=l1, solver=saga;, score=0.000 total time=   0.7s\n",
      "[CV 1/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.276 total time=   0.1s\n",
      "[CV 2/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.307 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "65 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.                nan 0.31640145        nan 0.35601159        nan\n",
      "        nan        nan        nan 0.21568143        nan 0.21657222\n",
      "        nan        nan        nan        nan 0.         0.31640145\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.359 total time=   0.1s\n",
      "[CV 4/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.400 total time=   0.1s\n",
      "[CV 5/5] END C=0.78, penalty=none, solver=lbfgs;, score=0.241 total time=   0.1s\n",
      "[CV 1/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.41000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.7000000000000001, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "Best parameters: {'solver': 'newton-cg', 'penalty': 'none', 'C': 0.49} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[634   0]\n",
      " [  0 366]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[470 348]\n",
      " [262 187]] \n",
      "\n",
      "Accuracy: 51.9 \n",
      "\n",
      "F1 Score: 38.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_roberta_train, accuracy_lr_roberta_train, f1_lr_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_roberta_test, accuracy_lr_roberta_test, f1_lr_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:36:00.139727255Z",
     "start_time": "2023-05-07T23:35:44.844837105Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [02:14<00:00, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[619  15]\n",
      " [314  52]] \n",
      "\n",
      "Accuracy: 67.1 \n",
      "\n",
      "F1 Score: 24.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[767  51]\n",
      " [424  25]] \n",
      "\n",
      "Accuracy: 62.5 \n",
      "\n",
      "F1 Score: 9.5 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_roberta.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_roberta.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_roberta, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_roberta_train, accuracy_nn_roberta_train, f1_nn_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_roberta_test, accuracy_nn_roberta_test, f1_nn_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:38:14.319036212Z",
     "start_time": "2023-05-07T23:36:00.138966910Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T23:48:58.760982365Z",
     "start_time": "2023-05-07T23:48:58.687210213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤════════════╤════════════╕\n",
      "│ Model                   │   Accuracy │   F1-Score │\n",
      "╞═════════════════════════╪════════════╪════════════╡\n",
      "│ LR+GloVe                │       53.4 │       33.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+GloVe               │       53.7 │       34.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+GloVe               │       56.1 │       34.4 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+GloVe      │       61.2 │       22.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+GloVe           │       53   │       36.4 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+GloVe     │       52.5 │       37.8 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+Word2Vec             │       59   │       40.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+Word2Vec            │       55.5 │       40   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+Word2Vec            │       59.3 │       39.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest + Word2Vec │       62.9 │       29.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+Word2Vec        │       56.3 │       38.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+Word2Vec  │       60.1 │       40   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+BERT                 │       52.8 │       34.6 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+BERT                │       53.1 │       35.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+BERT                │       50.4 │       33   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+BERT       │       57.9 │       22.4 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+BERT            │       52.3 │       34.8 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+BERT      │       59.6 │       17.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+RoBERTa              │       51.9 │       38   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+RoBERTa             │       52.8 │       38.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+RoBERTa             │       52.9 │       36   │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+RoBERTa    │       61.4 │       19.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+RoBERTa         │       53.9 │       36.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+RoBERTa   │       62.5 │        9.5 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ LR+GPT2                 │       55.2 │       37.6 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ KNN+GPT2                │       48.5 │       46.6 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ SVC+GPT2                │       55.6 │       35.7 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ RandomForest+GPT2       │       58.2 │       17.2 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ XGBoost+GPT2            │       52.6 │       35.9 │\n",
      "├─────────────────────────┼────────────┼────────────┤\n",
      "│ NeuralNetwork+GPT2      │       56.4 │       29   │\n",
      "╘═════════════════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "data = [[\"LR+GloVe\", accuracy_lr_glove_test, f1_lr_glove_test],\n",
    "        [\"KNN+GloVe\", accuracy_knn_glove_test, f1_knn_glove_test],\n",
    "        [\"SVC+GloVe\", accuracy_svc_glove_test, f1_svc_glove_test],\n",
    "        [\"RandomForest+GloVe\", accuracy_rf_glove_test, f1_rf_glove_test],\n",
    "        [\"XGBoost+GloVe\", accuracy_xgb_glove_test, f1_xgb_glove_test],\n",
    "        [\"NeuralNetwork+GloVe\", accuracy_nn_glove_test, f1_nn_glove_test],\n",
    "        [\"LR+Word2Vec\", accuracy_lr_w2v_test, f1_lr_w2v_test],\n",
    "        [\"KNN+Word2Vec\", accuracy_knn_w2v_test, f1_knn_w2v_test],\n",
    "        [\"SVC+Word2Vec\", accuracy_svc_w2v_test, f1_svc_w2v_test],\n",
    "        [\"RandomForest + Word2Vec\", accuracy_rf_w2v_test, f1_rf_w2v_test],\n",
    "        [\"XGBoost+Word2Vec\", accuracy_xgb_w2v_test, f1_xgb_w2v_test],\n",
    "        [\"NeuralNetwork+Word2Vec\", accuracy_nn_w2v_test, f1_nn_w2v_test],\n",
    "        [\"LR+BERT\", accuracy_lr_bert_test, f1_lr_bert_test],\n",
    "        [\"KNN+BERT\", accuracy_knn_bert_test, f1_knn_bert_test],\n",
    "        [\"SVC+BERT\", accuracy_svc_bert_test, f1_svc_bert_test],\n",
    "        [\"RandomForest+BERT\", accuracy_rf_bert_test, f1_rf_bert_test],\n",
    "        [\"XGBoost+BERT\", accuracy_xgb_bert_test, f1_xgb_bert_test],\n",
    "        [\"NeuralNetwork+BERT\", accuracy_nn_bert_test, f1_nn_bert_test],\n",
    "        [\"LR+RoBERTa\", accuracy_lr_roberta_test, f1_lr_roberta_test],\n",
    "        [\"KNN+RoBERTa\", accuracy_knn_roberta_test, f1_knn_roberta_test],\n",
    "        [\"SVC+RoBERTa\", accuracy_svc_roberta_test, f1_svc_roberta_test],\n",
    "        [\"RandomForest+RoBERTa\", accuracy_rf_roberta_test, f1_rf_roberta_test],\n",
    "        [\"XGBoost+RoBERTa\", accuracy_xgb_roberta_test, f1_xgb_roberta_test],\n",
    "        [\"NeuralNetwork+RoBERTa\", accuracy_nn_roberta_test, f1_nn_roberta_test],\n",
    "        [\"LR+GPT2\", accuracy_lr_gpt2_test, f1_lr_gpt2_test],\n",
    "        [\"KNN+GPT2\", accuracy_knn_gpt2_test, f1_knn_gpt2_test],\n",
    "        [\"SVC+GPT2\", accuracy_svc_gpt2_test, f1_svc_gpt2_test],\n",
    "        [\"RandomForest+GPT2\", accuracy_rf_gpt2_test, f1_rf_gpt2_test],\n",
    "        [\"XGBoost+GPT2\", accuracy_xgb_gpt2_test, f1_xgb_gpt2_test],\n",
    "        [\"NeuralNetwork+GPT2\", accuracy_nn_gpt2_test, f1_nn_gpt2_test]]\n",
    "  \n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#save results to csv\n",
    "if fast:\n",
    "    with open(\"results_fast_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(col_names)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "else:\n",
    "    with open(\"results_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(col_names)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "#display table\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      " Model                   &   Accuracy &   F1-Score \\\\\n",
      "\\hline\n",
      " LR+GloVe                &       53.4 &       33.2 \\\\\n",
      " KNN+GloVe               &       53.7 &       34.7 \\\\\n",
      " SVC+GloVe               &       56.1 &       34.4 \\\\\n",
      " RandomForest+GloVe      &       61.2 &       22.9 \\\\\n",
      " XGBoost+GloVe           &       53   &       36.4 \\\\\n",
      " NeuralNetwork+GloVe     &       52.5 &       37.8 \\\\\n",
      " LR+Word2Vec             &       59   &       40.7 \\\\\n",
      " KNN+Word2Vec            &       55.5 &       40   \\\\\n",
      " SVC+Word2Vec            &       59.3 &       39.2 \\\\\n",
      " RandomForest + Word2Vec &       62.9 &       29.9 \\\\\n",
      " XGBoost+Word2Vec        &       56.3 &       38.2 \\\\\n",
      " NeuralNetwork+Word2Vec  &       60.1 &       40   \\\\\n",
      " LR+BERT                 &       52.8 &       34.6 \\\\\n",
      " KNN+BERT                &       53.1 &       35.7 \\\\\n",
      " SVC+BERT                &       50.4 &       33   \\\\\n",
      " RandomForest+BERT       &       57.9 &       22.4 \\\\\n",
      " XGBoost+BERT            &       52.3 &       34.8 \\\\\n",
      " NeuralNetwork+BERT      &       59.6 &       17.9 \\\\\n",
      " LR+RoBERTa              &       51.9 &       38   \\\\\n",
      " KNN+RoBERTa             &       52.8 &       38.2 \\\\\n",
      " SVC+RoBERTa             &       52.9 &       36   \\\\\n",
      " RandomForest+RoBERTa    &       61.4 &       19.7 \\\\\n",
      " XGBoost+RoBERTa         &       53.9 &       36.2 \\\\\n",
      " NeuralNetwork+RoBERTa   &       62.5 &        9.5 \\\\\n",
      " LR+GPT2                 &       55.2 &       37.6 \\\\\n",
      " KNN+GPT2                &       48.5 &       46.6 \\\\\n",
      " SVC+GPT2                &       55.6 &       35.7 \\\\\n",
      " RandomForest+GPT2       &       58.2 &       17.2 \\\\\n",
      " XGBoost+GPT2            &       52.6 &       35.9 \\\\\n",
      " NeuralNetwork+GPT2      &       56.4 &       29   \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(data, headers=col_names, tablefmt=\"latex\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T23:49:00.904880155Z",
     "start_time": "2023-05-07T23:49:00.878387236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       53.4 │       33.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       59   │       40.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       52.8 │       34.6 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       51.9 │       38   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       55.2 │       37.6 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "lr_results = [\n",
    "    [\"GloVe\", accuracy_lr_glove_test, f1_lr_glove_test],\n",
    "    [\"Word2Vec\", accuracy_lr_w2v_test, f1_lr_w2v_test],\n",
    "    [\"BERT\", accuracy_lr_bert_test, f1_lr_bert_test],\n",
    "    [\"RoBERTa\", accuracy_lr_roberta_test, f1_lr_roberta_test],\n",
    "    [\"GPT2\", accuracy_lr_gpt2_test, f1_lr_gpt2_test]\n",
    "]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"Logistic Regression\")\n",
    "print(tabulate(lr_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:44.648347738Z",
     "start_time": "2023-05-08T00:11:44.628206561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       53.7 │       34.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       55.5 │       40   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       53.1 │       35.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       52.8 │       38.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       48.5 │       46.6 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "knn_results = [\n",
    "    [\"GloVe\", accuracy_knn_glove_test, f1_knn_glove_test],\n",
    "    [\"Word2Vec\", accuracy_knn_w2v_test, f1_knn_w2v_test],\n",
    "    [\"BERT\", accuracy_knn_bert_test, f1_knn_bert_test],\n",
    "    [\"RoBERTa\", accuracy_knn_roberta_test, f1_knn_roberta_test],\n",
    "    [\"GPT2\", accuracy_knn_gpt2_test, f1_knn_gpt2_test]\n",
    "]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"KNN\")\n",
    "print(tabulate(knn_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:45.623006697Z",
     "start_time": "2023-05-08T00:11:45.607642365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       56.1 │       34.4 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       59.3 │       39.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       50.4 │       33   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       52.9 │       36   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       55.6 │       35.7 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "svc_results = [\n",
    "    [\"GloVe\", accuracy_svc_glove_test, f1_svc_glove_test],\n",
    "    [\"Word2Vec\", accuracy_svc_w2v_test, f1_svc_w2v_test],\n",
    "    [\"BERT\", accuracy_svc_bert_test, f1_svc_bert_test],\n",
    "    [\"RoBERTa\", accuracy_svc_roberta_test, f1_svc_roberta_test],\n",
    "    [\"GPT2\", accuracy_svc_gpt2_test, f1_svc_gpt2_test]\n",
    "]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"SVM Classifier\")\n",
    "print(tabulate(svc_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:46.045799687Z",
     "start_time": "2023-05-08T00:11:46.031440509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       61.2 │       22.9 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       62.9 │       29.9 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       57.9 │       22.4 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       61.4 │       19.7 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       58.2 │       17.2 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "rf_results = [\n",
    "    [\"GloVe\", accuracy_rf_glove_test, f1_rf_glove_test],\n",
    "    [\"Word2Vec\", accuracy_rf_w2v_test, f1_rf_w2v_test],\n",
    "    [\"BERT\", accuracy_rf_bert_test, f1_rf_bert_test],\n",
    "    [\"RoBERTa\", accuracy_rf_roberta_test, f1_rf_roberta_test],\n",
    "    [\"GPT2\", accuracy_rf_gpt2_test, f1_rf_gpt2_test]\n",
    "]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"Random Forest\")\n",
    "print(tabulate(rf_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:46.310402046Z",
     "start_time": "2023-05-08T00:11:46.299016397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       53   │       36.4 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       56.3 │       38.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       52.3 │       34.8 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       53.9 │       36.2 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       52.6 │       35.9 │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "xgb_results = [\n",
    "    [\"GloVe\", accuracy_xgb_glove_test, f1_xgb_glove_test],\n",
    "    [\"Word2Vec\", accuracy_xgb_w2v_test, f1_xgb_w2v_test],\n",
    "    [\"BERT\", accuracy_xgb_bert_test, f1_xgb_bert_test],\n",
    "    [\"RoBERTa\", accuracy_xgb_roberta_test, f1_xgb_roberta_test],\n",
    "    [\"GPT2\", accuracy_xgb_gpt2_test, f1_xgb_gpt2_test]\n",
    "]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"XGBoost\")\n",
    "print(tabulate(xgb_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:46.663167632Z",
     "start_time": "2023-05-08T00:11:46.636014024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork\n",
      "╒══════════╤════════════╤════════════╕\n",
      "│ Model    │   Accuracy │   F1-Score │\n",
      "╞══════════╪════════════╪════════════╡\n",
      "│ GloVe    │       52.5 │       37.8 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ Word2Vec │       60.1 │       40   │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ BERT     │       59.6 │       17.9 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ RoBERTa  │       62.5 │        9.5 │\n",
      "├──────────┼────────────┼────────────┤\n",
      "│ GPT2     │       56.4 │       29   │\n",
      "╘══════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "nn_results = [\n",
    "    [\"GloVe\", accuracy_nn_glove_test, f1_nn_glove_test],\n",
    "    [\"Word2Vec\", accuracy_nn_w2v_test, f1_nn_w2v_test],\n",
    "    [\"BERT\", accuracy_nn_bert_test, f1_nn_bert_test],\n",
    "    [\"RoBERTa\", accuracy_nn_roberta_test, f1_nn_roberta_test],\n",
    "    [\"GPT2\", accuracy_nn_gpt2_test, f1_nn_gpt2_test]\n",
    "]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"NeuralNetwork\")\n",
    "print(tabulate(nn_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T00:11:47.147217610Z",
     "start_time": "2023-05-08T00:11:47.088596164Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24t1eSrlFLK6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
