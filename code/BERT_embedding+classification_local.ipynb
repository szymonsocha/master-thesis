{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpFId1mjCySe"
   },
   "source": [
    "# Word Embeddings + various classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TCU7NPLUuQrU",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:44.081529591Z",
     "start_time": "2023-05-01T18:38:44.033730861Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gensim\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaFYAFhluSCU",
    "outputId": "cf3c01ae-ba06-4501-d53b-8926d079f411",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:45.932931859Z",
     "start_time": "2023-05-01T18:38:44.864175508Z"
    }
   },
   "outputs": [],
   "source": [
    "fake = pd.read_csv('../../data/Fake.csv')\n",
    "true = pd.read_csv('../../data/True.csv')\n",
    "\n",
    "fake[\"label\"] = 0\n",
    "true[\"label\"] = 1\n",
    "\n",
    "df = pd.concat([fake, true], ignore_index = True)\n",
    "\n",
    "df['text'] = df['title'] + \" \" + df['text']\n",
    "df.drop(columns=['title', 'date', 'subject'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieOrxB_AuTwA",
    "outputId": "f5f4e1d6-b001-4dab-b81f-7b08125dcdfc",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:53.681970372Z",
     "start_time": "2023-05-01T18:38:45.930152428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/szymon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.64 s, sys: 83.9 ms, total: 7.73 s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "    \n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "df['text']=df['text'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQMXCPQ97YRZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIG7v_fk7jbE"
   },
   "source": [
    "Reduce dataset for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3OAKnGLyuVS0",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:53.682653437Z",
     "start_time": "2023-05-01T18:38:53.680022776Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_original = df.copy()\n",
    "# df = df.sample(frac=1).reset_index(drop=True)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA_tL8Sg7VWO"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-lrFVWwGiwt"
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:53.695299836Z",
     "start_time": "2023-05-01T18:38:53.683592170Z"
    }
   },
   "outputs": [],
   "source": [
    "redo_embedding = False # recalculate embeddings\n",
    "fast = True # True if use reduced dataset (1000 obs) vs. False if full dataset (40000 obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:53.757766822Z",
     "start_time": "2023-05-01T18:38:53.693518939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 ms, sys: 13 Âµs, total: 20.3 ms\n",
      "Wall time: 19.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load data\n",
    "\n",
    "if fast:\n",
    "    df_original = df.copy()\n",
    "    df = df.sample(frac=1).reset_index(drop=True)[:1000]\n",
    "\n",
    "if redo_embedding:\n",
    "    X = df['text'].tolist()\n",
    "    y = df['label'].tolist()\n",
    "\n",
    "    with open(\"X\", \"wb\") as fp:\n",
    "      pickle.dump(X, fp)\n",
    "    with open(\"y\", \"wb\") as fp:\n",
    "      pickle.dump(y, fp)\n",
    "elif fast:\n",
    "    with open(\"../../data/small/X\", \"rb\") as fp:\n",
    "      X = pickle.load(fp)\n",
    "    with open(\"../../data/small/y\", \"rb\") as fp:\n",
    "      y = pickle.load(fp)\n",
    "else:\n",
    "    with open(\"../../data/X\", \"rb\") as fp:\n",
    "      X = pickle.load(fp)\n",
    "    with open(\"../../data/y\", \"rb\") as fp:\n",
    "      y = pickle.load(fp)\n",
    "    \n",
    "if redo_embedding:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    with open(\"X_train\", \"wb\") as fp:\n",
    "      pickle.dump(X_train, fp)\n",
    "    with open(\"X_test\", \"wb\") as fp:\n",
    "      pickle.dump(X_test, fp)\n",
    "    with open(\"y_train\", \"wb\") as fp:\n",
    "      pickle.dump(y_train, fp)\n",
    "    with open(\"y_test\", \"wb\") as fp:\n",
    "      pickle.dump(y_test, fp)\n",
    "elif fast:\n",
    "    with open(\"../../data/small/X_train\", \"rb\") as fp:\n",
    "      X_train = pickle.load(fp)\n",
    "    with open(\"../../data/small/X_test\", \"rb\") as fp:\n",
    "      X_test = pickle.load(fp)   \n",
    "    with open(\"../../data/small/y_train\", \"rb\") as fp:\n",
    "      y_train = pickle.load(fp)\n",
    "    with open(\"../../data/small/y_test\", \"rb\") as fp:\n",
    "      y_test = pickle.load(fp)\n",
    "else:\n",
    "    with open(\"../../data/X_train\", \"rb\") as fp:\n",
    "      X_train = pickle.load(fp)\n",
    "    with open(\"../../data/X_test\", \"rb\") as fp:\n",
    "      X_test = pickle.load(fp)   \n",
    "    with open(\"../../data/y_train\", \"rb\") as fp:\n",
    "      y_train = pickle.load(fp)\n",
    "    with open(\"../../data/y_test\", \"rb\") as fp:\n",
    "      y_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqQEmeGREcUg"
   },
   "source": [
    "## BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbSRaebguY2a",
    "outputId": "a3fc1906-e2a4-4a92-8d1c-a656f2fdd828",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:53.854627032Z",
     "start_time": "2023-05-01T18:38:53.720595346Z"
    }
   },
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert = AutoModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bert.to(device)\n",
    "\n",
    "    def _get_bert_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512)\n",
    "        input_ids = np.array(input_ids)\n",
    "        input_ids = np.expand_dims(input_ids, axis=0)\n",
    "        input_ids = torch.tensor(input_ids).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert(input_ids)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        return last_hidden_state\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_bert_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_bert = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_bert_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_bert = np.squeeze(X_test_embeddings, axis=1)\n",
    "    \n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_bert).to_csv(\"../../data/small/embeddings/X_train_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_bert).to_csv(\"../../data/small/embeddings/X_test_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_bert).to_csv(\"../../data/embeddings/X_train_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_bert).to_csv(\"../../data/embeddings/X_test_embeddings_bert_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    \n",
    "elif fast:\n",
    "    X_train_embeddings_bert = pd.read_csv('../../data/small/embeddings/X_train_embeddings_bert.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_bert = pd.read_csv('../../data/small/embeddings/X_test_embeddings_bert.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_bert = pd.read_csv('../../data/embeddings/X_train_embeddings_bert.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_bert = pd.read_csv('../../data/embeddings/X_test_embeddings_bert.csv', sep=',', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhGA1YV7GaKD"
   },
   "source": [
    "## GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:53.920143445Z",
     "start_time": "2023-05-01T18:38:53.831907194Z"
    }
   },
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "\n",
    "    def load_glove_embeddings(filename):\n",
    "        embeddings_index = {}\n",
    "        with open(filename) as f:\n",
    "            for line in tqdm(f):\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                if len(values[1:]) == 300:\n",
    "                    coefs = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings_index[word] = coefs\n",
    "        return embeddings_index\n",
    "\n",
    "    glove_embeddings = load_glove_embeddings('../../glove/glove.840B.300d.txt')\n",
    "\n",
    "    def text_to_glove_embeddings(text, embeddings_index, embedding_dim):\n",
    "        embeddings = []\n",
    "        for sentence in text:\n",
    "            sentence_embeddings = []\n",
    "            for word in sentence.split():\n",
    "                if word in embeddings_index:\n",
    "                    sentence_embeddings.append(embeddings_index[word])\n",
    "            if len(sentence_embeddings) > 0:\n",
    "                embeddings.append(np.mean(sentence_embeddings, axis=0))\n",
    "            else:\n",
    "                embeddings.append(np.zeros(embedding_dim))\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    X_train_embeddings_glove = text_to_glove_embeddings(X_train, glove_embeddings, embedding_dim=300)\n",
    "    X_test_embeddings_glove = text_to_glove_embeddings(X_test, glove_embeddings, embedding_dim=300)\n",
    "    \n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_glove).to_csv(\"../../data/small/embeddings/X_train_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_glove).to_csv(\"../../data/small/embeddings/X_test_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_glove).to_csv(\"../../data/embeddings/X_train_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_glove).to_csv(\"../../data/embeddings/X_test_embeddings_glove_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_glove = pd.read_csv('../../data/small/embeddings/X_train_embeddings_glove.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_glove = pd.read_csv('../../data/small/embeddings/X_test_embeddings_glove.csv', sep=',', header=None).values\n",
    "\n",
    "else:\n",
    "    X_train_embeddings_glove = pd.read_csv('../../data/embeddings/X_train_embeddings_glove.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_glove = pd.read_csv('../../data/embeddings/X_test_embeddings_glove.csv', sep=',', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('../../word2vec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "def get_word2vec_embeddings(text):\n",
    "    embeddings = []\n",
    "    for sentence in tqdm(text):\n",
    "        tokens = sentence.split()\n",
    "        doc_vecs = [model[token] for token in tokens if token in model.key_to_index]\n",
    "        if len(doc_vecs) > 0:\n",
    "            doc_vec = np.mean(doc_vecs, axis=0)\n",
    "            embeddings.append(doc_vec)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "if redo_embedding:\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    X_train_embeddings_word2vec = get_word2vec_embeddings(X_train)\n",
    "    X_test_embeddings_word2vec = get_word2vec_embeddings(X_test)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_word2vec).to_csv(\"../../data/small/embeddings/X_train_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_word2vec).to_csv(\"../../data/small/embeddings/X_test_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_word2vec).to_csv(\"../../data/embeddings/X_train_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_word2vec).to_csv(\"../../data/embeddings/X_test_embeddings_word2vec_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_word2vec = pd.read_csv('../../data/small/embeddings/X_train_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_word2vec = pd.read_csv('../../data/small/embeddings/X_test_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "\n",
    "else:\n",
    "    X_train_embeddings_word2vec = pd.read_csv('../../data/embeddings/X_train_embeddings_word2vec.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_word2vec = pd.read_csv('../../data/embeddings/X_test_embeddings_word2vec.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.010658851Z",
     "start_time": "2023-05-01T18:38:53.920369514Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gpt2.to(device)\n",
    "\n",
    "    def _get_gpt2_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=1024)\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = gpt2.transformer.wte(input_ids)\n",
    "            mean_embedding = embeddings.mean(dim=1)\n",
    "        #     outputs = bert(input_ids)\n",
    "        #     last_hidden_state = outputs.last_hidden_state\n",
    "        #     last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "            #vector = gpt2.transformer.wte.weight[input_ids,:]\n",
    "        mean_embedding = mean_embedding.cpu().numpy()\n",
    "        return mean_embedding\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_gpt2_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_gpt2 = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_gpt2_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_gpt2 = np.squeeze(X_test_embeddings, axis=1)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_gpt2).to_csv(\"../../data/small/embeddings/X_train_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_gpt2).to_csv(\"../../data/small/embeddings/X_test_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_gpt2).to_csv(\"../../data/embeddings/X_train_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_gpt2).to_csv(\"../../data/embeddings/X_test_embeddings_gpt2_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_gpt2 = pd.read_csv('../../data/small/embeddings/X_train_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_gpt2 = pd.read_csv('../../data/small/embeddings/X_test_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_gpt2 = pd.read_csv('../../data/embeddings/X_train_embeddings_gpt2.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_gpt2 = pd.read_csv('../../data/embeddings/X_test_embeddings_gpt2.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.064237400Z",
     "start_time": "2023-05-01T18:38:53.988014692Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "if redo_embedding:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    roberta = AutoModel.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    roberta.to(device)\n",
    "\n",
    "    def _get_roberta_embedding(text):\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512)\n",
    "        input_ids = np.array(input_ids)\n",
    "        input_ids = np.expand_dims(input_ids, axis=0)\n",
    "        input_ids = torch.tensor(input_ids).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = roberta(input_ids)\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "            last_hidden_state = last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        return last_hidden_state\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    X_train_embeddings = []\n",
    "    for text in tqdm(X_train):\n",
    "        embedding = _get_roberta_embedding(text)\n",
    "        X_train_embeddings.append(embedding)\n",
    "    X_train_embeddings = np.array(X_train_embeddings)\n",
    "    X_train_embeddings_roberta = np.squeeze(X_train_embeddings, axis=1)\n",
    "\n",
    "    print(\"TEST\")\n",
    "    X_test_embeddings = []\n",
    "    for text in tqdm(X_test):\n",
    "        embedding = _get_roberta_embedding(text)\n",
    "        X_test_embeddings.append(embedding)\n",
    "    X_test_embeddings = np.array(X_test_embeddings)\n",
    "    X_test_embeddings_roberta = np.squeeze(X_test_embeddings, axis=1)\n",
    "\n",
    "    if fast:\n",
    "        pd.DataFrame(X_train_embeddings_roberta).to_csv(\"../../data/small/embeddings/X_train_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_roberta).to_csv(\"../../data/small/embeddings/X_test_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "    else:\n",
    "        pd.DataFrame(X_train_embeddings_roberta).to_csv(\"../../data/embeddings/X_train_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "        pd.DataFrame(X_test_embeddings_roberta).to_csv(\"../../data/embeddings/X_test_embeddings_roberta_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", index=False, header=False)\n",
    "\n",
    "elif fast:\n",
    "    X_train_embeddings_roberta = pd.read_csv('../../data/small/embeddings/X_train_embeddings_roberta.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_roberta = pd.read_csv('../../data/small/embeddings/X_test_embeddings_roberta.csv', sep=',', header=None).values\n",
    "else:\n",
    "    X_train_embeddings_roberta = pd.read_csv('../../data/embeddings/X_train_embeddings_roberta.csv', sep=',', header=None).values\n",
    "    X_test_embeddings_roberta = pd.read_csv('../../data/embeddings/X_test_embeddings_roberta.csv', sep=',', header=None).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.200108372Z",
     "start_time": "2023-05-01T18:38:54.072348162Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMvpJtV-EiIo"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.200425740Z",
     "start_time": "2023-05-01T18:38:54.194144624Z"
    }
   },
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, n_neighbors=2, weights='uniform', metric='minkowski'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = KNeighborsClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        self.n_neighbors = random_search.best_params_['n_neighbors']\n",
    "        self.weights = random_search.best_params_['weights']\n",
    "        self.metric = random_search.best_params_['metric']\n",
    "\n",
    "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.258938733Z",
     "start_time": "2023-05-01T18:38:54.204982077Z"
    }
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier:\n",
    "    def __init__(self, learning_rate=0.1, max_depth=5, min_child_weight=1, subsample=0.5, colsample_bytree=0.5, n_estimators=100, objective='req:squarederror'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.n_estimators = n_estimators\n",
    "        self.objective = objective\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = xgb.XGBClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        self.learning_rate = random_search.best_params_['learning_rate']\n",
    "        self.max_depth = random_search.best_params_['max_depth']\n",
    "        self.min_child_weight = random_search.best_params_['min_child_weight']\n",
    "        self.subsample = random_search.best_params_['subsample']\n",
    "        self.colsample_bytree = random_search.best_params_['colsample_bytree']\n",
    "        self.n_estimators = random_search.best_params_['n_estimators']\n",
    "        self.objective = random_search.best_params_['objective']\n",
    "\n",
    "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.259206051Z",
     "start_time": "2023-05-01T18:38:54.252295520Z"
    }
   },
   "outputs": [],
   "source": [
    "class RFClassifier:\n",
    "    def __init__(self, n_estimators=100, max_features='sqrt', max_depth='none', bootstrap=True):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.bootstrap = bootstrap\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap, verbose=True)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = RandomForestClassifier()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        self.n_estimators = random_search.best_params_['n_estimators']\n",
    "        self.max_features = random_search.best_params_['max_features']\n",
    "        self.max_depth = random_search.best_params_['max_depth']\n",
    "        self.bootstrap = random_search.best_params_['bootstrap']\n",
    "\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.259312960Z",
     "start_time": "2023-05-01T18:38:54.252765317Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVClassifier:\n",
    "    def __init__(self, C = 1, kernel='linear', gamma = 0.2):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma, verbose=True)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = svm.SVC()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        self.C = random_search.best_params_['C']\n",
    "        self.kernel = random_search.best_params_['kernel']\n",
    "        self.gamma = random_search.best_params_['gamma']\n",
    "\n",
    "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.259402149Z",
     "start_time": "2023-05-01T18:38:54.252937856Z"
    }
   },
   "outputs": [],
   "source": [
    "class LRClassifier:\n",
    "    def __init__(self, penalty = 'l2', solver = 'libinear', C = 0.5):\n",
    "        self.penalty = penalty\n",
    "        self.solver = solver\n",
    "        self.C = C\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
    "        self.model = LogisticRegression()\n",
    "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        self.penalty = random_search.best_params_['penalty']\n",
    "        self.solver = random_search.best_params_['solver']\n",
    "        self.C = random_search.best_params_['C']\n",
    "\n",
    "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100,1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100,1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class FakeNewsClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
    "        super(FakeNewsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "class NeuralNetworkClassifier:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=2):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X_train, y_train, num_epochs=10, lr=0.001):\n",
    "        self.model = FakeNewsClassifier(self.input_dim, self.hidden_dim, self.output_dim)\n",
    "        self.model = self.model.double()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        for _ in tqdm(range(num_epochs), desc=\"Epoch\"):\n",
    "            for embedding, label in zip(X_train, y_train):\n",
    "                embedding_tensor = torch.from_numpy(embedding).double().unsqueeze(0)\n",
    "                label_tensor = torch.tensor([label])\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(embedding_tensor)\n",
    "                loss = criterion(outputs, label_tensor)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        test_inputs = torch.from_numpy(X_test).double()\n",
    "        predictions = self.model(test_inputs)\n",
    "        predicted_classes = torch.argmax(predictions, dim=1)\n",
    "        predicted_classes = predicted_classes.numpy()\n",
    "        return predicted_classes\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100, 1)\n",
    "        f1 = round(f1_score(y_test, y_pred)*100, 1)\n",
    "\n",
    "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
    "        print('Accuracy:', accuracy, '\\n')\n",
    "        print('F1 Score:', f1, '\\n')\n",
    "\n",
    "        return cm, accuracy, f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:54.259486899Z",
     "start_time": "2023-05-01T18:38:54.253205924Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlaJrgisGNfg"
   },
   "source": [
    "## BERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMOZaIWp0_oy"
   },
   "source": [
    "### BERT + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "7HzI3FV7zy6t",
    "outputId": "8ca1830c-a309-4f27-f6dd-cee648ee0978",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:38:57.392159322Z",
     "start_time": "2023-05-01T18:38:54.253398982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.950 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[417   9]\n",
      " [  8 366]] \n",
      "\n",
      "Accuracy: 97.9 \n",
      "\n",
      "F1 Score: 97.7 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[102   5]\n",
      " [  4  89]] \n",
      "\n",
      "Accuracy: 95.5 \n",
      "\n",
      "F1 Score: 95.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_bert_train, accuracy_knn_bert_train, f1_knn_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_bert_test, accuracy_knn_bert_test, f1_knn_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg4FzG2htmwr"
   },
   "source": [
    "### BERT + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psJLbuc_win3",
    "outputId": "554936c2-e2c5-4b6f-df80-f9e4054f0dbe",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:41:00.934485731Z",
     "start_time": "2023-05-01T18:38:57.370412956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.988 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   4.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.894 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.887 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   4.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.856 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.875 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.1s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  1 373]] \n",
      "\n",
      "Accuracy: 99.9 \n",
      "\n",
      "F1 Score: 99.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[99  8]\n",
      " [ 1 92]] \n",
      "\n",
      "Accuracy: 95.5 \n",
      "\n",
      "F1 Score: 95.3 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_bert_train, accuracy_xgb_bert_train, f1_xgb_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_bert_test, accuracy_xgb_bert_test, f1_xgb_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekftGhJPFFFX"
   },
   "source": [
    "### BERT + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ks6w5IOrJYG",
    "outputId": "0341c3cf-975e-4e0c-8a26-01064b132ae1",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:41:07.659941503Z",
     "start_time": "2023-05-01T18:41:00.938908640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.956 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.912 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.963 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.900 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[97 10]\n",
      " [ 2 91]] \n",
      "\n",
      "Accuracy: 94.0 \n",
      "\n",
      "F1 Score: 93.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25], \n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_bert_train, accuracy_rf_bert_train, f1_rf_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_bert_test, accuracy_rf_bert_test, f1_rf_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbX9j48J1a9j"
   },
   "source": [
    "### BERT + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSTFuYyH63Mk",
    "outputId": "6ba15a33-8e98-4a4e-9113-8c771dc0dede",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:41:10.725493121Z",
     "start_time": "2023-05-01T18:41:07.664378101Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.950 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.956 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.969 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
      "[LibSVM]*\n",
      "optimization finished, #iter = 767\n",
      "obj = -222.085582, rho = 0.513498\n",
      "nSV = 179, nBSV = 0\n",
      "Total nSV = 179\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[103   4]\n",
      " [  1  92]] \n",
      "\n",
      "Accuracy: 97.5 \n",
      "\n",
      "F1 Score: 97.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_bert_train, accuracy_svc_bert_train, f1_svc_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_bert_test, accuracy_svc_bert_test, f1_svc_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYoz0OB11ayT"
   },
   "source": [
    "### BERT + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YijN0v7JCFbG",
    "outputId": "4bf95058-f264-43c2-e84d-1572b4814428",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:41:30.083968529Z",
     "start_time": "2023-05-01T18:41:10.727992303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.42, penalty=none, solver=saga;, score=0.963 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.42, penalty=none, solver=saga;, score=0.963 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.42, penalty=none, solver=saga;, score=0.963 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.42, penalty=none, solver=saga;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.42, penalty=none, solver=saga;, score=0.963 total time=   0.4s\n",
      "[CV 1/5] END C=0.62, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.62, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.62, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.62, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.62, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.68, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.68, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.68, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.68, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.68, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.32, penalty=l2, solver=saga;, score=0.950 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.32, penalty=l2, solver=saga;, score=0.975 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.32, penalty=l2, solver=saga;, score=0.963 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.32, penalty=l2, solver=saga;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.32, penalty=l2, solver=saga;, score=0.950 total time=   0.4s\n",
      "[CV 1/5] END C=0.53, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.53, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.53, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.53, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.53, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5700000000000001, penalty=none, solver=sag;, score=0.969 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5700000000000001, penalty=none, solver=sag;, score=0.969 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5700000000000001, penalty=none, solver=sag;, score=0.963 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5700000000000001, penalty=none, solver=sag;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5700000000000001, penalty=none, solver=sag;, score=0.956 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.27, penalty=none, solver=saga;, score=0.969 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.27, penalty=none, solver=saga;, score=0.963 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.27, penalty=none, solver=saga;, score=0.963 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.27, penalty=none, solver=saga;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.27, penalty=none, solver=saga;, score=0.956 total time=   0.4s\n",
      "[CV 1/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.944 total time=   0.1s\n",
      "[CV 2/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.975 total time=   0.1s\n",
      "[CV 3/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END C=0.88, penalty=l1, solver=liblinear;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END C=0.36, penalty=none, solver=lbfgs;, score=0.950 total time=   0.0s\n",
      "[CV 2/5] END C=0.36, penalty=none, solver=lbfgs;, score=0.963 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.36, penalty=none, solver=lbfgs;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END C=0.36, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=0.36, penalty=none, solver=lbfgs;, score=0.963 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.91, penalty=l1, solver=saga;, score=0.950 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.91, penalty=l1, solver=saga;, score=0.969 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.91, penalty=l1, solver=saga;, score=0.956 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.91, penalty=l1, solver=saga;, score=0.994 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.91, penalty=l1, solver=saga;, score=0.956 total time=   1.0s\n",
      "[CV 1/5] END C=0.6900000000000001, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6900000000000001, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6900000000000001, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6900000000000001, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6900000000000001, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.89, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.89, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.89, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.89, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.89, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.84, penalty=l2, solver=saga;, score=0.969 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.84, penalty=l2, solver=saga;, score=0.963 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.84, penalty=l2, solver=saga;, score=0.963 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.84, penalty=l2, solver=saga;, score=0.994 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.84, penalty=l2, solver=saga;, score=0.950 total time=   0.7s\n",
      "[CV 1/5] END C=0.5700000000000001, penalty=l1, solver=liblinear;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END C=0.5700000000000001, penalty=l1, solver=liblinear;, score=0.975 total time=   0.1s\n",
      "[CV 3/5] END C=0.5700000000000001, penalty=l1, solver=liblinear;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END C=0.5700000000000001, penalty=l1, solver=liblinear;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END C=0.5700000000000001, penalty=l1, solver=liblinear;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END C=0.8200000000000001, penalty=none, solver=newton-cg;, score=0.975 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.8200000000000001, penalty=none, solver=newton-cg;, score=0.969 total time=   0.1s\n",
      "[CV 3/5] END C=0.8200000000000001, penalty=none, solver=newton-cg;, score=0.963 total time=   0.1s\n",
      "[CV 4/5] END C=0.8200000000000001, penalty=none, solver=newton-cg;, score=0.994 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.8200000000000001, penalty=none, solver=newton-cg;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.950 total time=   0.1s\n",
      "[CV 2/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.994 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.32, penalty=l2, solver=lbfgs;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END C=0.36, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.36, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.36, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.36, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.36, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.39, penalty=none, solver=sag;, score=0.969 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.39, penalty=none, solver=sag;, score=0.969 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.39, penalty=none, solver=sag;, score=0.969 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.39, penalty=none, solver=sag;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96875     nan     nan 0.96625     nan 0.97    0.96875 0.9575  0.965\n",
      " 0.965       nan     nan 0.9675  0.95625 0.97125 0.96625     nan 0.97125\n",
      "     nan     nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.39, penalty=none, solver=sag;, score=0.956 total time=   0.4s\n",
      "[CV 1/5] END C=0.18, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.18, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.18, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.18, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.18, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.87, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.87, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.87, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.87, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.87, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[104   3]\n",
      " [  4  89]] \n",
      "\n",
      "Accuracy: 96.5 \n",
      "\n",
      "F1 Score: 96.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_bert, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_bert, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_bert_train, accuracy_lr_bert_train, f1_lr_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_bert_test, accuracy_lr_bert_test, f1_lr_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BERT + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|ââââââââââ| 10/10 [01:48<00:00, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[419   7]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 99.1 \n",
      "\n",
      "F1 Score: 99.1 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[99  8]\n",
      " [ 1 92]] \n",
      "\n",
      "Accuracy: 95.5 \n",
      "\n",
      "F1 Score: 95.3 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_bert.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_bert.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_bert, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_bert_train, accuracy_nn_bert_train, f1_nn_bert_train = classifier.evaluate(X_train_embeddings_bert, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_bert_test, accuracy_nn_bert_test, f1_nn_bert_test = classifier.evaluate(X_test_embeddings_bert, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:43:18.407278409Z",
     "start_time": "2023-05-01T18:41:30.090331924Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uSk7WKhGB1v"
   },
   "source": [
    "## GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1D_jiR2GI7H"
   },
   "source": [
    "### GloVe + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "LA5swddzG28v",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:43:19.563612750Z",
     "start_time": "2023-05-01T18:43:18.409442794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.825 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.856 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.831 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.856 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.856 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.856 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.781 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.825 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.844 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.819 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.894 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.856 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.831 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=distance;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.856 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.925 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[380  46]\n",
      " [ 18 356]] \n",
      "\n",
      "Accuracy: 92.0 \n",
      "\n",
      "F1 Score: 91.8 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[99  8]\n",
      " [ 7 86]] \n",
      "\n",
      "Accuracy: 92.5 \n",
      "\n",
      "F1 Score: 92.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_glove_train, accuracy_knn_glove_train, f1_knn_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_glove_test, accuracy_knn_glove_test, f1_knn_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Lfsat69GIoJ"
   },
   "source": [
    "### GloVe + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "rt7c3MSPG3PP",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:43:57.734746800Z",
     "start_time": "2023-05-01T18:43:19.568155788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.875 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.863 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.875 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.781 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.856 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.850 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.831 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.819 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.800 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.844 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.869 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.825 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.850 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.875 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.863 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.831 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.838 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.844 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.819 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.856 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.844 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.894 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.838 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.894 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.863 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.831 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.838 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.844 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.838 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.863 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.825 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.819 total time=   0.4s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[425   1]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 99.9 \n",
      "\n",
      "F1 Score: 99.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[103   4]\n",
      " [  4  89]] \n",
      "\n",
      "Accuracy: 96.0 \n",
      "\n",
      "F1 Score: 95.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_glove_train, accuracy_xgb_glove_train, f1_xgb_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_glove_test, accuracy_xgb_glove_test, f1_xgb_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUCEQAQXGIl5"
   },
   "source": [
    "### GloVe + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "GLutlbgvG3f8",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:44:04.326162191Z",
     "start_time": "2023-05-01T18:43:57.736853437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.875 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.887 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.875 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.831 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.856 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.856 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.856 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.875 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.875 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.881 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.894 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.894 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.856 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.894 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.825 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.825 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.869 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.869 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.863 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.875 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.887 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.887 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.881 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[98  9]\n",
      " [ 4 89]] \n",
      "\n",
      "Accuracy: 93.5 \n",
      "\n",
      "F1 Score: 93.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25], \n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_glove_train, accuracy_rf_glove_train, f1_rf_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_glove_test, accuracy_rf_glove_test, f1_rf_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vldrLVlwGIg9"
   },
   "source": [
    "### GloVe + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "MqqebdmmG3qI",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:44:06.154049414Z",
     "start_time": "2023-05-01T18:44:04.332341744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.894 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.900 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.900 total time=   0.0s\n",
      "[LibSVM].*.*\n",
      "optimization finished, #iter = 2158\n",
      "obj = -272.916122, rho = -6.511241\n",
      "nSV = 133, nBSV = 7\n",
      "Total nSV = 133\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[424   2]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 99.8 \n",
      "\n",
      "F1 Score: 99.7 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[106   1]\n",
      " [  2  91]] \n",
      "\n",
      "Accuracy: 98.5 \n",
      "\n",
      "F1 Score: 98.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_glove_train, accuracy_svc_glove_train, f1_svc_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_glove_test, accuracy_svc_glove_test, f1_svc_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8IPkDvHGIZw"
   },
   "source": [
    "### GloVe + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "7j_OebkkG32s",
    "ExecuteTime": {
     "end_time": "2023-05-01T18:44:11.259106648Z",
     "start_time": "2023-05-01T18:44:06.152081476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.32, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END C=0.32, penalty=l2, solver=newton-cg;, score=0.938 total time=   0.0s\n",
      "[CV 3/5] END C=0.32, penalty=l2, solver=newton-cg;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END C=0.32, penalty=l2, solver=newton-cg;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END C=0.32, penalty=l2, solver=newton-cg;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.21, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.21, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.21, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.21, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.21, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.51, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.51, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.51, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.51, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.51, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.5, penalty=l1, solver=saga;, score=0.875 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=0.5, penalty=l1, solver=saga;, score=0.875 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.5, penalty=l1, solver=saga;, score=0.931 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=0.5, penalty=l1, solver=saga;, score=0.944 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=0.5, penalty=l1, solver=saga;, score=0.919 total time=   0.2s\n",
      "[CV 1/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.4, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.38, penalty=l1, solver=liblinear;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END C=0.38, penalty=l1, solver=liblinear;, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END C=0.38, penalty=l1, solver=liblinear;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END C=0.38, penalty=l1, solver=liblinear;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END C=0.38, penalty=l1, solver=liblinear;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.12, penalty=l2, solver=saga;, score=0.869 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.12, penalty=l2, solver=saga;, score=0.912 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.12, penalty=l2, solver=saga;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.12, penalty=l2, solver=saga;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.12, penalty=l2, solver=saga;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.51, penalty=none, solver=sag;, score=0.938 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.51, penalty=none, solver=sag;, score=0.963 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.51, penalty=none, solver=sag;, score=0.950 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.51, penalty=none, solver=sag;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END ..C=0.51, penalty=none, solver=sag;, score=0.963 total time=   0.1s\n",
      "[CV 1/5] END ....C=0.89, penalty=l2, solver=sag;, score=0.906 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.89, penalty=l2, solver=sag;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.89, penalty=l2, solver=sag;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.89, penalty=l2, solver=sag;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.89, penalty=l2, solver=sag;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END C=0.56, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.56, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.56, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.56, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.56, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6, penalty=l1, solver=liblinear;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END C=0.6, penalty=l1, solver=liblinear;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END C=0.6, penalty=l1, solver=liblinear;, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END C=0.6, penalty=l1, solver=liblinear;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END C=0.6, penalty=l1, solver=liblinear;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.63, penalty=l1, solver=liblinear;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END C=0.63, penalty=l1, solver=liblinear;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END C=0.63, penalty=l1, solver=liblinear;, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END C=0.63, penalty=l1, solver=liblinear;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END C=0.63, penalty=l1, solver=liblinear;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.51, penalty=l2, solver=lbfgs;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.51, penalty=l2, solver=lbfgs;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.51, penalty=l2, solver=lbfgs;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.51, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.51, penalty=l2, solver=lbfgs;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END C=0.65, penalty=l2, solver=newton-cg;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END C=0.65, penalty=l2, solver=newton-cg;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END C=0.65, penalty=l2, solver=newton-cg;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END C=0.65, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END C=0.65, penalty=l2, solver=newton-cg;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END C=0.87, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.87, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.87, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.87, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.87, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.5, penalty=none, solver=sag;, score=0.944 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.5, penalty=none, solver=sag;, score=0.963 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.5, penalty=none, solver=sag;, score=0.950 total time=   0.2s\n",
      "[CV 4/5] END ...C=0.5, penalty=none, solver=sag;, score=0.994 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.5, penalty=none, solver=sag;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.85, penalty=l2, solver=lbfgs;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.85, penalty=l2, solver=lbfgs;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.85, penalty=l2, solver=lbfgs;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.85, penalty=l2, solver=lbfgs;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.85, penalty=l2, solver=lbfgs;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.59, penalty=l2, solver=lbfgs;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.59, penalty=l2, solver=lbfgs;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.59, penalty=l2, solver=lbfgs;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.59, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.59, penalty=l2, solver=lbfgs;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.86, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.86, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.86, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.86, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.86, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.93625     nan     nan 0.90875     nan 0.89125 0.91875 0.96125 0.94875\n",
      "     nan 0.90625     nan 0.90625 0.9425  0.94375     nan 0.96125 0.94875\n",
      " 0.9425      nan]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[424   2]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 99.8 \n",
      "\n",
      "F1 Score: 99.7 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[105   2]\n",
      " [  1  92]] \n",
      "\n",
      "Accuracy: 98.5 \n",
      "\n",
      "F1 Score: 98.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_glove, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_glove, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_glove_train, accuracy_lr_glove_train, f1_lr_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_glove_test, accuracy_lr_glove_test, f1_lr_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GloVe + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|ââââââââââ| 10/10 [00:14<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [ 35 339]] \n",
      "\n",
      "Accuracy: 95.6 \n",
      "\n",
      "F1 Score: 95.1 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[105   2]\n",
      " [ 13  80]] \n",
      "\n",
      "Accuracy: 92.5 \n",
      "\n",
      "F1 Score: 91.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_glove.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_glove.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_glove, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_glove_train, accuracy_nn_glove_train, f1_nn_glove_train = classifier.evaluate(X_train_embeddings_glove, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_glove_test, accuracy_nn_glove_test, f1_nn_glove_test = classifier.evaluate(X_test_embeddings_glove, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:44:25.577892294Z",
     "start_time": "2023-05-01T18:44:11.262287680Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:44:26.600247062Z",
     "start_time": "2023-05-01T18:44:25.581602852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.831 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.825 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.825 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.844 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.856 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.769 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.831 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.912 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[99  8]\n",
      " [14 79]] \n",
      "\n",
      "Accuracy: 89.0 \n",
      "\n",
      "F1 Score: 87.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_w2v_train, accuracy_knn_w2v_train, f1_knn_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_w2v_test, accuracy_knn_w2v_test, f1_knn_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:45:06.871915812Z",
     "start_time": "2023-05-01T18:44:26.605009893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.844 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.875 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.825 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.887 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.869 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.863 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.831 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.869 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.887 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.875 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.887 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.894 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.875 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.850 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.894 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.887 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.844 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.875 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.863 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.887 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.1s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[105   2]\n",
      " [  6  87]] \n",
      "\n",
      "Accuracy: 96.0 \n",
      "\n",
      "F1 Score: 95.6 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_w2v_train, accuracy_xgb_w2v_train, f1_xgb_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_w2v_test, accuracy_xgb_w2v_test, f1_xgb_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:45:12.836933606Z",
     "start_time": "2023-05-01T18:45:06.868046165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.850 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.887 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.894 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.887 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.894 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.875 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[101   6]\n",
      " [  5  88]] \n",
      "\n",
      "Accuracy: 94.5 \n",
      "\n",
      "F1 Score: 94.1 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_w2v_train, accuracy_rf_w2v_train, f1_rf_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_w2v_test, accuracy_rf_w2v_test, f1_rf_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:45:14.371562935Z",
     "start_time": "2023-05-01T18:45:12.836342229Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.950 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.919 total time=   0.0s\n",
      "[LibSVM]*\n",
      "optimization finished, #iter = 766\n",
      "obj = -641.469836, rho = -0.887162\n",
      "nSV = 154, nBSV = 56\n",
      "Total nSV = 154\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[423   3]\n",
      " [  1 373]] \n",
      "\n",
      "Accuracy: 99.5 \n",
      "\n",
      "F1 Score: 99.5 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[105   2]\n",
      " [  1  92]] \n",
      "\n",
      "Accuracy: 98.5 \n",
      "\n",
      "F1 Score: 98.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_w2v_train, accuracy_svc_w2v_train, f1_svc_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_w2v_test, accuracy_svc_w2v_test, f1_svc_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T18:45:17.410876549Z",
     "start_time": "2023-05-01T18:45:14.377529708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ....C=0.29, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.29, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.29, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.29, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.29, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.26, penalty=none, solver=lbfgs;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END C=0.26, penalty=none, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END C=0.26, penalty=none, solver=lbfgs;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END C=0.26, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=0.26, penalty=none, solver=lbfgs;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END C=0.08, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.08, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.08, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.08, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.08, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.7000000000000001, penalty=l2, solver=liblinear;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END C=0.7000000000000001, penalty=l2, solver=liblinear;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END C=0.7000000000000001, penalty=l2, solver=liblinear;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END C=0.7000000000000001, penalty=l2, solver=liblinear;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END C=0.7000000000000001, penalty=l2, solver=liblinear;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.47000000000000003, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.76, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.76, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.76, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.76, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.76, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.41000000000000003, penalty=l2, solver=newton-cg;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END C=0.41000000000000003, penalty=l2, solver=newton-cg;, score=0.938 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.41000000000000003, penalty=l2, solver=newton-cg;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END C=0.41000000000000003, penalty=l2, solver=newton-cg;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END C=0.41000000000000003, penalty=l2, solver=newton-cg;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END C=0.6900000000000001, penalty=l2, solver=liblinear;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END C=0.6900000000000001, penalty=l2, solver=liblinear;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END C=0.6900000000000001, penalty=l2, solver=liblinear;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END C=0.6900000000000001, penalty=l2, solver=liblinear;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END C=0.6900000000000001, penalty=l2, solver=liblinear;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END C=0.59, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.59, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.59, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.59, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.59, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.74, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.74, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.74, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.74, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.74, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0, penalty=none, solver=newton-cg;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END C=0.0, penalty=none, solver=newton-cg;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END C=0.0, penalty=none, solver=newton-cg;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END C=0.0, penalty=none, solver=newton-cg;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.0, penalty=none, solver=newton-cg;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END C=0.24, penalty=l2, solver=newton-cg;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END C=0.24, penalty=l2, solver=newton-cg;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END C=0.24, penalty=l2, solver=newton-cg;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END C=0.24, penalty=l2, solver=newton-cg;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END C=0.24, penalty=l2, solver=newton-cg;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END C=0.89, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.89, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.89, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.89, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.89, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.97, penalty=none, solver=sag;, score=0.963 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.97, penalty=none, solver=sag;, score=0.969 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.97, penalty=none, solver=sag;, score=0.963 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.97, penalty=none, solver=sag;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END ..C=0.97, penalty=none, solver=sag;, score=0.963 total time=   0.1s\n",
      "[CV 1/5] END C=0.9500000000000001, penalty=l2, solver=sag;, score=0.912 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.9500000000000001, penalty=l2, solver=sag;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END C=0.9500000000000001, penalty=l2, solver=sag;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END C=0.9500000000000001, penalty=l2, solver=sag;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END C=0.9500000000000001, penalty=l2, solver=sag;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END C=0.8300000000000001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.8300000000000001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.8300000000000001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.8300000000000001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.8300000000000001, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.48, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.48, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.48, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.48, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.48, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.2, penalty=l1, solver=saga;, score=0.825 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=0.2, penalty=l1, solver=saga;, score=0.881 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.2, penalty=l1, solver=saga;, score=0.838 total time=   0.2s\n",
      "[CV 4/5] END ....C=0.2, penalty=l1, solver=saga;, score=0.887 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [    nan 0.9675      nan 0.935       nan     nan 0.9325  0.935       nan\n",
      "     nan 0.9675  0.925       nan 0.97125 0.93875     nan     nan 0.8575\n",
      "     nan 0.9675 ]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=0.2, penalty=l1, solver=saga;, score=0.856 total time=   0.2s\n",
      "[CV 1/5] END ......C=0.34, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.34, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.34, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.34, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.34, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.81, penalty=none, solver=newton-cg;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END C=0.81, penalty=none, solver=newton-cg;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END C=0.81, penalty=none, solver=newton-cg;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END C=0.81, penalty=none, solver=newton-cg;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.81, penalty=none, solver=newton-cg;, score=0.969 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[425   1]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 99.9 \n",
      "\n",
      "F1 Score: 99.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[104   3]\n",
      " [  1  92]] \n",
      "\n",
      "Accuracy: 98.0 \n",
      "\n",
      "F1 Score: 97.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_word2vec, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_w2v_train, accuracy_lr_w2v_train, f1_lr_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_w2v_test, accuracy_lr_w2v_test, f1_lr_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|ââââââââââ| 10/10 [00:15<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  2 372]] \n",
      "\n",
      "Accuracy: 99.8 \n",
      "\n",
      "F1 Score: 99.7 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[106   1]\n",
      " [  4  89]] \n",
      "\n",
      "Accuracy: 97.5 \n",
      "\n",
      "F1 Score: 97.3 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_word2vec.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_word2vec.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_word2vec, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_w2v_train, accuracy_nn_w2v_train, f1_nn_w2v_train = classifier.evaluate(X_train_embeddings_word2vec, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_w2v_test, accuracy_nn_w2v_test, f1_nn_w2v_test = classifier.evaluate(X_test_embeddings_word2vec, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:45:33.325821631Z",
     "start_time": "2023-05-01T18:45:17.413613083Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=4, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.919 total time=   0.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.938 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=2, weights=uniform;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.944 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[410  16]\n",
      " [ 25 349]] \n",
      "\n",
      "Accuracy: 94.9 \n",
      "\n",
      "F1 Score: 94.5 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[104   3]\n",
      " [  4  89]] \n",
      "\n",
      "Accuracy: 96.5 \n",
      "\n",
      "F1 Score: 96.2 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_gpt2_train, accuracy_knn_gpt2_train, f1_knn_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_gpt2_test, accuracy_knn_gpt2_test, f1_knn_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:45:35.521460885Z",
     "start_time": "2023-05-01T18:45:33.331694156Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.863 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.887 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.869 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.863 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.856 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.988 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   4.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.844 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.875 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   4.1s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.869 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.894 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.894 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=9, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   5.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.988 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   0.4s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[105   2]\n",
      " [  2  91]] \n",
      "\n",
      "Accuracy: 98.0 \n",
      "\n",
      "F1 Score: 97.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_gpt2_train, accuracy_xgb_gpt2_train, f1_xgb_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_gpt2_test, accuracy_xgb_gpt2_test, f1_xgb_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:47:57.653957599Z",
     "start_time": "2023-05-01T18:45:35.525978198Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.912 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.912 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.887 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.906 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.956 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.887 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.887 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.900 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.931 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.919 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[104   3]\n",
      " [  5  88]] \n",
      "\n",
      "Accuracy: 96.0 \n",
      "\n",
      "F1 Score: 95.7 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_gpt2_train, accuracy_rf_gpt2_train, f1_rf_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_gpt2_test, accuracy_rf_gpt2_test, f1_rf_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:48:04.495807948Z",
     "start_time": "2023-05-01T18:47:57.615998968Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.944 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.944 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.981 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.931 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.981 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.912 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.931 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.963 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.950 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.981 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.988 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.988 total time=   0.0s\n",
      "[LibSVM]*.*\n",
      "optimization finished, #iter = 903\n",
      "obj = -4309.902660, rho = 2.393279\n",
      "nSV = 149, nBSV = 30\n",
      "Total nSV = 149\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[424   2]\n",
      " [  2 372]] \n",
      "\n",
      "Accuracy: 99.5 \n",
      "\n",
      "F1 Score: 99.5 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[106   1]\n",
      " [  0  93]] \n",
      "\n",
      "Accuracy: 99.5 \n",
      "\n",
      "F1 Score: 99.5 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_gpt2_train, accuracy_svc_gpt2_train, f1_svc_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_gpt2_test, accuracy_svc_gpt2_test, f1_svc_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:48:08.281495813Z",
     "start_time": "2023-05-01T18:48:04.502143267Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.75, penalty=none, solver=newton-cg;, score=0.969 total time=   0.1s\n",
      "[CV 2/5] END C=0.75, penalty=none, solver=newton-cg;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END C=0.75, penalty=none, solver=newton-cg;, score=0.975 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.75, penalty=none, solver=newton-cg;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END C=0.75, penalty=none, solver=newton-cg;, score=0.981 total time=   0.1s\n",
      "[CV 1/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.869 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.881 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.881 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.08, penalty=l2, solver=sag;, score=0.875 total time=   0.1s\n",
      "[CV 1/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.35000000000000003, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.531 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.531 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.537 total time=   0.0s\n",
      "[CV 1/5] END C=0.74, penalty=l1, solver=liblinear;, score=0.856 total time=   0.1s\n",
      "[CV 2/5] END C=0.74, penalty=l1, solver=liblinear;, score=0.806 total time=   0.1s\n",
      "[CV 3/5] END C=0.74, penalty=l1, solver=liblinear;, score=0.919 total time=   0.1s\n",
      "[CV 4/5] END C=0.74, penalty=l1, solver=liblinear;, score=0.925 total time=   0.1s\n",
      "[CV 5/5] END C=0.74, penalty=l1, solver=liblinear;, score=0.925 total time=   0.1s\n",
      "[CV 1/5] END C=0.31, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.31, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.31, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.31, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.31, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.53, penalty=none, solver=sag;, score=0.969 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.53, penalty=none, solver=sag;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.53, penalty=none, solver=sag;, score=0.975 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.53, penalty=none, solver=sag;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.53, penalty=none, solver=sag;, score=0.975 total time=   0.4s\n",
      "[CV 1/5] END C=0.09, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.09, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.09, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.09, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.09, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.52, penalty=none, solver=saga;, score=0.975 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.52, penalty=none, solver=saga;, score=1.000 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.52, penalty=none, solver=saga;, score=0.981 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.52, penalty=none, solver=saga;, score=0.994 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.52, penalty=none, solver=saga;, score=0.975 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.71, penalty=none, solver=saga;, score=0.975 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.71, penalty=none, solver=saga;, score=1.000 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.71, penalty=none, solver=saga;, score=0.981 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.71, penalty=none, solver=saga;, score=0.994 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.71, penalty=none, solver=saga;, score=0.975 total time=   0.5s\n",
      "[CV 1/5] END C=0.61, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.61, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.61, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.61, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.61, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.14, penalty=l1, solver=saga;, score=0.575 total time=   0.4s\n",
      "[CV 2/5] END ...C=0.14, penalty=l1, solver=saga;, score=0.656 total time=   0.3s\n",
      "[CV 3/5] END ...C=0.14, penalty=l1, solver=saga;, score=0.537 total time=   0.4s\n",
      "[CV 4/5] END ...C=0.14, penalty=l1, solver=saga;, score=0.550 total time=   0.4s\n",
      "[CV 5/5] END ...C=0.14, penalty=l1, solver=saga;, score=0.594 total time=   0.4s\n",
      "[CV 1/5] END C=0.46, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.46, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.46, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.46, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.46, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.33, penalty=l1, solver=saga;, score=0.756 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.33, penalty=l1, solver=saga;, score=0.731 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.33, penalty=l1, solver=saga;, score=0.844 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.33, penalty=l1, solver=saga;, score=0.787 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.33, penalty=l1, solver=saga;, score=0.744 total time=   0.7s\n",
      "[CV 1/5] END C=0.16, penalty=none, solver=newton-cg;, score=0.969 total time=   0.1s\n",
      "[CV 2/5] END C=0.16, penalty=none, solver=newton-cg;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END C=0.16, penalty=none, solver=newton-cg;, score=0.975 total time=   0.1s\n",
      "[CV 4/5] END C=0.16, penalty=none, solver=newton-cg;, score=0.988 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.16, penalty=none, solver=newton-cg;, score=0.981 total time=   0.1s\n",
      "[CV 1/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END C=0.73, penalty=none, solver=lbfgs;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END C=0.73, penalty=none, solver=lbfgs;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.71, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.71, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.71, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.71, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.71, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.856 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.812 total time=   0.1s\n",
      "[CV 3/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.919 total time=   0.1s\n",
      "[CV 4/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.919 total time=   0.0s\n",
      "[CV 5/5] END C=0.66, penalty=l1, solver=liblinear;, score=0.925 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.04, penalty=l2, solver=saga;, score=0.662 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.04, penalty=l2, solver=saga;, score=0.725 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.04, penalty=l2, solver=saga;, score=0.662 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.04, penalty=l2, solver=saga;, score=0.637 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.04, penalty=l2, solver=saga;, score=0.656 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.9825  0.87875     nan 0.5325  0.88625     nan 0.9825      nan 0.985\n",
      " 0.985       nan 0.5825      nan     nan 0.7725  0.9825  0.98        nan\n",
      " 0.88625 0.66875]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[422   4]\n",
      " [  2 372]] \n",
      "\n",
      "Accuracy: 99.2 \n",
      "\n",
      "F1 Score: 99.2 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[106   1]\n",
      " [  1  92]] \n",
      "\n",
      "Accuracy: 99.0 \n",
      "\n",
      "F1 Score: 98.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_gpt2, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_gpt2_train, accuracy_lr_gpt2_train, f1_lr_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_gpt2_test, accuracy_lr_gpt2_test, f1_lr_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:48:24.236538567Z",
     "start_time": "2023-05-01T18:48:08.286468012Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPT2 + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|ââââââââââ| 10/10 [01:49<00:00, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  6 368]] \n",
      "\n",
      "Accuracy: 99.2 \n",
      "\n",
      "F1 Score: 99.2 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[107   0]\n",
      " [  3  90]] \n",
      "\n",
      "Accuracy: 98.5 \n",
      "\n",
      "F1 Score: 98.4 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_gpt2.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_gpt2.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_gpt2, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_gpt2_train, accuracy_nn_gpt2_train, f1_nn_gpt2_train = classifier.evaluate(X_train_embeddings_gpt2, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_gpt2_test, accuracy_nn_gpt2_test, f1_nn_gpt2_test = classifier.evaluate(X_test_embeddings_gpt2, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:50:13.677532533Z",
     "start_time": "2023-05-01T18:48:24.239723277Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=8, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=7, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.981 total time=   0.0s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=minkowski, n_neighbors=6, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.975 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[421   5]\n",
      " [  3 371]] \n",
      "\n",
      "Accuracy: 99.0 \n",
      "\n",
      "F1 Score: 98.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[106   1]\n",
      " [  1  92]] \n",
      "\n",
      "Accuracy: 99.0 \n",
      "\n",
      "F1 Score: 98.9 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = KNNClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_knn_roberta_train, accuracy_knn_roberta_train, f1_knn_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_knn_roberta_test, accuracy_knn_roberta_test, f1_knn_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:50:15.808639227Z",
     "start_time": "2023-05-01T18:50:13.677842871Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.988 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=1.000 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=1.000 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=1.000 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.988 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=1.000 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=1.000 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=1.000 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=7, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.900 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.988 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.981 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=1.000 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=500, objective=reg:squarederror, subsample=0.5;, score=0.988 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.981 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.994 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=1.000 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.988 total time=   0.3s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[107   0]\n",
      " [  0  93]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = XGBoostClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_xgb_roberta_train, accuracy_xgb_roberta_train, f1_xgb_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_xgb_roberta_test, accuracy_xgb_roberta_test, f1_xgb_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:51:45.122197088Z",
     "start_time": "2023-05-01T18:50:15.817276462Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.950 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.956 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.956 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.963 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.963 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.969 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.950 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.963 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.981 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.969 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.969 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.938 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.994 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.988 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=10;, score=0.944 total time=   0.0s\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[105   2]\n",
      " [  2  91]] \n",
      "\n",
      "Accuracy: 98.0 \n",
      "\n",
      "F1 Score: 97.8 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = RFClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 25],\n",
    "    'max_features': [5, 10],\n",
    "    'max_depth': [10, 50, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_rf_roberta_train, accuracy_rf_roberta_train, f1_rf_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_rf_roberta_test, accuracy_rf_roberta_test, f1_rf_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:51:51.446879604Z",
     "start_time": "2023-05-01T18:51:45.128596486Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.956 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.994 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.981 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.950 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.981 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.944 total time=   0.1s\n",
      "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.531 total time=   0.1s\n",
      "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.531 total time=   0.1s\n",
      "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.531 total time=   0.1s\n",
      "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.531 total time=   0.1s\n",
      "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.537 total time=   0.1s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.969 total time=   0.1s\n",
      "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.981 total time=   0.1s\n",
      "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.988 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.963 total time=   0.1s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.963 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.975 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.963 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.887 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.906 total time=   0.0s\n",
      "[LibSVM]*\n",
      "optimization finished, #iter = 383\n",
      "obj = -41.229965, rho = 12.542940\n",
      "nSV = 114, nBSV = 43\n",
      "Total nSV = 114\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  1 373]] \n",
      "\n",
      "Accuracy: 99.9 \n",
      "\n",
      "F1 Score: 99.9 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[107   0]\n",
      " [  0  93]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = SVClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale']\n",
    "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_svc_roberta_train, accuracy_svc_roberta_train, f1_svc_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_svc_roberta_test, accuracy_svc_roberta_test, f1_svc_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:51:55.360023410Z",
     "start_time": "2023-05-01T18:51:51.452726106Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.28, penalty=none, solver=sag;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.28, penalty=none, solver=sag;, score=1.000 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.28, penalty=none, solver=sag;, score=0.988 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.28, penalty=none, solver=sag;, score=1.000 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.28, penalty=none, solver=sag;, score=0.994 total time=   0.4s\n",
      "[CV 1/5] END C=0.47000000000000003, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.47000000000000003, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.47000000000000003, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.47000000000000003, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.47000000000000003, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.9500000000000001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.9500000000000001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.9500000000000001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.9500000000000001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.9500000000000001, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.71, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.71, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.71, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.71, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.71, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.85, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.85, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.85, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.85, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.85, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .....C=0.6, penalty=l2, solver=sag;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=0.6, penalty=l2, solver=sag;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .....C=0.6, penalty=l2, solver=sag;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .....C=0.6, penalty=l2, solver=sag;, score=1.000 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .....C=0.6, penalty=l2, solver=sag;, score=0.994 total time=   0.3s\n",
      "[CV 1/5] END C=0.59, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 2/5] END C=0.59, penalty=l2, solver=liblinear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.59, penalty=l2, solver=liblinear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=0.59, penalty=l2, solver=liblinear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.59, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END C=0.59, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.59, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.59, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.59, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.59, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.24, penalty=none, solver=lbfgs;, score=0.994 total time=   0.0s\n",
      "[CV 2/5] END C=0.24, penalty=none, solver=lbfgs;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.24, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=0.24, penalty=none, solver=lbfgs;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.24, penalty=none, solver=lbfgs;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END C=0.38, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.38, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END C=0.38, penalty=l2, solver=liblinear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=0.38, penalty=l2, solver=liblinear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.38, penalty=l2, solver=liblinear;, score=0.988 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.47000000000000003, penalty=l2, solver=saga;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.47000000000000003, penalty=l2, solver=saga;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.47000000000000003, penalty=l2, solver=saga;, score=0.988 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.47000000000000003, penalty=l2, solver=saga;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.47000000000000003, penalty=l2, solver=saga;, score=0.988 total time=   0.4s\n",
      "[CV 1/5] END C=0.39, penalty=l2, solver=newton-cg;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END C=0.39, penalty=l2, solver=newton-cg;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.39, penalty=l2, solver=newton-cg;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=0.39, penalty=l2, solver=newton-cg;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.39, penalty=l2, solver=newton-cg;, score=0.994 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.56, penalty=l2, solver=saga;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.56, penalty=l2, solver=saga;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.56, penalty=l2, solver=saga;, score=0.988 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.56, penalty=l2, solver=saga;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.56, penalty=l2, solver=saga;, score=0.988 total time=   0.5s\n",
      "[CV 1/5] END C=0.43, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 2/5] END C=0.43, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 3/5] END C=0.43, penalty=l2, solver=liblinear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=0.43, penalty=l2, solver=liblinear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.43, penalty=l2, solver=liblinear;, score=0.988 total time=   0.0s\n",
      "[CV 1/5] END C=0.39, penalty=none, solver=lbfgs;, score=0.994 total time=   0.0s\n",
      "[CV 2/5] END C=0.39, penalty=none, solver=lbfgs;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.39, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=0.39, penalty=none, solver=lbfgs;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.39, penalty=none, solver=lbfgs;, score=1.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.02, penalty=none, solver=sag;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.02, penalty=none, solver=sag;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.02, penalty=none, solver=sag;, score=0.988 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.02, penalty=none, solver=sag;, score=1.000 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.02, penalty=none, solver=sag;, score=0.994 total time=   0.4s\n",
      "[CV 1/5] END C=0.81, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 2/5] END C=0.81, penalty=l2, solver=liblinear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END C=0.81, penalty=l2, solver=liblinear;, score=0.988 total time=   0.0s\n",
      "[CV 4/5] END C=0.81, penalty=l2, solver=liblinear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END C=0.81, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 1/5] END C=0.27, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.27, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.27, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.27, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.27, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.08, penalty=none, solver=saga;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.08, penalty=none, solver=saga;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.08, penalty=none, solver=saga;, score=0.988 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.08, penalty=none, solver=saga;, score=1.000 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.08, penalty=none, solver=saga;, score=0.994 total time=   0.4s\n",
      "[CV 1/5] END C=0.8, penalty=none, solver=newton-cg;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END C=0.8, penalty=none, solver=newton-cg;, score=1.000 total time=   0.1s\n",
      "[CV 3/5] END C=0.8, penalty=none, solver=newton-cg;, score=0.988 total time=   0.1s\n",
      "[CV 4/5] END C=0.8, penalty=none, solver=newton-cg;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END C=0.8, penalty=none, solver=newton-cg;, score=1.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.99625     nan     nan     nan     nan 0.995   0.995       nan 0.99625\n",
      " 0.9925  0.99375 0.99375 0.99375 0.9925  0.99625 0.99625 0.995       nan\n",
      " 0.995   0.9975 ]\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/szymon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[107   0]\n",
      " [  0  93]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LRClassifier()\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "param_distributions = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : np.arange(0, 1, 0.01)\n",
    "}\n",
    "classifier.randomized_search(X_train_embeddings_roberta, y_train, param_distributions)\n",
    "\n",
    "# Train classifier on training data\n",
    "classifier.fit(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_lr_roberta_train, accuracy_lr_roberta_train, f1_lr_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_lr_roberta_test, accuracy_lr_roberta_test, f1_lr_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:52:09.035808836Z",
     "start_time": "2023-05-01T18:51:55.363850475Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa + Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|ââââââââââ| 10/10 [01:49<00:00, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_______________________________________________________________________\n",
      "EVALUATION\n",
      "\n",
      "----- TRAIN -----\n",
      "\n",
      "Confusion matrix\n",
      " [[426   0]\n",
      " [  0 374]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "\n",
      "----- TEST -----\n",
      "\n",
      "Confusion matrix\n",
      " [[107   0]\n",
      " [  0  93]] \n",
      "\n",
      "Accuracy: 100.0 \n",
      "\n",
      "F1 Score: 100.0 \n",
      "\n",
      "_______________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_embeddings_roberta.shape[1]  # Dimensionality of word embeddings\n",
    "hidden_dim = X_train_embeddings_roberta.shape[1]*2  # Number of units in the hidden layer\n",
    "\n",
    "classifier = NeuralNetworkClassifier(input_dim, hidden_dim)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_embeddings_roberta, y_train, num_epochs=10, lr=0.001)\n",
    "\n",
    "# Evaluate classifier\n",
    "print('\\n')\n",
    "print('\\n_______________________________________________________________________')\n",
    "print('EVALUATION')\n",
    "\n",
    "print('\\n----- TRAIN -----')\n",
    "cm_nn_roberta_train, accuracy_nn_roberta_train, f1_nn_roberta_train = classifier.evaluate(X_train_embeddings_roberta, y_train)\n",
    "\n",
    "print('\\n----- TEST -----')\n",
    "cm_nn_roberta_test, accuracy_nn_roberta_test, f1_nn_roberta_test = classifier.evaluate(X_test_embeddings_roberta, y_test)\n",
    "print('_______________________________________________________________________')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:53:58.328924934Z",
     "start_time": "2023-05-01T18:52:09.038902605Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T19:17:36.621830048Z",
     "start_time": "2023-05-01T19:17:36.566117887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âââââââââââââââââââââââââââ¤âââââââââââââ¤âââââââââââââ\n",
      "â Model                   â   Accuracy â   F1-Score â\n",
      "âââââââââââââââââââââââââââªâââââââââââââªâââââââââââââ¡\n",
      "â KNN+BERT                â       95.5 â       95.2 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â XGBoost+BERT            â       95.5 â       95.3 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RandomForest+BERT       â       94   â       93.8 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â SVC+BERT                â       97.5 â       97.4 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â LR+BERT                 â       96.5 â       96.2 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â NeuralNetwork+BERT      â       95.5 â       95.3 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â KNN+GloVe               â       92.5 â       92   â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â XGBoost+GloVe           â       96   â       95.7 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RandomForest+GloVe      â       93.5 â       93.2 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â SVC+GloVe               â       98.5 â       98.4 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â LR+GloVe                â       98.5 â       98.4 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â NeuralNetwork+GloVe     â       92.5 â       91.4 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â KNN+Word2Vec            â       89   â       87.8 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â XGBoost+Word2Vec        â       96   â       95.6 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RandomForest + Word2Vec â       94.5 â       94.1 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â SVC+Word2Vec            â       98.5 â       98.4 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â LR+Word2Vec             â       98   â       97.9 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â NeuralNetwork+Word2Vec  â       97.5 â       97.3 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â KNN+GPT2                â       96.5 â       96.2 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â XGBoost+GPT2            â       98   â       97.8 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RandomForest+GPT2       â       96   â       95.7 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â SVC+GPT2                â       99.5 â       99.5 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â LR+GPT2                 â       99   â       98.9 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â NeuralNetwork+GPT2      â       98.5 â       98.4 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â KNN+RoBERTa             â       99   â       98.9 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â XGBoost+RoBERTa         â      100   â      100   â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RandomForest+RoBERTa    â       98   â       97.8 â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â SVC+RoBERTa             â      100   â      100   â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â LR+RoBERTa              â      100   â      100   â\n",
      "âââââââââââââââââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â NeuralNetwork+RoBERTa   â      100   â      100   â\n",
      "âââââââââââââââââââââââââââ§âââââââââââââ§âââââââââââââ\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "data = [[\"KNN+BERT\", accuracy_knn_bert_test, f1_knn_bert_test],\n",
    "        [\"XGBoost+BERT\", accuracy_xgb_bert_test, f1_xgb_bert_test],\n",
    "        [\"RandomForest+BERT\", accuracy_rf_bert_test, f1_rf_bert_test],\n",
    "        [\"SVC+BERT\", accuracy_svc_bert_test, f1_svc_bert_test],\n",
    "        [\"LR+BERT\", accuracy_lr_bert_test, f1_lr_bert_test],\n",
    "        [\"NeuralNetwork+BERT\", accuracy_nn_bert_test, f1_nn_bert_test],\n",
    "        [\"KNN+GloVe\", accuracy_knn_glove_test, f1_knn_glove_test],\n",
    "        [\"XGBoost+GloVe\", accuracy_xgb_glove_test, f1_xgb_glove_test],\n",
    "        [\"RandomForest+GloVe\", accuracy_rf_glove_test, f1_rf_glove_test],\n",
    "        [\"SVC+GloVe\", accuracy_svc_glove_test, f1_svc_glove_test],\n",
    "        [\"LR+GloVe\", accuracy_lr_glove_test, f1_lr_glove_test],\n",
    "        [\"NeuralNetwork+GloVe\", accuracy_nn_glove_test, f1_nn_glove_test],\n",
    "        [\"KNN+Word2Vec\", accuracy_knn_w2v_test, f1_knn_w2v_test],\n",
    "        [\"XGBoost+Word2Vec\", accuracy_xgb_w2v_test, f1_xgb_w2v_test],\n",
    "        [\"RandomForest + Word2Vec\", accuracy_rf_w2v_test, f1_rf_w2v_test],\n",
    "        [\"SVC+Word2Vec\", accuracy_svc_w2v_test, f1_svc_w2v_test],\n",
    "        [\"LR+Word2Vec\", accuracy_lr_w2v_test, f1_lr_w2v_test],\n",
    "        [\"NeuralNetwork+Word2Vec\", accuracy_nn_w2v_test, f1_nn_w2v_test],\n",
    "        [\"KNN+GPT2\", accuracy_knn_gpt2_test, f1_knn_gpt2_test],\n",
    "        [\"XGBoost+GPT2\", accuracy_xgb_gpt2_test, f1_xgb_gpt2_test],\n",
    "        [\"RandomForest+GPT2\", accuracy_rf_gpt2_test, f1_rf_gpt2_test],\n",
    "        [\"SVC+GPT2\", accuracy_svc_gpt2_test, f1_svc_gpt2_test],\n",
    "        [\"LR+GPT2\", accuracy_lr_gpt2_test, f1_lr_gpt2_test],\n",
    "        [\"NeuralNetwork+GPT2\", accuracy_nn_gpt2_test, f1_nn_gpt2_test],\n",
    "        [\"KNN+RoBERTa\", accuracy_knn_roberta_test, f1_knn_roberta_test],\n",
    "        [\"XGBoost+RoBERTa\", accuracy_xgb_roberta_test, f1_xgb_roberta_test],\n",
    "        [\"RandomForest+RoBERTa\", accuracy_rf_roberta_test, f1_rf_roberta_test],\n",
    "        [\"SVC+RoBERTa\", accuracy_svc_roberta_test, f1_svc_roberta_test],\n",
    "        [\"LR+RoBERTa\", accuracy_lr_roberta_test, f1_lr_roberta_test],\n",
    "        [\"NeuralNetwork+RoBERTa\", accuracy_nn_roberta_test, f1_nn_roberta_test]]\n",
    "  \n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#save results to csv\n",
    "if fast:\n",
    "    with open(\"results_fast_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(col_names)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "else:\n",
    "    with open(\"results_\"+time.strftime(\"%Y%m%d-%H%M%S\")+\".csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(col_names)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "#display table\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      " Model                   &   Accuracy &   F1-Score \\\\\n",
      "\\hline\n",
      " KNN+BERT                &       95.5 &       95.2 \\\\\n",
      " XGBoost+BERT            &       95.5 &       95.3 \\\\\n",
      " RandomForest+BERT       &       94   &       93.8 \\\\\n",
      " SVC+BERT                &       97.5 &       97.4 \\\\\n",
      " LR+BERT                 &       96.5 &       96.2 \\\\\n",
      " NeuralNetwork+BERT      &       95.5 &       95.3 \\\\\n",
      " KNN+GloVe               &       92.5 &       92   \\\\\n",
      " XGBoost+GloVe           &       96   &       95.7 \\\\\n",
      " RandomForest+GloVe      &       93.5 &       93.2 \\\\\n",
      " SVC+GloVe               &       98.5 &       98.4 \\\\\n",
      " LR+GloVe                &       98.5 &       98.4 \\\\\n",
      " NeuralNetwork+GloVe     &       92.5 &       91.4 \\\\\n",
      " KNN+Word2Vec            &       89   &       87.8 \\\\\n",
      " XGBoost+Word2Vec        &       96   &       95.6 \\\\\n",
      " RandomForest + Word2Vec &       94.5 &       94.1 \\\\\n",
      " SVC+Word2Vec            &       98.5 &       98.4 \\\\\n",
      " LR+Word2Vec             &       98   &       97.9 \\\\\n",
      " NeuralNetwork+Word2Vec  &       97.5 &       97.3 \\\\\n",
      " KNN+GPT2                &       96.5 &       96.2 \\\\\n",
      " XGBoost+GPT2            &       98   &       97.8 \\\\\n",
      " RandomForest+GPT2       &       96   &       95.7 \\\\\n",
      " SVC+GPT2                &       99.5 &       99.5 \\\\\n",
      " LR+GPT2                 &       99   &       98.9 \\\\\n",
      " NeuralNetwork+GPT2      &       98.5 &       98.4 \\\\\n",
      " KNN+RoBERTa             &       99   &       98.9 \\\\\n",
      " XGBoost+RoBERTa         &      100   &      100   \\\\\n",
      " RandomForest+RoBERTa    &       98   &       97.8 \\\\\n",
      " SVC+RoBERTa             &      100   &      100   \\\\\n",
      " LR+RoBERTa              &      100   &      100   \\\\\n",
      " NeuralNetwork+RoBERTa   &      100   &      100   \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "#print(tabulate(data, headers=col_names, tablefmt=\"latex\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T19:17:37.596490888Z",
     "start_time": "2023-05-01T19:17:37.561376633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "ââââââââââââ¤âââââââââââââ¤âââââââââââââ\n",
      "â Model    â   Accuracy â   F1-Score â\n",
      "ââââââââââââªâââââââââââââªâââââââââââââ¡\n",
      "â BERT     â       95.5 â       95.2 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GloVe    â       92.5 â       92   â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â Word2Vec â       89   â       87.8 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GPT2     â       96.5 â       96.2 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RoBERTa  â       99   â       98.9 â\n",
      "ââââââââââââ§âââââââââââââ§âââââââââââââ\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "knn_results = [[\"BERT\", accuracy_knn_bert_test, f1_knn_bert_test],\n",
    "        [\"GloVe\", accuracy_knn_glove_test, f1_knn_glove_test],\n",
    "        [\"Word2Vec\", accuracy_knn_w2v_test, f1_knn_w2v_test],\n",
    "        [\"GPT2\", accuracy_knn_gpt2_test, f1_knn_gpt2_test],\n",
    "        [\"RoBERTa\", accuracy_knn_roberta_test, f1_knn_roberta_test]]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"KNN\")\n",
    "print(tabulate(knn_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:53:58.418612917Z",
     "start_time": "2023-05-01T18:53:58.353344382Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "ââââââââââââ¤âââââââââââââ¤âââââââââââââ\n",
      "â Model    â   Accuracy â   F1-Score â\n",
      "ââââââââââââªâââââââââââââªâââââââââââââ¡\n",
      "â BERT     â       95.5 â       95.3 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GloVe    â       96   â       95.7 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â Word2Vec â       96   â       95.6 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GPT2     â       98   â       97.8 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RoBERTa  â      100   â      100   â\n",
      "ââââââââââââ§âââââââââââââ§âââââââââââââ\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "xgb_results = [[\"BERT\", accuracy_xgb_bert_test, f1_xgb_bert_test],\n",
    "        [\"GloVe\", accuracy_xgb_glove_test, f1_xgb_glove_test],\n",
    "        [\"Word2Vec\", accuracy_xgb_w2v_test, f1_xgb_w2v_test],\n",
    "        [\"GPT2\", accuracy_xgb_gpt2_test, f1_xgb_gpt2_test],\n",
    "        [\"RoBERTa\", accuracy_xgb_roberta_test, f1_xgb_roberta_test]]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"XGBoost\")\n",
    "print(tabulate(xgb_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:53:58.418862745Z",
     "start_time": "2023-05-01T18:53:58.400158630Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "ââââââââââââ¤âââââââââââââ¤âââââââââââââ\n",
      "â Model    â   Accuracy â   F1-Score â\n",
      "ââââââââââââªâââââââââââââªâââââââââââââ¡\n",
      "â BERT     â       94   â       93.8 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GloVe    â       93.5 â       93.2 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â Word2Vec â       94.5 â       94.1 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GPT2     â       96   â       95.7 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RoBERTa  â       98   â       97.8 â\n",
      "ââââââââââââ§âââââââââââââ§âââââââââââââ\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "rf_results = [[\"BERT\", accuracy_rf_bert_test, f1_rf_bert_test],\n",
    "        [\"GloVe\", accuracy_rf_glove_test, f1_rf_glove_test],\n",
    "        [\"Word2Vec\", accuracy_rf_w2v_test, f1_rf_w2v_test],\n",
    "        [\"GPT2\", accuracy_rf_gpt2_test, f1_rf_gpt2_test],\n",
    "        [\"RoBERTa\", accuracy_rf_roberta_test, f1_rf_roberta_test]]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"Random Forest\")\n",
    "print(tabulate(rf_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:53:58.419010854Z",
     "start_time": "2023-05-01T18:53:58.400349368Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "ââââââââââââ¤âââââââââââââ¤âââââââââââââ\n",
      "â Model    â   Accuracy â   F1-Score â\n",
      "ââââââââââââªâââââââââââââªâââââââââââââ¡\n",
      "â BERT     â       97.5 â       97.4 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GloVe    â       98.5 â       98.4 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â Word2Vec â       98.5 â       98.4 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GPT2     â       99.5 â       99.5 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RoBERTa  â      100   â      100   â\n",
      "ââââââââââââ§âââââââââââââ§âââââââââââââ\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "svc_results = [[\"BERT\", accuracy_svc_bert_test, f1_svc_bert_test],\n",
    "        [\"GloVe\", accuracy_svc_glove_test, f1_svc_glove_test],\n",
    "        [\"Word2Vec\", accuracy_svc_w2v_test, f1_svc_w2v_test],\n",
    "        [\"GPT2\", accuracy_svc_gpt2_test, f1_svc_gpt2_test],\n",
    "        [\"RoBERTa\", accuracy_svc_roberta_test, f1_svc_roberta_test]]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"SVM Classifier\")\n",
    "print(tabulate(svc_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:53:58.419156603Z",
     "start_time": "2023-05-01T18:53:58.400471087Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "ââââââââââââ¤âââââââââââââ¤âââââââââââââ\n",
      "â Model    â   Accuracy â   F1-Score â\n",
      "ââââââââââââªâââââââââââââªâââââââââââââ¡\n",
      "â BERT     â       96.5 â       96.2 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GloVe    â       98.5 â       98.4 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â Word2Vec â       98   â       97.9 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GPT2     â       99   â       98.9 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RoBERTa  â      100   â      100   â\n",
      "ââââââââââââ§âââââââââââââ§âââââââââââââ\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "lr_results = [[\"BERT\", accuracy_lr_bert_test, f1_lr_bert_test],\n",
    "        [\"GloVe\", accuracy_lr_glove_test, f1_lr_glove_test],\n",
    "        [\"Word2Vec\", accuracy_lr_w2v_test, f1_lr_w2v_test],\n",
    "        [\"GPT2\", accuracy_lr_gpt2_test, f1_lr_gpt2_test],\n",
    "        [\"RoBERTa\", accuracy_lr_roberta_test, f1_lr_roberta_test]]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"Logistic Regression\")\n",
    "print(tabulate(lr_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:53:58.419303222Z",
     "start_time": "2023-05-01T18:53:58.400686636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork\n",
      "ââââââââââââ¤âââââââââââââ¤âââââââââââââ\n",
      "â Model    â   Accuracy â   F1-Score â\n",
      "ââââââââââââªâââââââââââââªâââââââââââââ¡\n",
      "â BERT     â       95.5 â       95.3 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GloVe    â       92.5 â       91.4 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â Word2Vec â       97.5 â       97.3 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â GPT2     â       98.5 â       98.4 â\n",
      "ââââââââââââ¼âââââââââââââ¼âââââââââââââ¤\n",
      "â RoBERTa  â      100   â      100   â\n",
      "ââââââââââââ§âââââââââââââ§âââââââââââââ\n"
     ]
    }
   ],
   "source": [
    "#create data\n",
    "nn_results = [[\"BERT\", accuracy_nn_bert_test, f1_nn_bert_test],\n",
    "        [\"GloVe\", accuracy_nn_glove_test, f1_nn_glove_test],\n",
    "        [\"Word2Vec\", accuracy_nn_w2v_test, f1_nn_w2v_test],\n",
    "        [\"GPT2\", accuracy_nn_gpt2_test, f1_nn_gpt2_test],\n",
    "        [\"RoBERTa\", accuracy_nn_roberta_test, f1_nn_roberta_test]]\n",
    "\n",
    "#define header names\n",
    "col_names = [\"Model\", \"Accuracy\", \"F1-Score\"]\n",
    "\n",
    "#display table\n",
    "print(\"NeuralNetwork\")\n",
    "print(tabulate(nn_results, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-01T18:53:58.419478421Z",
     "start_time": "2023-05-01T18:53:58.400796885Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24t1eSrlFLK6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
