{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP3+rWQZrQ8a2Ih2rVkwD7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT word embeddings + various classification algorithms"
      ],
      "metadata": {
        "id": "vpFId1mjCySe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrZu8iBOnAZ4",
        "outputId": "2eb000a7-d3eb-4feb-f6a6-01c43f32dbfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as functional\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertModel, AutoTokenizer, AutoModel\n",
        "import gc\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score, classification_report, accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "id": "TCU7NPLUuQrU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "fake = pd.read_csv('/content/drive/MyDrive/master-thesis/thesis-data/Fake.csv')\n",
        "true = pd.read_csv('/content/drive/MyDrive/master-thesis/thesis-data/True.csv')\n",
        "\n",
        "fake[\"label\"] = 0\n",
        "true[\"label\"] = 1\n",
        "\n",
        "df = pd.concat([fake, true], ignore_index = True)\n",
        "\n",
        "df['text'] = df['title'] + \" \" + df['text']\n",
        "df.drop(columns=['title', 'date', 'subject'], inplace = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaFYAFhluSCU",
        "outputId": "e241044f-86ca-42d2-aa6e-6190a3facd92"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "    \n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(denoise_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieOrxB_AuTwA",
        "outputId": "412af1ca-ce15-4ceb-df3c-2f6b0c6fe394"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-41-67ef971f5969>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST IF WORKS!!! --------\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop = set(nltk.corpus.stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def remove_noise(text):\n",
        "    text = strip_html(text)\n",
        "    text = re.sub(r'\\[[^]]*\\]|\\bhttp\\S+', '', text)\n",
        "    text = ' '.join(word.lower() for word in text.split() if word.lower() not in stop)\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(remove_noise)\n",
        "# ----------"
      ],
      "metadata": {
        "id": "hHUMKD0xcDhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "QQMXCPQ97YRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce dataset for testing purposes"
      ],
      "metadata": {
        "id": "TIG7v_fk7jbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original = df.copy()\n",
        "df = df.sample(frac=1).reset_index(drop=True)[:1000]"
      ],
      "metadata": {
        "id": "3OAKnGLyuVS0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "oA_tL8Sg7VWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "E-lrFVWwGiwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Embedding"
      ],
      "metadata": {
        "id": "NqQEmeGREcUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "X = df['text'].tolist()\n",
        "y = df['label'].tolist()\n",
        "\n",
        "# Split data into training and test sets\n",
        "\n",
        "# # Old\n",
        "# train_size = int(0.8 * len(X))\n",
        "# X_train = X[:train_size]\n",
        "# y_train = y[:train_size]\n",
        "# X_test = X[train_size:]\n",
        "# y_test = y[train_size:]\n",
        "\n",
        "# New\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert = AutoModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "\n",
        "def _get_bert_embedding(text):\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=256)\n",
        "    input_ids = np.array(input_ids)\n",
        "    input_ids = np.expand_dims(input_ids, axis=0)\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert(input_ids)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        last_hidden_state = last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "    return last_hidden_state\n",
        "\n",
        "print(\"TRAIN\")\n",
        "X_train_embeddings = []\n",
        "for text in tqdm(X_train):\n",
        "    embedding = _get_bert_embedding(text)\n",
        "    X_train_embeddings.append(embedding)\n",
        "X_train_embeddings = np.array(X_train_embeddings)\n",
        "X_train_embeddings = np.squeeze(X_train_embeddings, axis=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "X_test_embeddings = []\n",
        "for text in tqdm(X_test):\n",
        "    embedding = _get_bert_embedding(text)\n",
        "    X_test_embeddings.append(embedding)\n",
        "X_test_embeddings = np.array(X_test_embeddings)\n",
        "X_test_embeddings = np.squeeze(X_test_embeddings, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pbSRaebguY2a",
        "outputId": "51510429-03ad-454f-f60a-cd81c84c09f1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 80/800 [01:11<10:40,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-78e66971d689>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mX_train_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_bert_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mX_train_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mX_train_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-78e66971d689>\u001b[0m in \u001b[0;36m_get_bert_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mlast_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlast_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embeddings_bert = X_train_embeddings.copy()\n",
        "X_test_embeddings_bert = X_test_embeddings.copy()\n",
        "\n",
        "X_train_split = X_train.copy()\n",
        "X_test_split = X_test.copy()\n",
        "y_train_split = y_train.copy()\n",
        "y_test_split = y_test.copy()\n",
        "\n",
        "# # Save current state -----------------------------------------------------------\n",
        "# with open(\"/content/drive/MyDrive/master-thesis/embeddings/X_train\", \"wb\") as fp:\n",
        "#   pickle.dump(X_train, fp)\n",
        "# with open(\"/content/drive/MyDrive/master-thesis/embeddings/X_test\", \"wb\") as fp:\n",
        "#   pickle.dump(X_test, fp)\n",
        "# with open(\"/content/drive/MyDrive/master-thesis/embeddings/y_train\", \"wb\") as fp:\n",
        "#   pickle.dump(y_train, fp)\n",
        "# with open(\"/content/drive/MyDrive/master-thesis/embeddings/y_test\", \"wb\") as fp:\n",
        "#   pickle.dump(y_test, fp)\n",
        "\n",
        "# pd.DataFrame(X_train_embeddings).to_csv(\"/content/drive/MyDrive/master-thesis/embeddings/X_train_embeddings.csv\", index=False, header=False)\n",
        "# pd.DataFrame(X_test_embeddings).to_csv(\"/content/drive/MyDrive/master-thesis/embeddings/X_test_embeddings.csv\", index=False, header=False)\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/master-thesis/embeddings/X\", \"wb\") as fp:\n",
        "#   pickle.dump(X, fp)\n",
        "# with open(\"/content/drive/MyDrive/master-thesis/embeddings/y\", \"wb\") as fp:\n",
        "#   pickle.dump(y, fp)\n",
        "# # ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "bVtZ4k1wI_0-",
        "outputId": "99deb42e-4ada-4ec1-d987-00a15652167e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-50e5b7a909ad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_embeddings_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_embeddings_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'copy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve data ----------------------------------------------------------------\n",
        "with open(\"/content/drive/MyDrive/master-thesis/embeddings/X_train\", \"rb\") as fp:\n",
        "  X_train = pickle.load(fp)\n",
        "with open(\"/content/drive/MyDrive/master-thesis/embeddings/X_test\", \"rb\") as fp:\n",
        "  X_test = pickle.load(fp)\n",
        "with open(\"/content/drive/MyDrive/master-thesis/embeddings/y_train\", \"rb\") as fp:\n",
        "  y_train = pickle.load(fp)\n",
        "with open(\"/content/drive/MyDrive/master-thesis/embeddings/y_test\", \"rb\") as fp:\n",
        "  y_test = pickle.load(fp)\n",
        "\n",
        "X_train_embeddings = pd.read_csv('/content/drive/MyDrive/master-thesis/embeddings/X_train_embeddings.csv', sep=',', header=None).values\n",
        "X_test_embeddings = pd.read_csv('/content/drive/MyDrive/master-thesis/embeddings/X_test_embeddings.csv', sep=',', header=None).values\n",
        "\n",
        "with open(\"/content/drive/MyDrive/master-thesis/embeddings/X\", \"rb\") as fp:\n",
        "  X = pickle.load(fp)\n",
        "with open(\"/content/drive/MyDrive/master-thesis/embeddings/y\", \"rb\") as fp:\n",
        "  y = pickle.load(fp)\n",
        "# ------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "8Ro4b4-kKUx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ... Embedding"
      ],
      "metadata": {
        "id": "bhGA1YV7GaKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "VMvpJtV-EiIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT embeddings"
      ],
      "metadata": {
        "id": "VlaJrgisGNfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "XMOZaIWp0_oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNClassifier:\n",
        "    def __init__(self, n_neighbors=2, weights='uniform', metric='minkowski'):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        if self.model is None:\n",
        "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        return y_pred\n",
        "\n",
        "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
        "        self.model = KNeighborsClassifier()\n",
        "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        self.n_neighbors = random_search.best_params_['n_neighbors']\n",
        "        self.weights = random_search.best_params_['weights']\n",
        "        self.metric = random_search.best_params_['metric']\n",
        "\n",
        "        self.model = KNeighborsClassifier(n_neighbors=self.n_neighbors, weights=self.weights, metric=self.metric)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        if self.model is None:\n",
        "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.predict(X_test)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
        "        print('Accuracy:', accuracy, '\\n')\n",
        "        print('F1 Score:', f1, '\\n')\n",
        "\n",
        "        return cm, accuracy, f1"
      ],
      "metadata": {
        "id": "e8NtrTGp08S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate classifier\n",
        "classifier = KNNClassifier()\n",
        "\n",
        "# Perform randomized search over hyperparameters\n",
        "param_distributions = {\n",
        "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    'weights' : ['uniform','distance'],\n",
        "    'metric' : ['minkowski','euclidean','manhattan']\n",
        "}\n",
        "classifier.randomized_search(X_train_embeddings, y_train, param_distributions)\n",
        "\n",
        "# Train classifier on training data\n",
        "classifier.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "print('\\n')\n",
        "print('\\n_______________________________________________________________________')\n",
        "print('EVALUATION')\n",
        "\n",
        "print('\\n----- TRAIN -----')\n",
        "cm, accuracy, f1 = classifier.evaluate(X_train_embeddings, y_train)\n",
        "\n",
        "print('\\n----- TEST -----')\n",
        "cm, accuracy, f1 = classifier.evaluate(X_test_embeddings, y_test)\n",
        "print('_______________________________________________________________________')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "7HzI3FV7zy6t",
        "outputId": "8ca1830c-a309-4f27-f6dd-cee648ee0978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-bfa1a1437dd4>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m'metric'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'minkowski'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'manhattan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomized_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train classifier on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-8104772c5c2c>\u001b[0m in \u001b[0;36mrandomized_search\u001b[0;34m(self, X_train, y_train, param_distributions, cv, n_iter)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_neighbors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 800]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "bg4FzG2htmwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XGBoostClassifier:\n",
        "    def __init__(self, learning_rate=0.1, max_depth=5, min_child_weight=1, subsample=0.5, colsample_bytree=0.5, n_estimators=100, objective='req:squarederror'):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.subsample = subsample\n",
        "        self.colsample_bytree = colsample_bytree\n",
        "        self.n_estimators = n_estimators\n",
        "        self.objective = objective\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        if self.model is None:\n",
        "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.model.predict(X_test)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
        "        self.model = xgb.XGBClassifier()\n",
        "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        self.learning_rate = random_search.best_params_['learning_rate']\n",
        "        self.max_depth = random_search.best_params_['max_depth']\n",
        "        self.min_child_weight = random_search.best_params_['min_child_weight']\n",
        "        self.subsample = random_search.best_params_['subsample']\n",
        "        self.colsample_bytree = random_search.best_params_['colsample_bytree']\n",
        "        self.n_estimators = random_search.best_params_['n_estimators']\n",
        "        self.objective = random_search.best_params_['objective']\n",
        "\n",
        "        self.model = xgb.XGBClassifier(learning_rate=self.learning_rate, max_depth=self.max_depth, min_child_weight=self.min_child_weight, subsample=self.subsample, colsample_bytree=self.colsample_bytree, n_estimators=self.n_estimators, objective=self.objective)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        if self.model is None:\n",
        "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.predict(X_test)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
        "        print('Accuracy:', accuracy, '\\n')\n",
        "        print('F1 Score:', f1, '\\n')\n",
        "\n",
        "        return cm, accuracy, f1"
      ],
      "metadata": {
        "id": "2gk8gwvitoQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate classifier\n",
        "classifier = XGBoostClassifier()\n",
        "\n",
        "# Perform randomized search over hyperparameters\n",
        "param_distributions = {\n",
        "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.5, 0.7],\n",
        "    'colsample_bytree': [0.5, 0.7],\n",
        "    'n_estimators': [50, 100, 200, 500],\n",
        "    'objective': ['reg:squarederror']\n",
        "}\n",
        "classifier.randomized_search(X_train_embeddings, y_train, param_distributions)\n",
        "\n",
        "# Train classifier on training data\n",
        "classifier.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "print('\\n')\n",
        "print('\\n_______________________________________________________________________')\n",
        "print('EVALUATION')\n",
        "\n",
        "print('\\n----- TRAIN -----')\n",
        "conf_matrix, accuracy, f1_sc = classifier.evaluate(X_train_embeddings, y_train)\n",
        "\n",
        "print('\\n----- TEST -----')\n",
        "conf_matrix, accuracy, f1_sc = classifier.evaluate(X_test_embeddings, y_test)\n",
        "print('_______________________________________________________________________')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psJLbuc_win3",
        "outputId": "554936c2-e2c5-4b6f-df80-f9e4054f0dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   2.3s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   2.5s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   3.3s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   2.0s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   2.0s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   1.8s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   1.4s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   1.1s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.881 total time=   1.1s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   1.1s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   2.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   2.3s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   2.9s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   3.7s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=   2.4s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   4.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   4.5s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.900 total time=   5.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   4.0s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   4.0s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   5.8s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   4.0s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   4.0s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   5.8s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   4.0s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   2.7s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   2.7s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.912 total time=   4.1s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.894 total time=   3.1s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   2.7s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   2.1s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   2.1s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   6.2s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   2.1s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=100, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   2.1s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   4.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   5.8s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.906 total time=   4.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   4.3s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   7.0s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=   1.5s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   1.0s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   1.0s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   1.0s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   1.0s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   5.5s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   7.3s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   5.3s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   7.2s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.925 total time=   5.3s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   3.9s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   5.8s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   4.0s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.887 total time=   4.1s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   5.9s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   5.1s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.875 total time=   5.6s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.881 total time=   6.6s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.806 total time=   5.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.5, max_depth=7, min_child_weight=1, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   7.2s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   1.0s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=   1.0s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.912 total time=   1.0s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.906 total time=   1.0s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   1.0s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=  10.0s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   8.1s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.925 total time=   9.9s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=  10.3s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=9, min_child_weight=3, n_estimators=200, objective=reg:squarederror, subsample=0.5;, score=0.956 total time=   9.6s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   1.6s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   1.6s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.931 total time=   2.4s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.919 total time=   2.6s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=50, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   1.5s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.975 total time=   6.3s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=   8.0s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   6.2s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=   8.1s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=200, objective=reg:squarederror, subsample=0.7;, score=0.950 total time=   6.2s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.969 total time=   2.5s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.963 total time=   3.9s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.938 total time=   2.9s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.919 total time=   2.5s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.975 total time=   2.6s\n",
            "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=  38.5s\n",
            "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=  39.2s\n",
            "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=  38.1s\n",
            "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.944 total time=  58.8s\n",
            "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.956 total time=  41.5s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.950 total time=   1.2s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   1.2s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   1.3s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.931 total time=   1.2s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, min_child_weight=5, n_estimators=50, objective=reg:squarederror, subsample=0.5;, score=0.944 total time=   1.2s\n",
            "[CV 1/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.963 total time=  12.4s\n",
            "[CV 2/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=  11.4s\n",
            "[CV 3/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=  11.3s\n",
            "[CV 4/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.938 total time=  10.3s\n",
            "[CV 5/5] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=500, objective=reg:squarederror, subsample=0.7;, score=0.969 total time=  11.5s\n",
            "\n",
            "\n",
            "\n",
            "_______________________________________________________________________\n",
            "EVALUATION\n",
            "\n",
            "----- TRAIN -----\n",
            "\n",
            "Confusion matrix\n",
            " [[410   0]\n",
            " [  0 390]] \n",
            "\n",
            "Accuracy: 1.0 \n",
            "\n",
            "F1 Score: 1.0 \n",
            "\n",
            "\n",
            "----- TEST -----\n",
            "\n",
            "Confusion matrix\n",
            " [[99  4]\n",
            " [ 2 95]] \n",
            "\n",
            "Accuracy: 0.97 \n",
            "\n",
            "F1 Score: 0.9693877551020409 \n",
            "\n",
            "_______________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "ekftGhJPFFFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RFClassifier:\n",
        "    def __init__(self, n_estimators=100, max_features='sqrt', max_depth='none', bootstrap=True):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_features = max_features\n",
        "        self.max_depth = max_depth\n",
        "        self.bootstrap = bootstrap\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap, verbose=True)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        if self.model is None:\n",
        "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.model.predict(X_test)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
        "        self.model = RandomForestClassifier()\n",
        "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        self.n_estimators = random_search.best_params_['n_estimators']\n",
        "        self.max_features = random_search.best_params_['max_features']\n",
        "        self.max_depth = random_search.best_params_['max_depth']\n",
        "        self.bootstrap = random_search.best_params_['bootstrap']\n",
        "\n",
        "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_features=self.max_features, max_depth=self.max_depth, bootstrap=self.bootstrap)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        if self.model is None:\n",
        "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.predict(X_test)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
        "        print('Accuracy:', accuracy, '\\n')\n",
        "        print('F1 Score:', f1, '\\n')\n",
        "\n",
        "        return cm, accuracy, f1"
      ],
      "metadata": {
        "id": "MmmjiSG7FGnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate classifier\n",
        "classifier = RFClassifier()\n",
        "\n",
        "# Perform randomized search over hyperparameters\n",
        "param_distributions = {\n",
        "    'n_estimators': [10, 25], \n",
        "    'max_features': [5, 10],\n",
        "    'max_depth': [10, 50, None], \n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "classifier.randomized_search(X_train_embeddings, y_train, param_distributions)\n",
        "\n",
        "# Train classifier on training data\n",
        "classifier.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "print('\\n')\n",
        "print('\\n_______________________________________________________________________')\n",
        "print('EVALUATION')\n",
        "\n",
        "print('\\n----- TRAIN -----')\n",
        "conf_matrix, accuracy, f1_sc = classifier.evaluate(X_train_embeddings, y_train)\n",
        "\n",
        "print('\\n----- TEST -----')\n",
        "conf_matrix, accuracy, f1_sc = classifier.evaluate(X_test_embeddings, y_test)\n",
        "print('_______________________________________________________________________')"
      ],
      "metadata": {
        "id": "_ks6w5IOrJYG",
        "outputId": "0341c3cf-975e-4e0c-8a26-01064b132ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.950 total time=   0.0s\n",
            "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.919 total time=   0.0s\n",
            "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.938 total time=   0.0s\n",
            "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=10;, score=0.931 total time=   0.0s\n",
            "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.925 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.975 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.925 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.938 total time=   0.2s\n",
            "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=25;, score=0.944 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.975 total time=   0.0s\n",
            "[CV 2/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
            "[CV 3/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
            "[CV 4/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
            "[CV 5/5] END bootstrap=False, max_depth=None, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
            "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.925 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.887 total time=   0.0s\n",
            "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.900 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=10;, score=0.906 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.969 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.931 total time=   0.2s\n",
            "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=25;, score=0.950 total time=   0.2s\n",
            "[CV 1/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.912 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.912 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.881 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=False, max_depth=None, max_features=10, n_estimators=10;, score=0.950 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.956 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.919 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.906 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=False, max_depth=10, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.969 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.931 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.887 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=False, max_depth=10, max_features=10, n_estimators=10;, score=0.963 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.919 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.894 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.875 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=10;, score=0.919 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.975 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.887 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=True, max_depth=10, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.975 total time=   0.2s\n",
            "[CV 2/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.963 total time=   0.2s\n",
            "[CV 3/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.931 total time=   0.2s\n",
            "[CV 4/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.956 total time=   0.2s\n",
            "[CV 5/5] END bootstrap=True, max_depth=10, max_features=10, n_estimators=25;, score=0.931 total time=   0.2s\n",
            "[CV 1/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.963 total time=   0.2s\n",
            "[CV 2/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.944 total time=   0.2s\n",
            "[CV 3/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.931 total time=   0.2s\n",
            "[CV 4/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.950 total time=   0.2s\n",
            "[CV 5/5] END bootstrap=True, max_depth=50, max_features=10, n_estimators=25;, score=0.938 total time=   0.2s\n",
            "[CV 1/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.925 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.906 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.881 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.919 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=False, max_depth=50, max_features=5, n_estimators=10;, score=0.906 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.938 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.950 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.925 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.931 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=False, max_depth=50, max_features=10, n_estimators=10;, score=0.931 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.950 total time=   0.2s\n",
            "[CV 2/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.956 total time=   0.2s\n",
            "[CV 3/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.906 total time=   0.2s\n",
            "[CV 4/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.944 total time=   0.2s\n",
            "[CV 5/5] END bootstrap=True, max_depth=None, max_features=10, n_estimators=25;, score=0.938 total time=   0.2s\n",
            "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.938 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.906 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.906 total time=   0.0s\n",
            "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=10;, score=0.931 total time=   0.0s\n",
            "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.969 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.950 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.912 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.944 total time=   0.1s\n",
            "[CV 3/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.881 total time=   0.1s\n",
            "[CV 4/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.938 total time=   0.1s\n",
            "[CV 5/5] END bootstrap=True, max_depth=None, max_features=5, n_estimators=25;, score=0.931 total time=   0.1s\n",
            "[CV 1/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
            "[CV 2/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.900 total time=   0.0s\n",
            "[CV 4/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n",
            "[CV 5/5] END bootstrap=True, max_depth=50, max_features=5, n_estimators=10;, score=0.919 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "_______________________________________________________________________\n",
            "EVALUATION\n",
            "\n",
            "----- TRAIN -----\n",
            "\n",
            "Confusion matrix\n",
            " [[410   0]\n",
            " [  0 390]] \n",
            "\n",
            "Accuracy: 1.0 \n",
            "\n",
            "F1 Score: 1.0 \n",
            "\n",
            "\n",
            "----- TEST -----\n",
            "\n",
            "Confusion matrix\n",
            " [[99  4]\n",
            " [ 4 93]] \n",
            "\n",
            "Accuracy: 0.96 \n",
            "\n",
            "F1 Score: 0.9587628865979382 \n",
            "\n",
            "_______________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVC"
      ],
      "metadata": {
        "id": "fbX9j48J1a9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVClassifier:\n",
        "    def __init__(self, C = 1, kernel='linear', gamma = 0.2):\n",
        "        self.C = C\n",
        "        self.kernel = kernel\n",
        "        self.gamma = gamma\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma, verbose=True)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        if self.model is None:\n",
        "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.model.predict(X_test)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
        "        self.model = svm.SVC()\n",
        "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        self.C = random_search.best_params_['C']\n",
        "        self.kernel = random_search.best_params_['kernel']\n",
        "        self.gamma = random_search.best_params_['gamma']\n",
        "\n",
        "        self.model = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        if self.model is None:\n",
        "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.predict(X_test)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
        "        print('Accuracy:', accuracy, '\\n')\n",
        "        print('F1 Score:', f1, '\\n')\n",
        "\n",
        "        return cm, accuracy, f1"
      ],
      "metadata": {
        "id": "l9ejvPAqrW93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate classifier\n",
        "classifier = SVClassifier()\n",
        "\n",
        "# Perform randomized search over hyperparameters\n",
        "param_distributions = {\n",
        "    'C': [1, 10, 100, 1000],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale']\n",
        "    #'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "}\n",
        "classifier.randomized_search(X_train_embeddings, y_train, param_distributions)\n",
        "\n",
        "# Train classifier on training data\n",
        "classifier.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "print('\\n')\n",
        "print('\\n_______________________________________________________________________')\n",
        "print('EVALUATION')\n",
        "\n",
        "print('\\n----- TRAIN -----')\n",
        "conf_matrix, accuracy, f1_sc = classifier.evaluate(X_train_embeddings, y_train)\n",
        "\n",
        "print('\\n----- TEST -----')\n",
        "conf_matrix, accuracy, f1_sc = classifier.evaluate(X_test_embeddings, y_test)\n",
        "print('_______________________________________________________________________')"
      ],
      "metadata": {
        "id": "fSTFuYyH63Mk",
        "outputId": "6ba15a33-8e98-4a4e-9113-8c771dc0dede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
            "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.981 total time=   0.1s\n",
            "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
            "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.956 total time=   0.0s\n",
            "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.975 total time=   0.1s\n",
            "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.969 total time=   0.1s\n",
            "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.994 total time=   0.1s\n",
            "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.963 total time=   0.1s\n",
            "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
            "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.956 total time=   0.1s\n",
            "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.938 total time=   0.1s\n",
            "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.906 total time=   0.1s\n",
            "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.1s\n",
            "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.1s\n",
            "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
            "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
            "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
            "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.975 total time=   0.0s\n",
            "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.994 total time=   0.0s\n",
            "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.981 total time=   0.0s\n",
            "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.975 total time=   0.0s\n",
            "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.956 total time=   0.0s\n",
            "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.931 total time=   0.0s\n",
            "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.925 total time=   0.0s\n",
            "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.944 total time=   0.0s\n",
            "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.944 total time=   0.0s\n",
            "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
            "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END ...C=100, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
            "[CV 2/5] END ...C=100, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ...C=100, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
            "[CV 4/5] END ...C=100, gamma=scale, kernel=poly;, score=0.981 total time=   0.1s\n",
            "[CV 5/5] END ...C=100, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.994 total time=   0.1s\n",
            "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=1.000 total time=   0.1s\n",
            "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
            "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
            "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.994 total time=   0.1s\n",
            "[CV 1/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.919 total time=   0.0s\n",
            "[CV 2/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.906 total time=   0.0s\n",
            "[CV 3/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.863 total time=   0.0s\n",
            "[CV 4/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.912 total time=   0.0s\n",
            "[CV 5/5] END C=100, gamma=scale, kernel=sigmoid;, score=0.900 total time=   0.0s\n",
            "[CV 1/5] END C=1000, gamma=scale, kernel=linear;, score=0.988 total time=   0.0s\n",
            "[CV 2/5] END C=1000, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 3/5] END C=1000, gamma=scale, kernel=linear;, score=0.975 total time=   0.0s\n",
            "[CV 4/5] END C=1000, gamma=scale, kernel=linear;, score=0.975 total time=   0.1s\n",
            "[CV 5/5] END C=1000, gamma=scale, kernel=linear;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.988 total time=   0.0s\n",
            "[CV 2/5] END ..C=1000, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.981 total time=   0.0s\n",
            "[CV 4/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.981 total time=   0.1s\n",
            "[CV 5/5] END ..C=1000, gamma=scale, kernel=poly;, score=0.994 total time=   0.0s\n",
            "[CV 1/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.994 total time=   0.1s\n",
            "[CV 2/5] END ...C=1000, gamma=scale, kernel=rbf;, score=1.000 total time=   0.1s\n",
            "[CV 3/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
            "[CV 4/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.975 total time=   0.1s\n",
            "[CV 5/5] END ...C=1000, gamma=scale, kernel=rbf;, score=0.994 total time=   0.1s\n",
            "[CV 1/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.906 total time=   0.0s\n",
            "[CV 2/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.887 total time=   0.0s\n",
            "[CV 3/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.906 total time=   0.0s\n",
            "[CV 5/5] END C=1000, gamma=scale, kernel=sigmoid;, score=0.894 total time=   0.0s\n",
            "[LibSVM]\n",
            "\n",
            "\n",
            "_______________________________________________________________________\n",
            "EVALUATION\n",
            "\n",
            "----- TRAIN -----\n",
            "\n",
            "Confusion matrix\n",
            " [[410   0]\n",
            " [  0 390]] \n",
            "\n",
            "Accuracy: 1.0 \n",
            "\n",
            "F1 Score: 1.0 \n",
            "\n",
            "\n",
            "----- TEST -----\n",
            "\n",
            "Confusion matrix\n",
            " [[101   2]\n",
            " [  1  96]] \n",
            "\n",
            "Accuracy: 0.985 \n",
            "\n",
            "F1 Score: 0.9846153846153847 \n",
            "\n",
            "_______________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "yYoz0OB11ayT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LRClassifier:\n",
        "    def __init__(self, penalty = 'l2', solver = 'libinear', C = 0.5):\n",
        "        self.penalty = penalty\n",
        "        self.solver = solver\n",
        "        self.C = C\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        if self.model is None:\n",
        "          raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.model.predict(X_test)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
        "        self.model = LogisticRegression()\n",
        "        random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        self.penalty = random_search.best_params_['penalty']\n",
        "        self.solver = random_search.best_params_['solver']\n",
        "        self.C = random_search.best_params_['C']\n",
        "\n",
        "        self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        if self.model is None:\n",
        "              raise ValueError(\"The model has not been trained yet. Please call 'fit' first.\")\n",
        "        y_pred = self.predict(X_test)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        print('\\nConfusion matrix\\n', cm, '\\n')\n",
        "        print('Accuracy:', accuracy, '\\n')\n",
        "        print('F1 Score:', f1, '\\n')\n",
        "\n",
        "        return cm, accuracy, f1"
      ],
      "metadata": {
        "id": "HHfhUGWu64b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate classifier\n",
        "classifier = LRClassifier()\n",
        "\n",
        "# Perform randomized search over hyperparameters\n",
        "param_distributions = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'C' : np.arange(0, 1, 0.01)\n",
        "}\n",
        "classifier.randomized_search(X_train_embeddings, y_train, param_distributions)\n",
        "\n",
        "# Train classifier on training data\n",
        "classifier.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# Evaluate classifier\n",
        "print('\\n')\n",
        "print('\\n_______________________________________________________________________')\n",
        "print('EVALUATION')\n",
        "\n",
        "print('\\n----- TRAIN -----')\n",
        "cm, accuracy, f1 = classifier.evaluate(X_train_embeddings, y_train)\n",
        "\n",
        "print('\\n----- TEST -----')\n",
        "cm, accuracy, f1 = classifier.evaluate(X_test_embeddings, y_test)\n",
        "print('_______________________________________________________________________')"
      ],
      "metadata": {
        "id": "YijN0v7JCFbG",
        "outputId": "4bf95058-f264-43c2-e84d-1572b4814428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END ..C=0.18, penalty=none, solver=sag;, score=0.981 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END ..C=0.18, penalty=none, solver=sag;, score=0.963 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END ..C=0.18, penalty=none, solver=sag;, score=0.975 total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END ..C=0.18, penalty=none, solver=sag;, score=0.975 total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END ..C=0.18, penalty=none, solver=sag;, score=0.994 total time=   0.8s\n",
            "[CV 1/5] END C=0.39, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.39, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.39, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.39, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.39, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END ..C=0.9, penalty=none, solver=saga;, score=0.981 total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END ..C=0.9, penalty=none, solver=saga;, score=0.969 total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END ..C=0.9, penalty=none, solver=saga;, score=0.969 total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END ..C=0.9, penalty=none, solver=saga;, score=0.981 total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END ..C=0.9, penalty=none, solver=saga;, score=0.994 total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.8300000000000001, penalty=l2, solver=sag;, score=0.981 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.8300000000000001, penalty=l2, solver=sag;, score=0.969 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.8300000000000001, penalty=l2, solver=sag;, score=0.969 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.8300000000000001, penalty=l2, solver=sag;, score=0.975 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.8300000000000001, penalty=l2, solver=sag;, score=0.994 total time=   0.7s\n",
            "[CV 1/5] END C=0.26, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.26, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.26, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.26, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.26, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.8, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.8, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.8, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.8, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.8, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.78, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.78, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.78, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.78, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.78, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.78, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.78, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.78, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.78, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.78, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ....C=0.31, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ....C=0.31, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ....C=0.31, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ....C=0.31, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ....C=0.31, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.18, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.18, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.18, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.18, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.18, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ..C=0.36, penalty=l2, solver=lbfgs;, score=0.981 total time=   0.2s\n",
            "[CV 2/5] END ..C=0.36, penalty=l2, solver=lbfgs;, score=0.969 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END ..C=0.36, penalty=l2, solver=lbfgs;, score=0.956 total time=   0.1s\n",
            "[CV 4/5] END ..C=0.36, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END ..C=0.36, penalty=l2, solver=lbfgs;, score=0.988 total time=   0.1s\n",
            "[CV 1/5] END C=0.75, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.75, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.75, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.75, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.75, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END ..C=0.05, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.1s\n",
            "[CV 2/5] END ..C=0.05, penalty=l2, solver=lbfgs;, score=0.963 total time=   0.1s\n",
            "[CV 3/5] END ..C=0.05, penalty=l2, solver=lbfgs;, score=0.931 total time=   0.1s\n",
            "[CV 4/5] END ..C=0.05, penalty=l2, solver=lbfgs;, score=0.969 total time=   0.1s\n",
            "[CV 5/5] END ..C=0.05, penalty=l2, solver=lbfgs;, score=0.956 total time=   0.1s\n",
            "[CV 1/5] END C=0.39, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.39, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.39, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.39, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.39, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.31, penalty=l2, solver=liblinear;, score=0.981 total time=   0.1s\n",
            "[CV 2/5] END C=0.31, penalty=l2, solver=liblinear;, score=0.969 total time=   0.1s\n",
            "[CV 3/5] END C=0.31, penalty=l2, solver=liblinear;, score=0.956 total time=   0.1s\n",
            "[CV 4/5] END C=0.31, penalty=l2, solver=liblinear;, score=0.975 total time=   0.1s\n",
            "[CV 5/5] END C=0.31, penalty=l2, solver=liblinear;, score=0.988 total time=   0.1s\n",
            "[CV 1/5] END C=0.58, penalty=l2, solver=liblinear;, score=0.981 total time=   0.1s\n",
            "[CV 2/5] END C=0.58, penalty=l2, solver=liblinear;, score=0.969 total time=   0.1s\n",
            "[CV 3/5] END C=0.58, penalty=l2, solver=liblinear;, score=0.969 total time=   0.1s\n",
            "[CV 4/5] END C=0.58, penalty=l2, solver=liblinear;, score=0.981 total time=   0.1s\n",
            "[CV 5/5] END C=0.58, penalty=l2, solver=liblinear;, score=0.988 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ....C=0.78, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END .C=0.56, penalty=none, solver=saga;, score=0.981 total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END .C=0.56, penalty=none, solver=saga;, score=0.969 total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END .C=0.56, penalty=none, solver=saga;, score=0.969 total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END .C=0.56, penalty=none, solver=saga;, score=0.981 total time=   0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END .C=0.56, penalty=none, solver=saga;, score=0.994 total time=   0.6s\n",
            "[CV 1/5] END ....C=0.97, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END ....C=0.97, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END ....C=0.97, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END ....C=0.97, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END ....C=0.97, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.969 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.956 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.944 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.969 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "55 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1048, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.9775      nan 0.97875 0.9775      nan     nan     nan     nan     nan\n",
            "     nan 0.97375     nan 0.95875     nan 0.97375 0.9775      nan 0.97875\n",
            "     nan 0.96   ]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.41000000000000003, penalty=l1, solver=saga;, score=0.963 total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "_______________________________________________________________________\n",
            "EVALUATION\n",
            "\n",
            "----- TRAIN -----\n",
            "\n",
            "Confusion matrix\n",
            " [[410   0]\n",
            " [  0 390]] \n",
            "\n",
            "Accuracy: 1.0 \n",
            "\n",
            "F1 Score: 1.0 \n",
            "\n",
            "\n",
            "----- TEST -----\n",
            "\n",
            "Confusion matrix\n",
            " [[102   1]\n",
            " [  1  96]] \n",
            "\n",
            "Accuracy: 0.99 \n",
            "\n",
            "F1 Score: 0.9896907216494846 \n",
            "\n",
            "_______________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # PLOTTING ROC EXAMPLE\n",
        "\n",
        "# class LRClassifier:\n",
        "#     def __init__(self, penalty = 'l2', solver = 'libinear', C = 0.5):\n",
        "#         self.penalty = penalty\n",
        "#         self.solver = solver\n",
        "#         self.C = C\n",
        "\n",
        "#     def fit(self, X_train, y_train):\n",
        "#         self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
        "#         self.model.fit(X_train, y_train)\n",
        "\n",
        "#     def predict(self, X_test, proba=False):\n",
        "#         if(proba):\n",
        "#           y_pred = self.model.predict_proba(X_test)\n",
        "#           return y_pred\n",
        "\n",
        "#         else:\n",
        "#           y_pred = self.model.predict(X_test)\n",
        "#           return y_pred\n",
        "\n",
        "\n",
        "#     def randomized_search(self, X_train, y_train, param_distributions, cv=5, n_iter=20):\n",
        "#         self.model = LogisticRegression()\n",
        "#         random_search = RandomizedSearchCV(self.model, param_distributions=param_distributions, cv=cv, n_iter=n_iter, verbose=3)\n",
        "#         random_search.fit(X_train, y_train)\n",
        "\n",
        "#         self.penalty = random_search.best_params_['penalty']\n",
        "#         self.solver = random_search.best_params_['solver']\n",
        "#         self.C = random_search.best_params_['C']\n",
        "\n",
        "#         self.model = LogisticRegression(penalty=self.penalty, solver=self.solver, C=self.C)\n",
        "\n",
        "#     def evaluate(self, X_test, y_test, plot_roc):\n",
        "#         y_pred = self.predict(X_test)\n",
        "\n",
        "#         print('Confusion matrix\\n', confusion_matrix(y_test, y_pred))\n",
        "#         print('\\nAccuracy:', accuracy_score(y_test, y_pred))\n",
        "#         print('\\nF1 Score:', f1_score(y_test, y_pred))\n",
        "\n",
        "#         if(plot_roc):\n",
        "#           y_pred_proba = classifier.predict(X_test, proba=True)[::,1]\n",
        "#           fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "#           auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "#           #create ROC curve\n",
        "#           plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "#           plt.ylabel('True Positive Rate')\n",
        "#           plt.xlabel('False Positive Rate')\n",
        "#           plt.legend(loc=4)\n",
        "#           plt.show()\n",
        "\n",
        "\n",
        "#         return confusion_matrix(y_test, y_pred), accuracy_score(y_test, y_pred), f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "# # Instantiate classifier\n",
        "# classifier = LRClassifier()\n",
        "\n",
        "# # Perform randomized search over hyperparameters\n",
        "# param_distributions = {\n",
        "#     'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "#     'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "#     'C' : np.arange(0, 1, 0.01)\n",
        "# }\n",
        "# classifier.randomized_search(X_train_embeddings, y_train, param_distributions)\n",
        "\n",
        "# # Train classifier on training data\n",
        "# classifier.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# # Evaluate classifier\n",
        "# print('\\n')\n",
        "# print('\\n_______________________________________________________________________')\n",
        "# print('EVALUATION')\n",
        "# print('\\n----- TRAIN -----')\n",
        "# conf_matrix, accuracy, f1_sc = classifier.evaluate(X_train_embeddings, y_train, plot_roc = True)\n",
        "# print('\\n')\n",
        "# print('\\n----- TEST -----')\n",
        "# conf_matrix, accuracy, f1_sc = classifier.evaluate(X_test_embeddings, y_test, plot_roc = True)\n",
        "# print('_______________________________________________________________________')"
      ],
      "metadata": {
        "id": "R5j173-2Tt2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ... embeddings"
      ],
      "metadata": {
        "id": "0uSk7WKhGB1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "h1D_jiR2GI7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP"
      ],
      "metadata": {
        "id": "LA5swddzG28v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "-Lfsat69GIoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP"
      ],
      "metadata": {
        "id": "rt7c3MSPG3PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "YUCEQAQXGIl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP"
      ],
      "metadata": {
        "id": "GLutlbgvG3f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVC"
      ],
      "metadata": {
        "id": "vldrLVlwGIg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP"
      ],
      "metadata": {
        "id": "MqqebdmmG3qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "d8IPkDvHGIZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP"
      ],
      "metadata": {
        "id": "7j_OebkkG32s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "24t1eSrlFLK6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4nZ7PewQFMwK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}